
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../framework/">
      
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Code - NNfluxnu</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.342714a4.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#api-reference" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="NNfluxnu" class="md-header__button md-logo" aria-label="NNfluxnu" data-md-component="logo">
      
  <img src="../logo/NN_nu_flux_blauw.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            NNfluxnu
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Code
            
          </span>
        </div>
      </div>
    </div>
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="NNfluxnu" class="md-nav__button md-logo" aria-label="NNfluxnu" data-md-component="logo">
      
  <img src="../logo/NN_nu_flux_blauw.png" alt="logo">

    </a>
    NNfluxnu
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../usage/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Usage
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../framework/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Framework
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Code
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Code
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#core-fitting-modules" class="md-nav__link">
    <span class="md-ellipsis">
      🔧 Core Fitting Modules
    </span>
  </a>
  
    <nav class="md-nav" aria-label="🔧 Core Fitting Modules">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#perform_fit_combpy" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit_comb.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_comb" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit_comb
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_comb.perform_fit" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="perform_fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_comb.perform_fit--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_comb.perform_fit--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_comb.perform_fit--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#perform_fit_nu_nubpy" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit_nu_nub.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_nu_nub" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit_nu_nub
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_nu_nub.perform_fit" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="perform_fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_nu_nub.perform_fit--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_nu_nub.perform_fit--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_nu_nub.perform_fit--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#execute_fitpy" class="md-nav__link">
    <span class="md-ellipsis">
      execute_fit.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.execute_fit" class="md-nav__link">
    <span class="md-ellipsis">
      execute_fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="execute_fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#execute_postfitpy" class="md-nav__link">
    <span class="md-ellipsis">
      execute_postfit.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.execute_postfit" class="md-nav__link">
    <span class="md-ellipsis">
      execute_postfit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.execute_postfit.postfit_execution" class="md-nav__link">
    <span class="md-ellipsis">
      postfit_execution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hyperparameter-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      🎯 Hyperparameter optimization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="🎯 Hyperparameter optimization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#perform_hyperoptpy" class="md-nav__link">
    <span class="md-ellipsis">
      perform_hyperopt.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.perform_hyperopt" class="md-nav__link">
    <span class="md-ellipsis">
      perform_hyperopt
    </span>
  </a>
  
    <nav class="md-nav" aria-label="perform_hyperopt">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hyperopt_combpy" class="md-nav__link">
    <span class="md-ellipsis">
      hyperopt_comb.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_comb" class="md-nav__link">
    <span class="md-ellipsis">
      hyperopt_comb
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_comb.perform_fit" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="perform_fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_comb.perform_fit--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_comb.perform_fit--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_comb.perform_fit--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperopt_nu_nubpy" class="md-nav__link">
    <span class="md-ellipsis">
      hyperopt_nu_nub.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_nu_nub" class="md-nav__link">
    <span class="md-ellipsis">
      hyperopt_nu_nub
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_nu_nub.perform_fit" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="perform_fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_nu_nub.perform_fit--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_nu_nub.perform_fit--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      🧠 Model Architecture
    </span>
  </a>
  
    <nav class="md-nav" aria-label="🧠 Model Architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#structure_nnpy" class="md-nav__link">
    <span class="md-ellipsis">
      structure_NN.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.structure_NN" class="md-nav__link">
    <span class="md-ellipsis">
      structure_NN
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomLoss" class="md-nav__link">
    <span class="md-ellipsis">
      CustomLoss
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CustomLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomLoss--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomLoss--methods" class="md-nav__link">
    <span class="md-ellipsis">
      Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
    <nav class="md-nav" aria-label="forward">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomLoss.forward--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomLoss.forward--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomPreprocessing" class="md-nav__link">
    <span class="md-ellipsis">
      CustomPreprocessing
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CustomPreprocessing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomPreprocessing--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomPreprocessing--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomPreprocessing.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
    <nav class="md-nav" aria-label="forward">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomPreprocessing.forward--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomPreprocessing.forward--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP" class="md-nav__link">
    <span class="md-ellipsis">
      PreprocessedMLP
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PreprocessedMLP">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP--attributes" class="md-nav__link">
    <span class="md-ellipsis">
      Attributes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP--methods" class="md-nav__link">
    <span class="md-ellipsis">
      Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
    <nav class="md-nav" aria-label="forward">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.forward--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.forward--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.neuralnet" class="md-nav__link">
    <span class="md-ellipsis">
      neuralnet
    </span>
  </a>
  
    <nav class="md-nav" aria-label="neuralnet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.neuralnet--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.neuralnet--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.preproces" class="md-nav__link">
    <span class="md-ellipsis">
      preproces
    </span>
  </a>
  
    <nav class="md-nav" aria-label="preproces">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.preproces--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.preproces--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.SimplePerceptron" class="md-nav__link">
    <span class="md-ellipsis">
      SimplePerceptron
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SimplePerceptron">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.SimplePerceptron--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.SimplePerceptron--attributes" class="md-nav__link">
    <span class="md-ellipsis">
      Attributes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.SimplePerceptron--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.SimplePerceptron.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
    <nav class="md-nav" aria-label="forward">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.SimplePerceptron.forward--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.SimplePerceptron.forward--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#plotting-and-visualization" class="md-nav__link">
    <span class="md-ellipsis">
      📈 Plotting and Visualization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="📈 Plotting and Visualization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#plot_comb_pdf_clpy" class="md-nav__link">
    <span class="md-ellipsis">
      plot_comb_pdf_cl.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.plot_comb_pdf_cl" class="md-nav__link">
    <span class="md-ellipsis">
      plot_comb_pdf_cl
    </span>
  </a>
  
    <nav class="md-nav" aria-label="plot_comb_pdf_cl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#plot_diff_level1_combpy" class="md-nav__link">
    <span class="md-ellipsis">
      plot_diff_level1_comb.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.plot_diff_level1_comb" class="md-nav__link">
    <span class="md-ellipsis">
      plot_diff_level1_comb
    </span>
  </a>
  
    <nav class="md-nav" aria-label="plot_diff_level1_comb">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#plot_for_diff_level_1_shifts_nu_nubpy" class="md-nav__link">
    <span class="md-ellipsis">
      plot_for_diff_level_1_shifts_nu_nub.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.plot_for_diff_level_1_shifts_nu_nub" class="md-nav__link">
    <span class="md-ellipsis">
      plot_for_diff_level_1_shifts_nu_nub
    </span>
  </a>
  
    <nav class="md-nav" aria-label="plot_for_diff_level_1_shifts_nu_nub">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#plot_nu_nub_clpy" class="md-nav__link">
    <span class="md-ellipsis">
      plot_nu_nub_cl.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.plot_nu_nub_cl" class="md-nav__link">
    <span class="md-ellipsis">
      plot_nu_nub_cl
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pdf-output" class="md-nav__link">
    <span class="md-ellipsis">
      📦 PDF Output
    </span>
  </a>
  
    <nav class="md-nav" aria-label="📦 PDF Output">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#write_all_pdfs_to_lhapdfpy" class="md-nav__link">
    <span class="md-ellipsis">
      write_all_pdfs_to_lhapdf.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.write_all_pdfs_to_lhapdf" class="md-nav__link">
    <span class="md-ellipsis">
      write_all_pdfs_to_lhapdf
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.write_all_pdfs_to_lhapdf.customize_info_file" class="md-nav__link">
    <span class="md-ellipsis">
      customize_info_file
    </span>
  </a>
  
    <nav class="md-nav" aria-label="customize_info_file">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.write_all_pdfs_to_lhapdf.customize_info_file--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.write_all_pdfs_to_lhapdf.customize_info_file--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.write_all_pdfs_to_lhapdf.write_lhapdf_grid" class="md-nav__link">
    <span class="md-ellipsis">
      write_lhapdf_grid
    </span>
  </a>
  
    <nav class="md-nav" aria-label="write_lhapdf_grid">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.write_all_pdfs_to_lhapdf.write_lhapdf_grid--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.write_all_pdfs_to_lhapdf.write_lhapdf_grid--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-and-reading" class="md-nav__link">
    <span class="md-ellipsis">
      🧪 Data and Reading
    </span>
  </a>
  
    <nav class="md-nav" aria-label="🧪 Data and Reading">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mc_data_repspy" class="md-nav__link">
    <span class="md-ellipsis">
      MC_data_reps.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.MC_data_reps" class="md-nav__link">
    <span class="md-ellipsis">
      MC_data_reps
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.MC_data_reps.generate_MC_replicas" class="md-nav__link">
    <span class="md-ellipsis">
      generate_MC_replicas
    </span>
  </a>
  
    <nav class="md-nav" aria-label="generate_MC_replicas">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#read_faserv_pdfpy" class="md-nav__link">
    <span class="md-ellipsis">
      read_faserv_pdf.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.read_faserv_pdf" class="md-nav__link">
    <span class="md-ellipsis">
      read_faserv_pdf
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.read_faserv_pdf.read_pdf" class="md-nav__link">
    <span class="md-ellipsis">
      read_pdf
    </span>
  </a>
  
    <nav class="md-nav" aria-label="read_pdf">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.read_faserv_pdf.read_pdf--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.read_faserv_pdf.read_pdf--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#read_fk_tablepy" class="md-nav__link">
    <span class="md-ellipsis">
      read_fk_table.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.read_fk_table" class="md-nav__link">
    <span class="md-ellipsis">
      read_fk_table
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.read_fk_table.get_fk_table" class="md-nav__link">
    <span class="md-ellipsis">
      get_fk_table
    </span>
  </a>
  
    <nav class="md-nav" aria-label="get_fk_table">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.read_fk_table.get_fk_table--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.read_fk_table.get_fk_table--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#help_read_filespy" class="md-nav__link">
    <span class="md-ellipsis">
      help_read_files.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.help_read_files" class="md-nav__link">
    <span class="md-ellipsis">
      help_read_files
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#post-fit-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      📊 Post-Fit Analysis
    </span>
  </a>
  
    <nav class="md-nav" aria-label="📊 Post-Fit Analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#postfit_criteriapy" class="md-nav__link">
    <span class="md-ellipsis">
      postfit_criteria.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.postfit_criteria" class="md-nav__link">
    <span class="md-ellipsis">
      postfit_criteria
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.postfit_criteria.Postfit" class="md-nav__link">
    <span class="md-ellipsis">
      Postfit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Postfit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_criteria.Postfit.apply_postfit_criteria" class="md-nav__link">
    <span class="md-ellipsis">
      apply_postfit_criteria
    </span>
  </a>
  
    <nav class="md-nav" aria-label="apply_postfit_criteria">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_criteria.Postfit.apply_postfit_criteria--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_criteria.Postfit.apply_postfit_criteria--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_criteria.Postfit.apply_postfit_criteria--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#postfit_measurespy" class="md-nav__link">
    <span class="md-ellipsis">
      postfit_measures.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures" class="md-nav__link">
    <span class="md-ellipsis">
      postfit_measures
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures" class="md-nav__link">
    <span class="md-ellipsis">
      Measures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Measures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.N_event_pred" class="md-nav__link">
    <span class="md-ellipsis">
      N_event_pred
    </span>
  </a>
  
    <nav class="md-nav" aria-label="N_event_pred">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.N_event_pred--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_accuracy" class="md-nav__link">
    <span class="md-ellipsis">
      compute_accuracy
    </span>
  </a>
  
    <nav class="md-nav" aria-label="compute_accuracy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_accuracy--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_accuracy--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_bias_to_variance" class="md-nav__link">
    <span class="md-ellipsis">
      compute_bias_to_variance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="compute_bias_to_variance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_bias_to_variance--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_bias_to_variance--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_delta_chi" class="md-nav__link">
    <span class="md-ellipsis">
      compute_delta_chi
    </span>
  </a>
  
    <nav class="md-nav" aria-label="compute_delta_chi">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_delta_chi--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_delta_chi--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_phi" class="md-nav__link">
    <span class="md-ellipsis">
      compute_phi
    </span>
  </a>
  
    <nav class="md-nav" aria-label="compute_phi">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_phi--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_phi--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pullpy" class="md-nav__link">
    <span class="md-ellipsis">
      pull.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.pull" class="md-nav__link">
    <span class="md-ellipsis">
      pull
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.pull.compute_pull" class="md-nav__link">
    <span class="md-ellipsis">
      compute_pull
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#miscellaneous-modules" class="md-nav__link">
    <span class="md-ellipsis">
      🧬 Miscellaneous Modules
    </span>
  </a>
  
    <nav class="md-nav" aria-label="🧬 Miscellaneous Modules">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#form_loss_fctpy" class="md-nav__link">
    <span class="md-ellipsis">
      form_loss_fct.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct" class="md-nav__link">
    <span class="md-ellipsis">
      form_loss_fct
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.complete_loss_fct_comb" class="md-nav__link">
    <span class="md-ellipsis">
      complete_loss_fct_comb
    </span>
  </a>
  
    <nav class="md-nav" aria-label="complete_loss_fct_comb">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.complete_loss_fct_comb--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.complete_loss_fct_comb--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.complete_loss_fct_nu_nub" class="md-nav__link">
    <span class="md-ellipsis">
      complete_loss_fct_nu_nub
    </span>
  </a>
  
    <nav class="md-nav" aria-label="complete_loss_fct_nu_nub">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.complete_loss_fct_nu_nub--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.complete_loss_fct_nu_nub--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.raw_loss_fct" class="md-nav__link">
    <span class="md-ellipsis">
      raw_loss_fct
    </span>
  </a>
  
    <nav class="md-nav" aria-label="raw_loss_fct">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.raw_loss_fct--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.raw_loss_fct--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate_datapy" class="md-nav__link">
    <span class="md-ellipsis">
      generate_data.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.generate_data" class="md-nav__link">
    <span class="md-ellipsis">
      generate_data
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.generate_data.aggregate_entries_with_indices" class="md-nav__link">
    <span class="md-ellipsis">
      aggregate_entries_with_indices
    </span>
  </a>
  
    <nav class="md-nav" aria-label="aggregate_entries_with_indices">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.aggregate_entries_with_indices--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.aggregate_entries_with_indices--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.aggregate_entries_with_indices--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.generate_data.compute_pseudo_data" class="md-nav__link">
    <span class="md-ellipsis">
      compute_pseudo_data
    </span>
  </a>
  
    <nav class="md-nav" aria-label="compute_pseudo_data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.compute_pseudo_data--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.compute_pseudo_data--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.compute_pseudo_data--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.generate_data.write_data" class="md-nav__link">
    <span class="md-ellipsis">
      write_data
    </span>
  </a>
  
    <nav class="md-nav" aria-label="write_data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.write_data--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.write_data--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.write_data--output-files" class="md-nav__link">
    <span class="md-ellipsis">
      Output Files
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.write_data--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datayaml-fit_settingsyaml-aall_fits-runcards-etc" class="md-nav__link">
    <span class="md-ellipsis">
      data.yaml, fit_settings.yaml, aall_fits/, runcards/, etc.
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#core-fitting-modules" class="md-nav__link">
    <span class="md-ellipsis">
      🔧 Core Fitting Modules
    </span>
  </a>
  
    <nav class="md-nav" aria-label="🔧 Core Fitting Modules">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#perform_fit_combpy" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit_comb.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_comb" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit_comb
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_comb.perform_fit" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="perform_fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_comb.perform_fit--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_comb.perform_fit--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_comb.perform_fit--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#perform_fit_nu_nubpy" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit_nu_nub.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_nu_nub" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit_nu_nub
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_nu_nub.perform_fit" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="perform_fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_nu_nub.perform_fit--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_nu_nub.perform_fit--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.perform_fit_nu_nub.perform_fit--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#execute_fitpy" class="md-nav__link">
    <span class="md-ellipsis">
      execute_fit.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.execute_fit" class="md-nav__link">
    <span class="md-ellipsis">
      execute_fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="execute_fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#execute_postfitpy" class="md-nav__link">
    <span class="md-ellipsis">
      execute_postfit.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.execute_postfit" class="md-nav__link">
    <span class="md-ellipsis">
      execute_postfit
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.execute_postfit.postfit_execution" class="md-nav__link">
    <span class="md-ellipsis">
      postfit_execution
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#hyperparameter-optimization" class="md-nav__link">
    <span class="md-ellipsis">
      🎯 Hyperparameter optimization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="🎯 Hyperparameter optimization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#perform_hyperoptpy" class="md-nav__link">
    <span class="md-ellipsis">
      perform_hyperopt.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.perform_hyperopt" class="md-nav__link">
    <span class="md-ellipsis">
      perform_hyperopt
    </span>
  </a>
  
    <nav class="md-nav" aria-label="perform_hyperopt">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#hyperopt_combpy" class="md-nav__link">
    <span class="md-ellipsis">
      hyperopt_comb.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_comb" class="md-nav__link">
    <span class="md-ellipsis">
      hyperopt_comb
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_comb.perform_fit" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="perform_fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_comb.perform_fit--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_comb.perform_fit--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_comb.perform_fit--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hyperopt_nu_nubpy" class="md-nav__link">
    <span class="md-ellipsis">
      hyperopt_nu_nub.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_nu_nub" class="md-nav__link">
    <span class="md-ellipsis">
      hyperopt_nu_nub
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_nu_nub.perform_fit" class="md-nav__link">
    <span class="md-ellipsis">
      perform_fit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="perform_fit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_nu_nub.perform_fit--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.hyperopt_nu_nub.perform_fit--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-architecture" class="md-nav__link">
    <span class="md-ellipsis">
      🧠 Model Architecture
    </span>
  </a>
  
    <nav class="md-nav" aria-label="🧠 Model Architecture">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#structure_nnpy" class="md-nav__link">
    <span class="md-ellipsis">
      structure_NN.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.structure_NN" class="md-nav__link">
    <span class="md-ellipsis">
      structure_NN
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomLoss" class="md-nav__link">
    <span class="md-ellipsis">
      CustomLoss
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CustomLoss">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomLoss--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomLoss--methods" class="md-nav__link">
    <span class="md-ellipsis">
      Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomLoss.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
    <nav class="md-nav" aria-label="forward">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomLoss.forward--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomLoss.forward--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomPreprocessing" class="md-nav__link">
    <span class="md-ellipsis">
      CustomPreprocessing
    </span>
  </a>
  
    <nav class="md-nav" aria-label="CustomPreprocessing">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomPreprocessing--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomPreprocessing--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomPreprocessing.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
    <nav class="md-nav" aria-label="forward">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomPreprocessing.forward--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.CustomPreprocessing.forward--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP" class="md-nav__link">
    <span class="md-ellipsis">
      PreprocessedMLP
    </span>
  </a>
  
    <nav class="md-nav" aria-label="PreprocessedMLP">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP--attributes" class="md-nav__link">
    <span class="md-ellipsis">
      Attributes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP--methods" class="md-nav__link">
    <span class="md-ellipsis">
      Methods
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
    <nav class="md-nav" aria-label="forward">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.forward--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.forward--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.neuralnet" class="md-nav__link">
    <span class="md-ellipsis">
      neuralnet
    </span>
  </a>
  
    <nav class="md-nav" aria-label="neuralnet">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.neuralnet--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.neuralnet--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.preproces" class="md-nav__link">
    <span class="md-ellipsis">
      preproces
    </span>
  </a>
  
    <nav class="md-nav" aria-label="preproces">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.preproces--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.PreprocessedMLP.preproces--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.SimplePerceptron" class="md-nav__link">
    <span class="md-ellipsis">
      SimplePerceptron
    </span>
  </a>
  
    <nav class="md-nav" aria-label="SimplePerceptron">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.SimplePerceptron--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.SimplePerceptron--attributes" class="md-nav__link">
    <span class="md-ellipsis">
      Attributes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.SimplePerceptron--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.SimplePerceptron.forward" class="md-nav__link">
    <span class="md-ellipsis">
      forward
    </span>
  </a>
  
    <nav class="md-nav" aria-label="forward">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.SimplePerceptron.forward--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.structure_NN.SimplePerceptron.forward--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#plotting-and-visualization" class="md-nav__link">
    <span class="md-ellipsis">
      📈 Plotting and Visualization
    </span>
  </a>
  
    <nav class="md-nav" aria-label="📈 Plotting and Visualization">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#plot_comb_pdf_clpy" class="md-nav__link">
    <span class="md-ellipsis">
      plot_comb_pdf_cl.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.plot_comb_pdf_cl" class="md-nav__link">
    <span class="md-ellipsis">
      plot_comb_pdf_cl
    </span>
  </a>
  
    <nav class="md-nav" aria-label="plot_comb_pdf_cl">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#plot_diff_level1_combpy" class="md-nav__link">
    <span class="md-ellipsis">
      plot_diff_level1_comb.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.plot_diff_level1_comb" class="md-nav__link">
    <span class="md-ellipsis">
      plot_diff_level1_comb
    </span>
  </a>
  
    <nav class="md-nav" aria-label="plot_diff_level1_comb">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#plot_for_diff_level_1_shifts_nu_nubpy" class="md-nav__link">
    <span class="md-ellipsis">
      plot_for_diff_level_1_shifts_nu_nub.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.plot_for_diff_level_1_shifts_nu_nub" class="md-nav__link">
    <span class="md-ellipsis">
      plot_for_diff_level_1_shifts_nu_nub
    </span>
  </a>
  
    <nav class="md-nav" aria-label="plot_for_diff_level_1_shifts_nu_nub">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#plot_nu_nub_clpy" class="md-nav__link">
    <span class="md-ellipsis">
      plot_nu_nub_cl.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.plot_nu_nub_cl" class="md-nav__link">
    <span class="md-ellipsis">
      plot_nu_nub_cl
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pdf-output" class="md-nav__link">
    <span class="md-ellipsis">
      📦 PDF Output
    </span>
  </a>
  
    <nav class="md-nav" aria-label="📦 PDF Output">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#write_all_pdfs_to_lhapdfpy" class="md-nav__link">
    <span class="md-ellipsis">
      write_all_pdfs_to_lhapdf.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.write_all_pdfs_to_lhapdf" class="md-nav__link">
    <span class="md-ellipsis">
      write_all_pdfs_to_lhapdf
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.write_all_pdfs_to_lhapdf.customize_info_file" class="md-nav__link">
    <span class="md-ellipsis">
      customize_info_file
    </span>
  </a>
  
    <nav class="md-nav" aria-label="customize_info_file">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.write_all_pdfs_to_lhapdf.customize_info_file--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.write_all_pdfs_to_lhapdf.customize_info_file--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.write_all_pdfs_to_lhapdf.write_lhapdf_grid" class="md-nav__link">
    <span class="md-ellipsis">
      write_lhapdf_grid
    </span>
  </a>
  
    <nav class="md-nav" aria-label="write_lhapdf_grid">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.write_all_pdfs_to_lhapdf.write_lhapdf_grid--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters:
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.write_all_pdfs_to_lhapdf.write_lhapdf_grid--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes:
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-and-reading" class="md-nav__link">
    <span class="md-ellipsis">
      🧪 Data and Reading
    </span>
  </a>
  
    <nav class="md-nav" aria-label="🧪 Data and Reading">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mc_data_repspy" class="md-nav__link">
    <span class="md-ellipsis">
      MC_data_reps.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.MC_data_reps" class="md-nav__link">
    <span class="md-ellipsis">
      MC_data_reps
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.MC_data_reps.generate_MC_replicas" class="md-nav__link">
    <span class="md-ellipsis">
      generate_MC_replicas
    </span>
  </a>
  
    <nav class="md-nav" aria-label="generate_MC_replicas">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#read_faserv_pdfpy" class="md-nav__link">
    <span class="md-ellipsis">
      read_faserv_pdf.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.read_faserv_pdf" class="md-nav__link">
    <span class="md-ellipsis">
      read_faserv_pdf
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.read_faserv_pdf.read_pdf" class="md-nav__link">
    <span class="md-ellipsis">
      read_pdf
    </span>
  </a>
  
    <nav class="md-nav" aria-label="read_pdf">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.read_faserv_pdf.read_pdf--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.read_faserv_pdf.read_pdf--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#read_fk_tablepy" class="md-nav__link">
    <span class="md-ellipsis">
      read_fk_table.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.read_fk_table" class="md-nav__link">
    <span class="md-ellipsis">
      read_fk_table
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.read_fk_table.get_fk_table" class="md-nav__link">
    <span class="md-ellipsis">
      get_fk_table
    </span>
  </a>
  
    <nav class="md-nav" aria-label="get_fk_table">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.read_fk_table.get_fk_table--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.read_fk_table.get_fk_table--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#help_read_filespy" class="md-nav__link">
    <span class="md-ellipsis">
      help_read_files.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.help_read_files" class="md-nav__link">
    <span class="md-ellipsis">
      help_read_files
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#post-fit-analysis" class="md-nav__link">
    <span class="md-ellipsis">
      📊 Post-Fit Analysis
    </span>
  </a>
  
    <nav class="md-nav" aria-label="📊 Post-Fit Analysis">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#postfit_criteriapy" class="md-nav__link">
    <span class="md-ellipsis">
      postfit_criteria.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.postfit_criteria" class="md-nav__link">
    <span class="md-ellipsis">
      postfit_criteria
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.postfit_criteria.Postfit" class="md-nav__link">
    <span class="md-ellipsis">
      Postfit
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Postfit">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_criteria.Postfit.apply_postfit_criteria" class="md-nav__link">
    <span class="md-ellipsis">
      apply_postfit_criteria
    </span>
  </a>
  
    <nav class="md-nav" aria-label="apply_postfit_criteria">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_criteria.Postfit.apply_postfit_criteria--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_criteria.Postfit.apply_postfit_criteria--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_criteria.Postfit.apply_postfit_criteria--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#postfit_measurespy" class="md-nav__link">
    <span class="md-ellipsis">
      postfit_measures.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures" class="md-nav__link">
    <span class="md-ellipsis">
      postfit_measures
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures" class="md-nav__link">
    <span class="md-ellipsis">
      Measures
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Measures">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.N_event_pred" class="md-nav__link">
    <span class="md-ellipsis">
      N_event_pred
    </span>
  </a>
  
    <nav class="md-nav" aria-label="N_event_pred">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.N_event_pred--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_accuracy" class="md-nav__link">
    <span class="md-ellipsis">
      compute_accuracy
    </span>
  </a>
  
    <nav class="md-nav" aria-label="compute_accuracy">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_accuracy--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_accuracy--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_bias_to_variance" class="md-nav__link">
    <span class="md-ellipsis">
      compute_bias_to_variance
    </span>
  </a>
  
    <nav class="md-nav" aria-label="compute_bias_to_variance">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_bias_to_variance--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_bias_to_variance--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_delta_chi" class="md-nav__link">
    <span class="md-ellipsis">
      compute_delta_chi
    </span>
  </a>
  
    <nav class="md-nav" aria-label="compute_delta_chi">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_delta_chi--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_delta_chi--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_phi" class="md-nav__link">
    <span class="md-ellipsis">
      compute_phi
    </span>
  </a>
  
    <nav class="md-nav" aria-label="compute_phi">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_phi--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.postfit_measures.Measures.compute_phi--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pullpy" class="md-nav__link">
    <span class="md-ellipsis">
      pull.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.pull" class="md-nav__link">
    <span class="md-ellipsis">
      pull
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.pull.compute_pull" class="md-nav__link">
    <span class="md-ellipsis">
      compute_pull
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#miscellaneous-modules" class="md-nav__link">
    <span class="md-ellipsis">
      🧬 Miscellaneous Modules
    </span>
  </a>
  
    <nav class="md-nav" aria-label="🧬 Miscellaneous Modules">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#form_loss_fctpy" class="md-nav__link">
    <span class="md-ellipsis">
      form_loss_fct.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct" class="md-nav__link">
    <span class="md-ellipsis">
      form_loss_fct
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.complete_loss_fct_comb" class="md-nav__link">
    <span class="md-ellipsis">
      complete_loss_fct_comb
    </span>
  </a>
  
    <nav class="md-nav" aria-label="complete_loss_fct_comb">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.complete_loss_fct_comb--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.complete_loss_fct_comb--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.complete_loss_fct_nu_nub" class="md-nav__link">
    <span class="md-ellipsis">
      complete_loss_fct_nu_nub
    </span>
  </a>
  
    <nav class="md-nav" aria-label="complete_loss_fct_nu_nub">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.complete_loss_fct_nu_nub--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.complete_loss_fct_nu_nub--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.raw_loss_fct" class="md-nav__link">
    <span class="md-ellipsis">
      raw_loss_fct
    </span>
  </a>
  
    <nav class="md-nav" aria-label="raw_loss_fct">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.raw_loss_fct--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.form_loss_fct.raw_loss_fct--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#generate_datapy" class="md-nav__link">
    <span class="md-ellipsis">
      generate_data.py
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.generate_data" class="md-nav__link">
    <span class="md-ellipsis">
      generate_data
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.generate_data.aggregate_entries_with_indices" class="md-nav__link">
    <span class="md-ellipsis">
      aggregate_entries_with_indices
    </span>
  </a>
  
    <nav class="md-nav" aria-label="aggregate_entries_with_indices">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.aggregate_entries_with_indices--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.aggregate_entries_with_indices--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.aggregate_entries_with_indices--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.generate_data.compute_pseudo_data" class="md-nav__link">
    <span class="md-ellipsis">
      compute_pseudo_data
    </span>
  </a>
  
    <nav class="md-nav" aria-label="compute_pseudo_data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.compute_pseudo_data--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.compute_pseudo_data--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.compute_pseudo_data--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#NN_fit.generate_data.write_data" class="md-nav__link">
    <span class="md-ellipsis">
      write_data
    </span>
  </a>
  
    <nav class="md-nav" aria-label="write_data">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.write_data--parameters" class="md-nav__link">
    <span class="md-ellipsis">
      Parameters
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.write_data--returns" class="md-nav__link">
    <span class="md-ellipsis">
      Returns
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.write_data--output-files" class="md-nav__link">
    <span class="md-ellipsis">
      Output Files
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#NN_fit.generate_data.write_data--notes" class="md-nav__link">
    <span class="md-ellipsis">
      Notes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#datayaml-fit_settingsyaml-aall_fits-runcards-etc" class="md-nav__link">
    <span class="md-ellipsis">
      data.yaml, fit_settings.yaml, aall_fits/, runcards/, etc.
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="api-reference">📘 API Reference<a class="headerlink" href="#api-reference" title="Permanent link">&para;</a></h1>
<p>Welcome to the full API reference for the <code>NN_fit</code> package. Below you’ll find organized documentation for all modules in the codebase, including classes, functions, and docstrings.</p>
<hr />
<h2 id="core-fitting-modules">🔧 Core Fitting Modules<a class="headerlink" href="#core-fitting-modules" title="Permanent link">&para;</a></h2>
<h3 id="perform_fit_combpy"><code>perform_fit_comb.py</code><a class="headerlink" href="#perform_fit_combpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.perform_fit_comb"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h2 id="NN_fit.perform_fit_comb.perform_fit" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">perform_fit</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">num_reps</span><span class="p">,</span> <span class="n">range_alpha</span><span class="p">,</span> <span class="n">range_beta</span><span class="p">,</span> <span class="n">range_gamma</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="p">,</span> <span class="n">patience</span><span class="p">,</span> <span class="n">x_alphas</span><span class="p">,</span> <span class="n">fk_tables</span><span class="p">,</span> <span class="n">binwidths</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="p">,</span> <span class="n">extended_loss</span><span class="p">,</span> <span class="n">activation_function</span><span class="p">,</span> <span class="n">num_input_layers</span><span class="p">,</span> <span class="n">num_output_layers</span><span class="p">,</span> <span class="n">hidden_layers</span><span class="p">,</span> <span class="n">x_vals</span><span class="p">,</span> <span class="n">preproc</span><span class="p">,</span> <span class="n">validation_split</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">,</span> <span class="n">max_chi_sq</span><span class="p">,</span> <span class="n">lag_mult_pos</span><span class="p">,</span> <span class="n">lag_mult_int</span><span class="p">,</span> <span class="n">x_int</span><span class="p">)</span></code>

<a href="#NN_fit.perform_fit_comb.perform_fit" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Performs repeated training of neural networks to fit pseudo-data predictions using a
physics-constrained loss function and neural PDF parameterization.</p>
<p>Each replica (<code>num_reps</code>) of the prediction is fitted using a randomly initialized
neural network (based on PreprocessedMLP), and the corresponding predictions and losses
are recorded. Optionally uses a validation split.</p>
<h4 id="NN_fit.perform_fit_comb.perform_fit--parameters">Parameters<a class="headerlink" href="#NN_fit.perform_fit_comb.perform_fit--parameters" title="Permanent link">&para;</a></h4>
<p>pred : list of np.ndarray
    List of length <code>num_reps</code>, each containing the pseudo-data event predictions.
num_reps : int
    Number of replicas (i.e., independent fits with random initialization).
range_alpha : float
    Upper bound for uniform sampling of <code>alpha</code> preprocessing parameter.
range_beta : float
    Upper bound for uniform sampling of <code>beta</code> preprocessing parameter.
range_gamma : float
    Upper bound for uniform sampling of <code>gamma</code> preprocessing parameter.
lr : float
    Learning rate for the Adam optimizer.
wd : float
    Weight decay (L2 regularization) for the optimizer.
patience : int
    Early stopping patience (currently unused but declared).
x_alphas : torch.Tensor
    Input x-values used to evaluate PDF predictions for data loss.
fk_tables : torch.Tensor
    FastKernel tables to convert PDFs into observable space.
binwidths : torch.Tensor
    Widths of each bin used in rebinning the predictions.
cov_matrix : np.ndarray
    Covariance matrix used for weighted loss calculation.
extended_loss : bool
    If True, uses extended loss with constraints (e.g., normalization, positivity).
activation_function : str
    Activation function used in the neural network (e.g., 'relu', 'tanh').
num_input_layers : int
    Number of input layers before hidden layers.
num_output_layers : int
    Number of output layers after hidden layers.
hidden_layers : list of int
    Number of neurons in each hidden layer.
x_vals : np.ndarray
    x-values used to store final fitted PDFs.
preproc : str
    Type of preprocessing function (e.g., 'powerlaw', 'exp') applied to PDFs.
validation_split : float
    Fraction of data used for validation (between 0 and 1).
max_epochs : int
    Maximum number of training epochs.
max_chi_sq : float
    Maximum allowed chi-squared for a fit to be accepted.
lag_mult_pos : float
    Lagrange multiplier for positivity constraint.
lag_mult_int : float
    Lagrange multiplier for integral constraint.
x_int : np.ndarray
    x-values used for computing integral constraints.</p>
<h4 id="NN_fit.perform_fit_comb.perform_fit--returns">Returns<a class="headerlink" href="#NN_fit.perform_fit_comb.perform_fit--returns" title="Permanent link">&para;</a></h4>
<p>chi_squares : list of float
    Training loss (chi-squared) values saved periodically during training.
N_event_pred : list of np.ndarray
    Predicted event yields after applying the FastKernel convolution.
neutrino_pdfs : list of np.ndarray
    Final predicted PDFs (postprocessed) from successful fits.
model : PreprocessedMLP
    Final trained model (from last accepted fit).
chi_square_for_postfit : list of float
    Final chi-squared values for each accepted fit (for post-fit evaluation).
train_indices : np.ndarray
    Indices used for training set in the last run (if validation was used).
val_indices : np.ndarray
    Indices used for validation set in the last run (if validation was used).
training_length : int
    Number of training steps run in the final (last) model.</p>
<h4 id="NN_fit.perform_fit_comb.perform_fit--notes">Notes<a class="headerlink" href="#NN_fit.perform_fit_comb.perform_fit--notes" title="Permanent link">&para;</a></h4>
<ul>
<li>Only models with <code>loss &lt; max_chi_sq</code> are retained in the final output.</li>
<li>The PDFs are preprocessed using a parameterized function with random α, β, γ values.</li>
<li>Assumes the model class <code>PreprocessedMLP</code> and loss class <code>CustomLoss</code> are defined externally.</li>
<li>Model and predictions use PyTorch; inputs must be tensors where appropriate.</li>
<li>Currently no explicit early stopping logic is implemented (but patience is reserved).</li>
</ul>


            <details class="quote">
              <summary>Source code in <code>NN_fit/perform_fit_comb.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">perform_fit</span><span class="p">(</span>
    <span class="n">pred</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">num_reps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">range_alpha</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">range_beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">range_gamma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">wd</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">x_alphas</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">fk_tables</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">binwidths</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">cov_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">extended_loss</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">activation_function</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">num_input_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_output_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">hidden_layers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">x_vals</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">preproc</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">max_chi_sq</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">lag_mult_pos</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">lag_mult_int</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">x_int</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
    <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>  <span class="c1"># chi_squares</span>
    <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>  <span class="c1"># N_event_pred</span>
    <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>  <span class="c1"># neutrino_pdfs</span>
    <span class="n">PreprocessedMLP</span><span class="p">,</span>  <span class="c1"># model (last accepted fit)</span>
    <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>  <span class="c1"># chi_square_for_postfit</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># train_indices</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># val_indices</span>
    <span class="nb">int</span><span class="p">,</span>  <span class="c1"># training_length</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs repeated training of neural networks to fit pseudo-data predictions using a</span>
<span class="sd">    physics-constrained loss function and neural PDF parameterization.</span>

<span class="sd">    Each replica (`num_reps`) of the prediction is fitted using a randomly initialized</span>
<span class="sd">    neural network (based on PreprocessedMLP), and the corresponding predictions and losses</span>
<span class="sd">    are recorded. Optionally uses a validation split.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pred : list of np.ndarray</span>
<span class="sd">        List of length `num_reps`, each containing the pseudo-data event predictions.</span>
<span class="sd">    num_reps : int</span>
<span class="sd">        Number of replicas (i.e., independent fits with random initialization).</span>
<span class="sd">    range_alpha : float</span>
<span class="sd">        Upper bound for uniform sampling of `alpha` preprocessing parameter.</span>
<span class="sd">    range_beta : float</span>
<span class="sd">        Upper bound for uniform sampling of `beta` preprocessing parameter.</span>
<span class="sd">    range_gamma : float</span>
<span class="sd">        Upper bound for uniform sampling of `gamma` preprocessing parameter.</span>
<span class="sd">    lr : float</span>
<span class="sd">        Learning rate for the Adam optimizer.</span>
<span class="sd">    wd : float</span>
<span class="sd">        Weight decay (L2 regularization) for the optimizer.</span>
<span class="sd">    patience : int</span>
<span class="sd">        Early stopping patience (currently unused but declared).</span>
<span class="sd">    x_alphas : torch.Tensor</span>
<span class="sd">        Input x-values used to evaluate PDF predictions for data loss.</span>
<span class="sd">    fk_tables : torch.Tensor</span>
<span class="sd">        FastKernel tables to convert PDFs into observable space.</span>
<span class="sd">    binwidths : torch.Tensor</span>
<span class="sd">        Widths of each bin used in rebinning the predictions.</span>
<span class="sd">    cov_matrix : np.ndarray</span>
<span class="sd">        Covariance matrix used for weighted loss calculation.</span>
<span class="sd">    extended_loss : bool</span>
<span class="sd">        If True, uses extended loss with constraints (e.g., normalization, positivity).</span>
<span class="sd">    activation_function : str</span>
<span class="sd">        Activation function used in the neural network (e.g., &#39;relu&#39;, &#39;tanh&#39;).</span>
<span class="sd">    num_input_layers : int</span>
<span class="sd">        Number of input layers before hidden layers.</span>
<span class="sd">    num_output_layers : int</span>
<span class="sd">        Number of output layers after hidden layers.</span>
<span class="sd">    hidden_layers : list of int</span>
<span class="sd">        Number of neurons in each hidden layer.</span>
<span class="sd">    x_vals : np.ndarray</span>
<span class="sd">        x-values used to store final fitted PDFs.</span>
<span class="sd">    preproc : str</span>
<span class="sd">        Type of preprocessing function (e.g., &#39;powerlaw&#39;, &#39;exp&#39;) applied to PDFs.</span>
<span class="sd">    validation_split : float</span>
<span class="sd">        Fraction of data used for validation (between 0 and 1).</span>
<span class="sd">    max_epochs : int</span>
<span class="sd">        Maximum number of training epochs.</span>
<span class="sd">    max_chi_sq : float</span>
<span class="sd">        Maximum allowed chi-squared for a fit to be accepted.</span>
<span class="sd">    lag_mult_pos : float</span>
<span class="sd">        Lagrange multiplier for positivity constraint.</span>
<span class="sd">    lag_mult_int : float</span>
<span class="sd">        Lagrange multiplier for integral constraint.</span>
<span class="sd">    x_int : np.ndarray</span>
<span class="sd">        x-values used for computing integral constraints.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    chi_squares : list of float</span>
<span class="sd">        Training loss (chi-squared) values saved periodically during training.</span>
<span class="sd">    N_event_pred : list of np.ndarray</span>
<span class="sd">        Predicted event yields after applying the FastKernel convolution.</span>
<span class="sd">    neutrino_pdfs : list of np.ndarray</span>
<span class="sd">        Final predicted PDFs (postprocessed) from successful fits.</span>
<span class="sd">    model : PreprocessedMLP</span>
<span class="sd">        Final trained model (from last accepted fit).</span>
<span class="sd">    chi_square_for_postfit : list of float</span>
<span class="sd">        Final chi-squared values for each accepted fit (for post-fit evaluation).</span>
<span class="sd">    train_indices : np.ndarray</span>
<span class="sd">        Indices used for training set in the last run (if validation was used).</span>
<span class="sd">    val_indices : np.ndarray</span>
<span class="sd">        Indices used for validation set in the last run (if validation was used).</span>
<span class="sd">    training_length : int</span>
<span class="sd">        Number of training steps run in the final (last) model.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - Only models with `loss &lt; max_chi_sq` are retained in the final output.</span>
<span class="sd">    - The PDFs are preprocessed using a parameterized function with random α, β, γ values.</span>
<span class="sd">    - Assumes the model class `PreprocessedMLP` and loss class `CustomLoss` are defined externally.</span>
<span class="sd">    - Model and predictions use PyTorch; inputs must be tensors where appropriate.</span>
<span class="sd">    - Currently no explicit early stopping logic is implemented (but patience is reserved).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="p">(</span>
        <span class="n">neutrino_pdfs</span><span class="p">,</span>
        <span class="n">N_event_pred</span><span class="p">,</span>
        <span class="n">chi_squares</span><span class="p">,</span>
        <span class="n">preproc_pdfs</span><span class="p">,</span>
        <span class="n">nn_pdfs</span><span class="p">,</span>
        <span class="n">chi_square_for_postfit</span><span class="p">,</span>
        <span class="n">val_losses</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="n">x_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">x_int</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_int</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_reps</span><span class="p">):</span>
        <span class="n">training_length</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">best_loss</span> <span class="o">=</span> <span class="mf">1e13</span>  <span class="c1"># initial loss</span>
        <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="n">range_alpha</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="n">range_beta</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="n">range_gamma</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">PreprocessedMLP</span><span class="p">(</span>
            <span class="n">alpha</span><span class="p">,</span>
            <span class="n">beta</span><span class="p">,</span>
            <span class="n">gamma</span><span class="p">,</span>
            <span class="n">activation_function</span><span class="p">,</span>
            <span class="n">hidden_layers</span><span class="p">,</span>
            <span class="n">num_input_layers</span><span class="p">,</span>
            <span class="n">num_output_layers</span><span class="p">,</span>
            <span class="n">preproc</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">criterion</span> <span class="o">=</span> <span class="n">CustomLoss</span><span class="p">(</span>
            <span class="n">extended_loss</span><span class="p">,</span>
            <span class="n">num_output_layers</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">wd</span><span class="p">)</span>

        <span class="n">dataset_size</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">dataset_size</span><span class="p">)</span>

        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
        <span class="n">val_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dataset_size</span> <span class="o">*</span> <span class="n">validation_split</span><span class="p">)</span>

        <span class="n">train_indices</span><span class="p">,</span> <span class="n">val_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">val_size</span><span class="p">:],</span> <span class="n">indices</span><span class="p">[:</span><span class="n">val_size</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">validation_split</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">pred_train</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">train_indices</span><span class="p">]</span>
            <span class="n">cov_matrix_train</span> <span class="o">=</span> <span class="n">cov_matrix</span><span class="p">[</span><span class="n">train_indices</span><span class="p">][:,</span> <span class="n">train_indices</span><span class="p">]</span>
            <span class="n">cov_matrix_val</span> <span class="o">=</span> <span class="n">cov_matrix</span><span class="p">[</span><span class="n">val_indices</span><span class="p">][:,</span> <span class="n">val_indices</span><span class="p">]</span>
            <span class="n">pred_val</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">val_indices</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

        <span class="k">while</span> <span class="n">counter</span> <span class="o">&lt;</span> <span class="n">max_epochs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">max_epochs</span> <span class="o">&lt;</span> <span class="n">training_length</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="n">training_length</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_alphas</span><span class="p">)</span>

            <span class="n">y_preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">fk_tables</span><span class="p">,</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span> <span class="o">*</span> <span class="n">binwidths</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

            <span class="n">y_preds</span> <span class="o">=</span> <span class="n">y_preds</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

            <span class="n">y_int_mu</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_int</span><span class="p">)</span>
            <span class="n">y_int_mub</span> <span class="o">=</span> <span class="n">y_int_mu</span>

            <span class="k">if</span> <span class="n">validation_split</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
                <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_preds</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span>
                <span class="n">y_val</span> <span class="o">=</span> <span class="n">y_preds</span><span class="p">[</span><span class="n">val_indices</span><span class="p">]</span>

                <span class="n">loss_val</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
                    <span class="n">y_val</span><span class="p">,</span>
                    <span class="n">pred_val</span><span class="p">,</span>
                    <span class="n">cov_matrix_val</span><span class="p">,</span>
                    <span class="n">y_pred</span><span class="p">,</span>
                    <span class="n">y_int_mu</span><span class="p">,</span>
                    <span class="n">y_int_mub</span><span class="p">,</span>
                    <span class="n">x_int</span><span class="p">,</span>
                    <span class="n">lag_mult_pos</span><span class="p">,</span>
                    <span class="n">lag_mult_int</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
                    <span class="n">y_train</span><span class="p">,</span>
                    <span class="n">pred_train</span><span class="p">,</span>
                    <span class="n">cov_matrix_train</span><span class="p">,</span>
                    <span class="n">y_pred</span><span class="p">,</span>
                    <span class="n">y_int_mu</span><span class="p">,</span>
                    <span class="n">y_int_mub</span><span class="p">,</span>
                    <span class="n">x_int</span><span class="p">,</span>
                    <span class="n">lag_mult_pos</span><span class="p">,</span>
                    <span class="n">lag_mult_int</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
                    <span class="n">y_preds</span><span class="p">,</span>
                    <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="n">cov_matrix</span><span class="p">,</span>
                    <span class="n">y_pred</span><span class="p">,</span>
                    <span class="n">y_int_mu</span><span class="p">,</span>
                    <span class="n">y_int_mub</span><span class="p">,</span>
                    <span class="n">x_int</span><span class="p">,</span>
                    <span class="n">lag_mult_pos</span><span class="p">,</span>
                    <span class="n">lag_mult_int</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">training_length</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">chi_squares</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                <span class="k">if</span> <span class="n">validation_split</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
                    <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_val</span><span class="p">)</span>

            <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">loss</span> <span class="o">&lt;</span> <span class="n">best_loss</span><span class="p">:</span>
                <span class="n">best_loss</span> <span class="o">=</span> <span class="n">loss</span>
                <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">loss</span> <span class="o">&lt;</span> <span class="n">max_chi_sq</span><span class="p">:</span>
            <span class="n">f_nu</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_vals</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

            <span class="n">chi_square_for_postfit</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

            <span class="n">preproc_pdfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">preproces</span><span class="p">(</span><span class="n">x_vals</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">nn_pdf</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">neuralnet</span><span class="p">(</span><span class="n">x_vals</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">nn_pdfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn_pdf</span><span class="p">)</span>

            <span class="n">N_event_pred</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_preds</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

            <span class="n">neutrino_pdfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f_nu</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="n">chi_squares</span><span class="p">,</span>
        <span class="n">N_event_pred</span><span class="p">,</span>
        <span class="n">neutrino_pdfs</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">chi_square_for_postfit</span><span class="p">,</span>
        <span class="n">train_indices</span><span class="p">,</span>
        <span class="n">val_indices</span><span class="p">,</span>
        <span class="n">training_length</span><span class="p">,</span>
        <span class="n">val_losses</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><h3 id="perform_fit_nu_nubpy"><code>perform_fit_nu_nub.py</code><a class="headerlink" href="#perform_fit_nu_nubpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.perform_fit_nu_nub"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h2 id="NN_fit.perform_fit_nu_nub.perform_fit" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">perform_fit</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">num_reps</span><span class="p">,</span> <span class="n">range_alpha</span><span class="p">,</span> <span class="n">range_beta</span><span class="p">,</span> <span class="n">range_gamma</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="p">,</span> <span class="n">patience</span><span class="p">,</span> <span class="n">x_alphas</span><span class="p">,</span> <span class="n">fk_tables_mu</span><span class="p">,</span> <span class="n">fk_tables_mub</span><span class="p">,</span> <span class="n">binwidths_mu</span><span class="p">,</span> <span class="n">binwidths_mub</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="p">,</span> <span class="n">extended_loss</span><span class="p">,</span> <span class="n">activation_function</span><span class="p">,</span> <span class="n">num_input_layers</span><span class="p">,</span> <span class="n">num_output_layers</span><span class="p">,</span> <span class="n">hidden_layers</span><span class="p">,</span> <span class="n">x_vals</span><span class="p">,</span> <span class="n">preproc</span><span class="p">,</span> <span class="n">validation_split</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">,</span> <span class="n">max_chi_sq</span><span class="p">,</span> <span class="n">fit_faser_data</span><span class="p">,</span> <span class="n">lag_mult_pos</span><span class="p">,</span> <span class="n">lag_mult_int</span><span class="p">,</span> <span class="n">x_int</span><span class="p">)</span></code>

<a href="#NN_fit.perform_fit_nu_nub.perform_fit" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Performs repeated training of neural networks to fit pseudo-data predictions using a
physics-constrained loss function and neural PDF parameterization.</p>
<p>Each replica (<code>num_reps</code>) of the prediction is fitted using a randomly initialized
neural network (based on PreprocessedMLP), and the corresponding predictions and losses
are recorded. Optionally uses a validation split.</p>
<h4 id="NN_fit.perform_fit_nu_nub.perform_fit--parameters">Parameters<a class="headerlink" href="#NN_fit.perform_fit_nu_nub.perform_fit--parameters" title="Permanent link">&para;</a></h4>
<p>pred : list of np.ndarray
    List of length <code>num_reps</code>, each containing the pseudo-data event predictions.
num_reps : int
    Number of replicas (i.e., independent fits with random initialization).
range_alpha : float
    Upper bound for uniform sampling of <code>alpha</code> preprocessing parameter.
range_beta : float
    Upper bound for uniform sampling of <code>beta</code> preprocessing parameter.
range_gamma : float
    Upper bound for uniform sampling of <code>gamma</code> preprocessing parameter.
lr : float
    Learning rate for the Adam optimizer.
wd : float
    Weight decay (L2 regularization) for the optimizer.
patience : int
    Early stopping patience (currently unused but declared).
x_alphas : torch.Tensor
    Input x-values used to evaluate PDF predictions for data loss.
fk_tables : torch.Tensor
    FastKernel tables to convert PDFs into observable space.
binwidths : torch.Tensor
    Widths of each bin used in rebinning the predictions.
cov_matrix : np.ndarray
    Covariance matrix used for weighted loss calculation.
extended_loss : bool
    If True, uses extended loss with constraints (e.g., normalization, positivity).
activation_function : str
    Activation function used in the neural network (e.g., 'relu', 'tanh').
num_input_layers : int
    Number of input layers before hidden layers.
num_output_layers : int
    Number of output layers after hidden layers.
hidden_layers : list of int
    Number of neurons in each hidden layer.
x_vals : np.ndarray
    x-values used to store final fitted PDFs.
preproc : str
    Type of preprocessing function (e.g., 'powerlaw', 'exp') applied to PDFs.
validation_split : float
    Fraction of data used for validation (between 0 and 1).
max_epochs : int
    Maximum number of training epochs.
max_chi_sq : float
    Maximum allowed chi-squared for a fit to be accepted.
lag_mult_pos : float
    Lagrange multiplier for positivity constraint.
lag_mult_int : float
    Lagrange multiplier for integral constraint.
x_int : np.ndarray
    x-values used for computing integral constraints.</p>
<h4 id="NN_fit.perform_fit_nu_nub.perform_fit--returns">Returns<a class="headerlink" href="#NN_fit.perform_fit_nu_nub.perform_fit--returns" title="Permanent link">&para;</a></h4>
<p>chi_squares : list of float
    Training loss (chi-squared) values saved periodically during training.
N_event_pred : list of np.ndarray
    Predicted event yields after applying the FastKernel convolution.
neutrino_pdfs : list of np.ndarray
    Final predicted PDFs (postprocessed) from successful fits.
model : PreprocessedMLP
    Final trained model (from last accepted fit).
chi_square_for_postfit : list of float
    Final chi-squared values for each accepted fit (for post-fit evaluation).
train_indices : np.ndarray
    Indices used for training set in the last run (if validation was used).
val_indices : np.ndarray
    Indices used for validation set in the last run (if validation was used).
training_length : int
    Number of training steps run in the final (last) model.</p>
<h4 id="NN_fit.perform_fit_nu_nub.perform_fit--notes">Notes<a class="headerlink" href="#NN_fit.perform_fit_nu_nub.perform_fit--notes" title="Permanent link">&para;</a></h4>
<ul>
<li>Only models with <code>loss &lt; max_chi_sq</code> are retained in the final output.</li>
<li>The PDFs are preprocessed using a parameterized function with random α, β, γ values.</li>
<li>Assumes the model class <code>PreprocessedMLP</code> and loss class <code>CustomLoss</code> are defined externally.</li>
<li>Model and predictions use PyTorch; inputs must be tensors where appropriate.</li>
<li>Currently no explicit early stopping logic is implemented (but patience is reserved).</li>
</ul>


            <details class="quote">
              <summary>Source code in <code>NN_fit/perform_fit_nu_nub.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">perform_fit</span><span class="p">(</span>
    <span class="n">pred</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">num_reps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">range_alpha</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">range_beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">range_gamma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">wd</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">x_alphas</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">fk_tables_mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">fk_tables_mub</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">binwidths_mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">binwidths_mub</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">cov_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">extended_loss</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">activation_function</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">num_input_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_output_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">hidden_layers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">x_vals</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">preproc</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">max_chi_sq</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">fit_faser_data</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">lag_mult_pos</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">lag_mult_int</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">x_int</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
    <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>  <span class="c1"># chi_squares</span>
    <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>  <span class="c1"># N_event_pred_mu</span>
    <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>  <span class="c1"># N_event_pred_mub</span>
    <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>  <span class="c1"># neutrino_pdfs_mu</span>
    <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>  <span class="c1"># neutrino_pdfs_mub</span>
    <span class="n">PreprocessedMLP</span><span class="p">,</span>  <span class="c1"># model (last accepted fit)</span>
    <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>  <span class="c1"># chi_square_for_postfit</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># train_indices</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># val_indices</span>
    <span class="nb">int</span><span class="p">,</span>  <span class="c1"># training_length</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs repeated training of neural networks to fit pseudo-data predictions using a</span>
<span class="sd">    physics-constrained loss function and neural PDF parameterization.</span>

<span class="sd">    Each replica (`num_reps`) of the prediction is fitted using a randomly initialized</span>
<span class="sd">    neural network (based on PreprocessedMLP), and the corresponding predictions and losses</span>
<span class="sd">    are recorded. Optionally uses a validation split.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pred : list of np.ndarray</span>
<span class="sd">        List of length `num_reps`, each containing the pseudo-data event predictions.</span>
<span class="sd">    num_reps : int</span>
<span class="sd">        Number of replicas (i.e., independent fits with random initialization).</span>
<span class="sd">    range_alpha : float</span>
<span class="sd">        Upper bound for uniform sampling of `alpha` preprocessing parameter.</span>
<span class="sd">    range_beta : float</span>
<span class="sd">        Upper bound for uniform sampling of `beta` preprocessing parameter.</span>
<span class="sd">    range_gamma : float</span>
<span class="sd">        Upper bound for uniform sampling of `gamma` preprocessing parameter.</span>
<span class="sd">    lr : float</span>
<span class="sd">        Learning rate for the Adam optimizer.</span>
<span class="sd">    wd : float</span>
<span class="sd">        Weight decay (L2 regularization) for the optimizer.</span>
<span class="sd">    patience : int</span>
<span class="sd">        Early stopping patience (currently unused but declared).</span>
<span class="sd">    x_alphas : torch.Tensor</span>
<span class="sd">        Input x-values used to evaluate PDF predictions for data loss.</span>
<span class="sd">    fk_tables : torch.Tensor</span>
<span class="sd">        FastKernel tables to convert PDFs into observable space.</span>
<span class="sd">    binwidths : torch.Tensor</span>
<span class="sd">        Widths of each bin used in rebinning the predictions.</span>
<span class="sd">    cov_matrix : np.ndarray</span>
<span class="sd">        Covariance matrix used for weighted loss calculation.</span>
<span class="sd">    extended_loss : bool</span>
<span class="sd">        If True, uses extended loss with constraints (e.g., normalization, positivity).</span>
<span class="sd">    activation_function : str</span>
<span class="sd">        Activation function used in the neural network (e.g., &#39;relu&#39;, &#39;tanh&#39;).</span>
<span class="sd">    num_input_layers : int</span>
<span class="sd">        Number of input layers before hidden layers.</span>
<span class="sd">    num_output_layers : int</span>
<span class="sd">        Number of output layers after hidden layers.</span>
<span class="sd">    hidden_layers : list of int</span>
<span class="sd">        Number of neurons in each hidden layer.</span>
<span class="sd">    x_vals : np.ndarray</span>
<span class="sd">        x-values used to store final fitted PDFs.</span>
<span class="sd">    preproc : str</span>
<span class="sd">        Type of preprocessing function (e.g., &#39;powerlaw&#39;, &#39;exp&#39;) applied to PDFs.</span>
<span class="sd">    validation_split : float</span>
<span class="sd">        Fraction of data used for validation (between 0 and 1).</span>
<span class="sd">    max_epochs : int</span>
<span class="sd">        Maximum number of training epochs.</span>
<span class="sd">    max_chi_sq : float</span>
<span class="sd">        Maximum allowed chi-squared for a fit to be accepted.</span>
<span class="sd">    lag_mult_pos : float</span>
<span class="sd">        Lagrange multiplier for positivity constraint.</span>
<span class="sd">    lag_mult_int : float</span>
<span class="sd">        Lagrange multiplier for integral constraint.</span>
<span class="sd">    x_int : np.ndarray</span>
<span class="sd">        x-values used for computing integral constraints.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    chi_squares : list of float</span>
<span class="sd">        Training loss (chi-squared) values saved periodically during training.</span>
<span class="sd">    N_event_pred : list of np.ndarray</span>
<span class="sd">        Predicted event yields after applying the FastKernel convolution.</span>
<span class="sd">    neutrino_pdfs : list of np.ndarray</span>
<span class="sd">        Final predicted PDFs (postprocessed) from successful fits.</span>
<span class="sd">    model : PreprocessedMLP</span>
<span class="sd">        Final trained model (from last accepted fit).</span>
<span class="sd">    chi_square_for_postfit : list of float</span>
<span class="sd">        Final chi-squared values for each accepted fit (for post-fit evaluation).</span>
<span class="sd">    train_indices : np.ndarray</span>
<span class="sd">        Indices used for training set in the last run (if validation was used).</span>
<span class="sd">    val_indices : np.ndarray</span>
<span class="sd">        Indices used for validation set in the last run (if validation was used).</span>
<span class="sd">    training_length : int</span>
<span class="sd">        Number of training steps run in the final (last) model.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - Only models with `loss &lt; max_chi_sq` are retained in the final output.</span>
<span class="sd">    - The PDFs are preprocessed using a parameterized function with random α, β, γ values.</span>
<span class="sd">    - Assumes the model class `PreprocessedMLP` and loss class `CustomLoss` are defined externally.</span>
<span class="sd">    - Model and predictions use PyTorch; inputs must be tensors where appropriate.</span>
<span class="sd">    - Currently no explicit early stopping logic is implemented (but patience is reserved).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="p">(</span>
        <span class="n">neutrino_pdfs_mu</span><span class="p">,</span>
        <span class="n">neutrino_pdfs_mub</span><span class="p">,</span>
        <span class="n">N_event_pred_mu</span><span class="p">,</span>
        <span class="n">N_event_pred_mub</span><span class="p">,</span>
        <span class="n">chi_squares</span><span class="p">,</span>
        <span class="n">preproc_pdfs</span><span class="p">,</span>
        <span class="n">nn_pdfs</span><span class="p">,</span>
        <span class="n">chi_square_for_postfit</span><span class="p">,</span>
        <span class="n">val_losses</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">[],</span>
        <span class="p">[],</span>
        <span class="p">[],</span>
        <span class="p">[],</span>
        <span class="p">[],</span>
        <span class="p">[],</span>
        <span class="p">[],</span>
        <span class="p">[],</span>
        <span class="p">[],</span>
    <span class="p">)</span>
    <span class="n">x_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">x_int</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_int</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">training_length</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_reps</span><span class="p">):</span>
        <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="n">range_alpha</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="n">range_beta</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="n">range_gamma</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">PreprocessedMLP</span><span class="p">(</span>
            <span class="n">alpha</span><span class="p">,</span>
            <span class="n">beta</span><span class="p">,</span>
            <span class="n">gamma</span><span class="p">,</span>
            <span class="n">activation_function</span><span class="p">,</span>
            <span class="n">hidden_layers</span><span class="p">,</span>
            <span class="n">num_input_layers</span><span class="p">,</span>
            <span class="n">num_output_layers</span><span class="p">,</span>
            <span class="n">preproc</span><span class="o">=</span><span class="n">preproc</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">criterion</span> <span class="o">=</span> <span class="n">CustomLoss</span><span class="p">(</span>
            <span class="n">extended_loss</span><span class="p">,</span>
            <span class="n">num_output_layers</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">wd</span><span class="p">)</span>

        <span class="n">dataset_size</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">dataset_size</span><span class="p">)</span>
        <span class="c1"># np.random.seed(seed)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
        <span class="n">val_size</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">dataset_size</span> <span class="o">*</span> <span class="n">validation_split</span><span class="p">)</span>

        <span class="n">train_indices</span><span class="p">,</span> <span class="n">val_indices</span> <span class="o">=</span> <span class="n">indices</span><span class="p">[</span><span class="n">val_size</span><span class="p">:],</span> <span class="n">indices</span><span class="p">[:</span><span class="n">val_size</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">validation_split</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">pred_train</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">train_indices</span><span class="p">]</span>
            <span class="n">cov_matrix_train</span> <span class="o">=</span> <span class="n">cov_matrix</span><span class="p">[</span><span class="n">train_indices</span><span class="p">][:,</span> <span class="n">train_indices</span><span class="p">]</span>
            <span class="n">cov_matrix_val</span> <span class="o">=</span> <span class="n">cov_matrix</span><span class="p">[</span><span class="n">val_indices</span><span class="p">][:,</span> <span class="n">val_indices</span><span class="p">]</span>
            <span class="n">pred_val</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">val_indices</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

        <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">best_loss</span> <span class="o">=</span> <span class="mf">1e13</span>
        <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">while</span> <span class="n">counter</span> <span class="o">&lt;</span> <span class="n">patience</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">max_epochs</span> <span class="o">&lt;</span> <span class="n">training_length</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">training_length</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_alphas</span><span class="p">)</span>

            <span class="n">y_pred_mu</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">fk_tables_mu</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">binwidths_mu</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="n">y_pred_mub</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">fk_tables_mub</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">binwidths_mub</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="n">y_pred_mu</span> <span class="o">=</span> <span class="n">y_pred_mu</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">y_pred_mub</span> <span class="o">=</span> <span class="n">y_pred_mub</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">fit_faser_data</span><span class="p">:</span>
                <span class="n">y_pred_mu</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">y_pred_mu</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">y_pred_mub</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">y_pred_mub</span> <span class="o">=</span> <span class="n">y_pred_mub</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

                <span class="n">y_pred_mub</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flip</span><span class="p">(</span><span class="n">y_pred_mub</span><span class="p">,</span> <span class="n">dims</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

            <span class="n">y_preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">y_pred_mu</span><span class="p">,</span> <span class="n">y_pred_mub</span><span class="p">))</span>
            <span class="c1"># y_preds = y_pred_mu + y_pred_mub  # torch hstack</span>
            <span class="c1"># y_preds = y_pred_mu</span>

            <span class="n">y_int_mu</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_int</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>
            <span class="n">y_int_mub</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_int</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_alphas</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">validation_split</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
                <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_preds</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span>
                <span class="n">y_val</span> <span class="o">=</span> <span class="n">y_preds</span><span class="p">[</span><span class="n">val_indices</span><span class="p">]</span>

                <span class="n">loss_val</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
                    <span class="n">y_val</span><span class="p">,</span>
                    <span class="n">pred_val</span><span class="p">,</span>
                    <span class="n">cov_matrix_val</span><span class="p">,</span>
                    <span class="n">y_pred</span><span class="p">,</span>
                    <span class="n">y_int_mu</span><span class="p">,</span>
                    <span class="n">y_int_mub</span><span class="p">,</span>
                    <span class="n">x_int</span><span class="p">,</span>
                    <span class="n">lag_mult_pos</span><span class="p">,</span>
                    <span class="n">lag_mult_int</span><span class="p">,</span>
                <span class="p">)</span>

                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
                    <span class="n">y_train</span><span class="p">,</span>
                    <span class="n">pred_train</span><span class="p">,</span>
                    <span class="n">cov_matrix_train</span><span class="p">,</span>
                    <span class="n">y_pred</span><span class="p">,</span>
                    <span class="n">y_int_mu</span><span class="p">,</span>
                    <span class="n">y_int_mub</span><span class="p">,</span>
                    <span class="n">x_int</span><span class="p">,</span>
                    <span class="n">lag_mult_pos</span><span class="p">,</span>
                    <span class="n">lag_mult_int</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
                    <span class="n">y_preds</span><span class="p">,</span>
                    <span class="n">pred</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
                    <span class="n">cov_matrix</span><span class="p">,</span>
                    <span class="n">y_pred</span><span class="p">,</span>
                    <span class="n">y_int_mu</span><span class="p">,</span>
                    <span class="n">y_int_mub</span><span class="p">,</span>
                    <span class="n">x_int</span><span class="p">,</span>
                    <span class="n">lag_mult_pos</span><span class="p">,</span>
                    <span class="n">lag_mult_int</span><span class="p">,</span>
                <span class="p">)</span>

            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">training_length</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">chi_squares</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                <span class="k">if</span> <span class="n">validation_split</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
                    <span class="n">val_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss_val</span><span class="p">)</span>

            <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">loss</span> <span class="o">&lt;</span> <span class="n">best_loss</span><span class="p">:</span>
                <span class="n">best_loss</span> <span class="o">=</span> <span class="n">loss</span>
                <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="k">if</span> <span class="n">loss</span> <span class="o">&lt;</span> <span class="n">max_chi_sq</span><span class="p">:</span>
            <span class="n">f_nu_mub</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_vals</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">f_nu_mu</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_vals</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>

            <span class="n">chi_square_for_postfit</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

            <span class="n">preproc_pdfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">preproces</span><span class="p">(</span><span class="n">x_vals</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">())</span>
            <span class="n">nn_pdf</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">neuralnet</span><span class="p">(</span><span class="n">x_vals</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">nn_pdfs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn_pdf</span><span class="p">)</span>

            <span class="n">N_event_pred_mu</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_pred_mu</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">N_event_pred_mub</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_pred_mub</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

            <span class="n">neutrino_pdfs_mu</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f_nu_mu</span><span class="p">)</span>
            <span class="n">neutrino_pdfs_mub</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">f_nu_mub</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">(</span>
        <span class="n">chi_squares</span><span class="p">,</span>
        <span class="n">N_event_pred_mu</span><span class="p">,</span>
        <span class="n">N_event_pred_mub</span><span class="p">,</span>
        <span class="n">neutrino_pdfs_mu</span><span class="p">,</span>
        <span class="n">neutrino_pdfs_mub</span><span class="p">,</span>
        <span class="n">model</span><span class="p">,</span>
        <span class="n">chi_square_for_postfit</span><span class="p">,</span>
        <span class="n">train_indices</span><span class="p">,</span>
        <span class="n">val_indices</span><span class="p">,</span>
        <span class="n">training_length</span><span class="p">,</span>
        <span class="n">val_losses</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><h3 id="execute_fitpy"><code>execute_fit.py</code><a class="headerlink" href="#execute_fitpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.execute_fit"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">











  </div>

    </div>

</div><h3 id="execute_postfitpy"><code>execute_postfit.py</code><a class="headerlink" href="#execute_postfitpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.execute_postfit"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h2 id="NN_fit.execute_postfit.postfit_execution" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">postfit_execution</span><span class="p">(</span><span class="n">postfit_criteria</span><span class="p">,</span> <span class="n">validation_split</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="p">,</span> <span class="n">num_output_layers</span><span class="p">,</span> <span class="n">chi_square_for_postfit</span><span class="p">,</span> <span class="n">neutrino_pdfs_mu</span><span class="p">,</span> <span class="n">neutrino_pdfs_mub</span><span class="p">,</span> <span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">postfit_measures</span><span class="p">,</span> <span class="n">train_indices</span><span class="p">,</span> <span class="n">val_indices</span><span class="p">,</span> <span class="n">level1</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">dir_for_data</span><span class="p">,</span> <span class="n">filename_postfit</span><span class="p">,</span> <span class="n">diff_lev_1</span><span class="p">,</span> <span class="n">fit_level</span><span class="p">,</span> <span class="n">x_alphas</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">pdf_set</span><span class="p">,</span> <span class="n">particle_id_nu</span><span class="p">,</span> <span class="n">particle_id_nub</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">,</span> <span class="n">patience</span><span class="p">,</span> <span class="n">chi_squares</span><span class="p">,</span> <span class="n">neutrino_pdf_fit_name_lhapdf</span><span class="p">,</span> <span class="n">x_vals</span><span class="p">,</span> <span class="n">produce_plot</span><span class="p">,</span> <span class="n">training_lengths</span><span class="p">,</span> <span class="n">stat_error</span><span class="p">,</span> <span class="n">sys_error</span><span class="p">,</span> <span class="n">low_bin</span><span class="p">,</span> <span class="n">high_bin</span><span class="p">,</span> <span class="n">N_event_pred_nu</span><span class="p">,</span> <span class="n">N_event_pred_nub</span><span class="p">,</span> <span class="n">low_bin_mu</span><span class="p">,</span> <span class="n">high_bin_mu</span><span class="p">,</span> <span class="n">low_bin_mub</span><span class="p">,</span> <span class="n">high_bin_mub</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">)</span></code>

<a href="#NN_fit.execute_postfit.postfit_execution" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Execute post-fit processing after a PDF (Parton Distribution Function) neural fit.</p>
<p>This function performs various operations following a neural network-based PDF fit:
- Applies post-fit criteria to PDFs and predictions.
- Calculates post-fit measures (e.g., delta chi-squared, phi, bias-to-variance).
- Logs results and configuration to file.
- Writes PDF replicas and uncertainties to LHAPDF-compatible grid files.
- Optionally generates plots of the results.</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>postfit_criteria</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to apply post-fit criteria to the predictions and PDFs.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>validation_split</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Fraction of data used for validation. If 0, no validation is used.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>data</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Measured experimental data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>cov_matrix</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Covariance matrix of the data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>num_output_layers</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of neural network outputs (1 for single PDF, 2 for neutrino/antineutrino PDFs).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>chi_square_for_postfit</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Chi-square values for the post-fit predictions.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>neutrino_pdfs_mu</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Neutrino PDFs for muon neutrino (only if <code>num_output_layers==2</code>).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>neutrino_pdfs_mub</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Neutrino PDFs for anti-muon neutrino (only if <code>num_output_layers==2</code>).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>neutrino_pdfs</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Neutrino PDFs for the single-output model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>postfit_measures</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to compute post-fit performance metrics.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>train_indices</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Training sample indices.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>val_indices</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Validation sample indices.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>level1</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Level-1 shifts or corrections.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>N_event_pred</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Predicted number of events from the model.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pred</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Model predictions.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>dir_for_data</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Directory to save results and intermediate files.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>filename_postfit</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the post-fit report file.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>diff_lev_1</code>
            </td>
            <td>
                  <code><span title="str">str</span> / <span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Identifier for the level-1 difference, used in LHAPDF naming.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>fit_level</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Level of fit used; affects which postfit measures are computed.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>x_alphas</code>
            </td>
            <td>
                  <code><span title="torch.Tensor">Tensor</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Neural network output alphas (PDF coefficients).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pdf</code>
            </td>
            <td>
                  <code><span title="object">object</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Reference PDF used during fitting.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>pdf_set</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name of the PDF set used as baseline.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>particle_id_nu</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>PDG ID for the neutrino used.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>particle_id_nub</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>PDG ID for the anti-neutrino used.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>lr</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Learning rate used in the training.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>wd</code>
            </td>
            <td>
                  <code><span title="float">float</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Weight decay used during training.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>max_epochs</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Maximum number of training epochs.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>patience</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Early stopping patience.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>chi_squares</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Chi-square values for the fit.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>neutrino_pdf_fit_name_lhapdf</code>
            </td>
            <td>
                  <code><span title="str">str</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Name to use for the LHAPDF set.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>x_vals</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>X-values (momentum fraction) for PDF grids.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>produce_plot</code>
            </td>
            <td>
                  <code><span title="bool">bool</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Whether to produce summary plots of fit results.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>training_lengths</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Number of epochs run for each replica.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>stat_error</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Statistical error on the data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>sys_error</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Systematic error on the data.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>low_bin</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Lower bound for binning (single PDF).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>high_bin</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Upper bound for binning (single PDF).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>N_event_pred_nu</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Event predictions for muon neutrino (two-output case).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>N_event_pred_nub</code>
            </td>
            <td>
                  <code><span title="numpy.ndarray">ndarray</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Event predictions for anti-muon neutrino (two-output case).</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>low_bin_mu</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Lower bin index for muon neutrino.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>high_bin_mu</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Upper bin index for muon neutrino.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>low_bin_mub</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Lower bin index for anti-muon neutrino.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>high_bin_mub</code>
            </td>
            <td>
                  <code><span title="int">int</span></code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>Upper bin index for anti-muon neutrino.</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


<details class="outputs" open>
  <summary>Outputs</summary>
  <ul>
<li>Writes various <code>.txt</code> files with statistical and fit information.</li>
<li>Creates LHAPDF-compatible grid files with the fitted PDFs.</li>
<li>Optionally generates plots summarizing the fit quality and predictions.</li>
</ul>
</details>

<details class="notes" open>
  <summary>Notes</summary>
  <ul>
<li>Assumes presence of <code>Postfit</code>, <code>Measures</code>, and LHAPDF writing utilities.</li>
<li>Assumes external plotting utilities (<code>plot_comb_pdf_cl</code>, <code>plot_nu_nub_cl</code>) are available.</li>
<li>Handles both single-output (combined neutrino) and two-output (neutrino/antineutrino) models.</li>
</ul>
</details>

            <details class="quote">
              <summary>Source code in <code>NN_fit/execute_postfit.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">postfit_execution</span><span class="p">(</span>
    <span class="n">postfit_criteria</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">validation_split</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">cov_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">num_output_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">chi_square_for_postfit</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">neutrino_pdfs_mu</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">neutrino_pdfs_mub</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">neutrino_pdfs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">postfit_measures</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">train_indices</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">val_indices</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">level1</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">N_event_pred</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">pred</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">dir_for_data</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">filename_postfit</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">diff_lev_1</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
    <span class="n">fit_level</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">x_alphas</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">pdf</span><span class="p">:</span> <span class="nb">object</span><span class="p">,</span>
    <span class="n">pdf_set</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">particle_id_nu</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">particle_id_nub</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">wd</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">chi_squares</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">neutrino_pdf_fit_name_lhapdf</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">x_vals</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">produce_plot</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">training_lengths</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">stat_error</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">sys_error</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">low_bin</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">high_bin</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">N_event_pred_nu</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">N_event_pred_nub</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">low_bin_mu</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">high_bin_mu</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">low_bin_mub</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">high_bin_mub</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">val_losses</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Execute post-fit processing after a PDF (Parton Distribution Function) neural fit.</span>

<span class="sd">    This function performs various operations following a neural network-based PDF fit:</span>
<span class="sd">    - Applies post-fit criteria to PDFs and predictions.</span>
<span class="sd">    - Calculates post-fit measures (e.g., delta chi-squared, phi, bias-to-variance).</span>
<span class="sd">    - Logs results and configuration to file.</span>
<span class="sd">    - Writes PDF replicas and uncertainties to LHAPDF-compatible grid files.</span>
<span class="sd">    - Optionally generates plots of the results.</span>

<span class="sd">    Parameters:</span>
<span class="sd">        postfit_criteria (bool): Whether to apply post-fit criteria to the predictions and PDFs.</span>
<span class="sd">        validation_split (float): Fraction of data used for validation. If 0, no validation is used.</span>
<span class="sd">        data (np.ndarray): Measured experimental data.</span>
<span class="sd">        cov_matrix (np.ndarray): Covariance matrix of the data.</span>
<span class="sd">        num_output_layers (int): Number of neural network outputs (1 for single PDF, 2 for neutrino/antineutrino PDFs).</span>
<span class="sd">        chi_square_for_postfit (np.ndarray): Chi-square values for the post-fit predictions.</span>
<span class="sd">        neutrino_pdfs_mu (np.ndarray): Neutrino PDFs for muon neutrino (only if `num_output_layers==2`).</span>
<span class="sd">        neutrino_pdfs_mub (np.ndarray): Neutrino PDFs for anti-muon neutrino (only if `num_output_layers==2`).</span>
<span class="sd">        neutrino_pdfs (np.ndarray): Neutrino PDFs for the single-output model.</span>
<span class="sd">        postfit_measures (bool): Whether to compute post-fit performance metrics.</span>
<span class="sd">        train_indices (np.ndarray): Training sample indices.</span>
<span class="sd">        val_indices (np.ndarray): Validation sample indices.</span>
<span class="sd">        level1 (np.ndarray): Level-1 shifts or corrections.</span>
<span class="sd">        N_event_pred (np.ndarray): Predicted number of events from the model.</span>
<span class="sd">        pred (np.ndarray): Model predictions.</span>
<span class="sd">        dir_for_data (str): Directory to save results and intermediate files.</span>
<span class="sd">        filename_postfit (str): Name of the post-fit report file.</span>
<span class="sd">        diff_lev_1 (str/int): Identifier for the level-1 difference, used in LHAPDF naming.</span>
<span class="sd">        fit_level (int): Level of fit used; affects which postfit measures are computed.</span>
<span class="sd">        x_alphas (torch.Tensor): Neural network output alphas (PDF coefficients).</span>
<span class="sd">        pdf (object): Reference PDF used during fitting.</span>
<span class="sd">        pdf_set (str): Name of the PDF set used as baseline.</span>
<span class="sd">        particle_id_nu (int): PDG ID for the neutrino used.</span>
<span class="sd">        particle_id_nub (int): PDG ID for the anti-neutrino used.</span>
<span class="sd">        lr (float): Learning rate used in the training.</span>
<span class="sd">        wd (float): Weight decay used during training.</span>
<span class="sd">        max_epochs (int): Maximum number of training epochs.</span>
<span class="sd">        patience (int): Early stopping patience.</span>
<span class="sd">        chi_squares (np.ndarray): Chi-square values for the fit.</span>
<span class="sd">        neutrino_pdf_fit_name_lhapdf (str): Name to use for the LHAPDF set.</span>
<span class="sd">        x_vals (np.ndarray): X-values (momentum fraction) for PDF grids.</span>
<span class="sd">        produce_plot (bool): Whether to produce summary plots of fit results.</span>
<span class="sd">        training_lengths (np.ndarray): Number of epochs run for each replica.</span>
<span class="sd">        stat_error (np.ndarray): Statistical error on the data.</span>
<span class="sd">        sys_error (np.ndarray): Systematic error on the data.</span>
<span class="sd">        low_bin (int): Lower bound for binning (single PDF).</span>
<span class="sd">        high_bin (int): Upper bound for binning (single PDF).</span>
<span class="sd">        N_event_pred_nu (np.ndarray): Event predictions for muon neutrino (two-output case).</span>
<span class="sd">        N_event_pred_nub (np.ndarray): Event predictions for anti-muon neutrino (two-output case).</span>
<span class="sd">        low_bin_mu (int): Lower bin index for muon neutrino.</span>
<span class="sd">        high_bin_mu (int): Upper bin index for muon neutrino.</span>
<span class="sd">        low_bin_mub (int): Lower bin index for anti-muon neutrino.</span>
<span class="sd">        high_bin_mub (int): Upper bin index for anti-muon neutrino.</span>

<span class="sd">    Outputs:</span>
<span class="sd">        - Writes various `.txt` files with statistical and fit information.</span>
<span class="sd">        - Creates LHAPDF-compatible grid files with the fitted PDFs.</span>
<span class="sd">        - Optionally generates plots summarizing the fit quality and predictions.</span>

<span class="sd">    Notes:</span>
<span class="sd">        - Assumes presence of `Postfit`, `Measures`, and LHAPDF writing utilities.</span>
<span class="sd">        - Assumes external plotting utilities (`plot_comb_pdf_cl`, `plot_nu_nub_cl`) are available.</span>
<span class="sd">        - Handles both single-output (combined neutrino) and two-output (neutrino/antineutrino) models.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">postfit_criteria</span><span class="p">:</span>
        <span class="n">train_indices</span> <span class="o">=</span> <span class="n">train_indices</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">val_indices</span> <span class="o">=</span> <span class="n">val_indices</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">level1</span> <span class="o">=</span> <span class="n">level1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">validation_split</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">train_indices</span> <span class="o">=</span> <span class="n">train_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">val_indices</span> <span class="o">=</span> <span class="n">val_indices</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">train_indices</span> <span class="o">=</span> <span class="n">train_indices</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
            <span class="n">val_indices</span> <span class="o">=</span> <span class="n">val_indices</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

            <span class="n">N_event_pred_train</span> <span class="o">=</span> <span class="n">N_event_pred</span><span class="p">[:,</span> <span class="n">train_indices</span><span class="p">]</span>
            <span class="n">pred_train</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[:,</span> <span class="n">train_indices</span><span class="p">]</span>

            <span class="n">N_event_pred_val</span> <span class="o">=</span> <span class="n">N_event_pred</span><span class="p">[:,</span> <span class="n">val_indices</span><span class="p">]</span>
            <span class="n">data_val</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">val_indices</span><span class="p">]</span>
            <span class="n">pred_val</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[:,</span> <span class="n">val_indices</span><span class="p">]</span>

            <span class="n">level1_val</span> <span class="o">=</span> <span class="n">level1</span><span class="p">[</span><span class="n">val_indices</span><span class="p">]</span>

            <span class="n">val_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">val_indices</span><span class="p">)</span>

            <span class="n">cov_matrix_val</span> <span class="o">=</span> <span class="n">cov_matrix</span><span class="p">[</span><span class="n">val_indices</span><span class="p">][:,</span> <span class="n">val_indices</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">num_output_layers</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">compute_postfit_criteria</span><span class="p">(</span><span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span>
                <span class="n">closure_fit</span> <span class="o">=</span> <span class="n">Postfit</span><span class="p">()</span>
                <span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">closure_fit</span><span class="o">.</span><span class="n">apply_postfit_criteria</span><span class="p">(</span>
                    <span class="n">chi_square_for_postfit</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">pred</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="p">(</span><span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">postfit_criteria</span> <span class="ow">and</span> <span class="n">validation_split</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
                <span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">N_event_pred_train</span><span class="p">,</span> <span class="n">pred_train</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">compute_postfit_criteria</span><span class="p">(</span>
                        <span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">N_event_pred_train</span><span class="p">,</span> <span class="n">pred_train</span>
                    <span class="p">)</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">postfit_criteria</span> <span class="ow">and</span> <span class="n">validation_split</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">compute_postfit_criteria</span><span class="p">(</span>
                    <span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">pred</span>
                <span class="p">)</span>
        <span class="k">if</span> <span class="n">num_output_layers</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>

            <span class="k">def</span><span class="w"> </span><span class="nf">compute_postfit_criteria</span><span class="p">(</span>
                <span class="n">neutrino_pdfs_mu</span><span class="p">,</span> <span class="n">neutrino_pdfs_mub</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">pred</span>
            <span class="p">):</span>
                <span class="c1"># if postfit_criteria:</span>
                <span class="n">closure_fit</span> <span class="o">=</span> <span class="n">Postfit</span><span class="p">()</span>
                <span class="n">neutrino_pdfs_mu</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">closure_fit</span><span class="o">.</span><span class="n">apply_postfit_criteria</span><span class="p">(</span>
                    <span class="n">chi_square_for_postfit</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">neutrino_pdfs_mu</span><span class="p">,</span> <span class="n">pred</span>
                <span class="p">)</span>
                <span class="n">neutrino_pdfs_mub</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">pred</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="n">closure_fit</span><span class="o">.</span><span class="n">apply_postfit_criteria</span><span class="p">(</span>
                        <span class="n">chi_square_for_postfit</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">neutrino_pdfs_mub</span><span class="p">,</span> <span class="n">pred</span>
                    <span class="p">)</span>
                <span class="p">)</span>

            <span class="k">if</span> <span class="n">postfit_criteria</span> <span class="ow">and</span> <span class="n">validation_split</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
                <span class="n">compute_postfit_criteria</span><span class="p">(</span>
                    <span class="n">neutrino_pdfs_mu</span><span class="p">,</span> <span class="n">neutrino_pdfs_mub</span><span class="p">,</span> <span class="n">N_event_pred_train</span><span class="p">,</span> <span class="n">pred_train</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">postfit_criteria</span> <span class="ow">and</span> <span class="n">validation_split</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">compute_postfit_criteria</span><span class="p">(</span>
                    <span class="n">neutrino_pdfs_mu</span><span class="p">,</span> <span class="n">neutrino_pdfs_mub</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">pred</span>
                <span class="p">)</span>

    <span class="k">if</span> <span class="n">postfit_measures</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_for_data</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">filename_postfit</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;level 1 shift </span><span class="si">{</span><span class="n">diff_lev_1</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;postfit report faser sim fit:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;100 replicas:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">def</span><span class="w"> </span><span class="nf">compute_postfit_measures</span><span class="p">(</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">level1</span><span class="p">,</span> <span class="n">pred</span><span class="p">):</span>
            <span class="n">compute_postfit</span> <span class="o">=</span> <span class="n">Measures</span><span class="p">(</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">fit_level</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">delta_chi</span> <span class="o">=</span> <span class="n">compute_postfit</span><span class="o">.</span><span class="n">compute_delta_chi</span><span class="p">(</span>
                    <span class="n">data</span><span class="p">,</span>
                    <span class="n">N_event_pred</span><span class="p">,</span>
                    <span class="n">level1</span><span class="p">,</span>
                    <span class="n">x_alphas</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span>
                <span class="p">)</span>

                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_for_data</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">filename_postfit</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
                    <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;delta chi^2 = </span><span class="si">{</span><span class="n">delta_chi</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="k">if</span> <span class="n">num_output_layers</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">compute_postfit</span><span class="o">.</span><span class="n">compute_accuracy</span><span class="p">(</span>
                        <span class="n">x_alphas</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
                        <span class="n">neutrino_pdfs</span><span class="p">,</span>
                        <span class="n">pdf</span><span class="p">,</span>
                        <span class="mi">1</span><span class="p">,</span>
                        <span class="n">pdf_set</span><span class="p">,</span>
                        <span class="n">particle_id_nu</span><span class="p">,</span>
                    <span class="p">)</span>

                    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_for_data</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">filename_postfit</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
                        <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;accuracy = </span><span class="si">{</span><span class="n">accuracy</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">num_output_layers</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                    <span class="n">accuracy_nu</span> <span class="o">=</span> <span class="n">compute_postfit</span><span class="o">.</span><span class="n">compute_accuracy</span><span class="p">(</span>
                        <span class="n">x_alphas</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
                        <span class="n">neutrino_pdfs_mu</span><span class="p">,</span>
                        <span class="n">pdf</span><span class="p">,</span>
                        <span class="mi">1</span><span class="p">,</span>
                        <span class="n">pdf_set</span><span class="p">,</span>
                        <span class="n">particle_id_nu</span><span class="p">,</span>
                    <span class="p">)</span>

                    <span class="n">accuracy_nub</span> <span class="o">=</span> <span class="n">compute_postfit</span><span class="o">.</span><span class="n">compute_accuracy</span><span class="p">(</span>
                        <span class="n">x_alphas</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
                        <span class="n">neutrino_pdfs_mub</span><span class="p">,</span>
                        <span class="n">pdf</span><span class="p">,</span>
                        <span class="mi">1</span><span class="p">,</span>
                        <span class="n">pdf_set</span><span class="p">,</span>
                        <span class="n">particle_id_nub</span><span class="p">,</span>
                    <span class="p">)</span>

                    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_for_data</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">filename_postfit</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
                        <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;accuracy nu = </span><span class="si">{</span><span class="n">accuracy_nu</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
                        <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;accuracy nub = </span><span class="si">{</span><span class="n">accuracy_nub</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">phi</span> <span class="o">=</span> <span class="n">compute_postfit</span><span class="o">.</span><span class="n">compute_phi</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">chi_square_for_postfit</span><span class="p">)</span>

            <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_for_data</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">filename_postfit</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
                <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;phi = </span><span class="si">{</span><span class="n">phi</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">fit_level</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">bias_to_var</span> <span class="o">=</span> <span class="n">compute_postfit</span><span class="o">.</span><span class="n">compute_bias_to_variance</span><span class="p">(</span>
                    <span class="n">data</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">N_event_pred</span><span class="p">)</span>
                <span class="p">)</span>

                <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_for_data</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">filename_postfit</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
                    <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;bias_to_var = </span><span class="si">{</span><span class="n">bias_to_var</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">postfit_measures</span> <span class="ow">and</span> <span class="n">validation_split</span> <span class="o">!=</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">compute_postfit_measures</span><span class="p">(</span>
                <span class="n">cov_matrix_val</span><span class="p">,</span> <span class="n">N_event_pred_val</span><span class="p">,</span> <span class="n">data_val</span><span class="p">,</span> <span class="n">level1_val</span><span class="p">,</span> <span class="n">pred_val</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">postfit_measures</span> <span class="ow">and</span> <span class="n">validation_split</span> <span class="o">==</span> <span class="mf">0.0</span><span class="p">:</span>
            <span class="n">compute_postfit_measures</span><span class="p">(</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">level1</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_for_data</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">filename_postfit</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;mean chi^2 = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">chi_square_for_postfit</span><span class="p">)</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;average training length = </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">training_lengths</span><span class="p">)</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;settings used:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;learning rate = </span><span class="si">{</span><span class="n">lr</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;weigth decay = </span><span class="si">{</span><span class="n">wd</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;max training lenght = </span><span class="si">{</span><span class="n">max_epochs</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;patience = </span><span class="si">{</span><span class="n">patience</span><span class="si">}</span><span class="s2">:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_for_data</span><span class="si">}</span><span class="s2">/chi_square.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">chi_squares</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_for_data</span><span class="si">}</span><span class="s2">/chi_squares_for_postfit.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">chi_square_for_postfit</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_for_data</span><span class="si">}</span><span class="s2">/events.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>

    <span class="n">os</span><span class="o">.</span><span class="n">makedirs</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;/opt/anaconda3/envs/test_lhapdf/share/LHAPDF/</span><span class="si">{</span><span class="n">neutrino_pdf_fit_name_lhapdf</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">diff_lev_1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">template_path</span> <span class="o">=</span> <span class="s2">&quot;/opt/anaconda3/envs/test_lhapdf/share/LHAPDF/template_.info&quot;</span>
    <span class="n">path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;/opt/anaconda3/envs/test_lhapdf/share/LHAPDF/</span><span class="si">{</span><span class="n">neutrino_pdf_fit_name_lhapdf</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">diff_lev_1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">neutrino_pdf_fit_name_lhapdf</span><span class="si">}</span><span class="s2">.info&quot;</span>
    <span class="n">set_index</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="mf">1e7</span><span class="p">)</span>
    <span class="n">pdf_dict_central</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">pdf_dict_error</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">if</span> <span class="n">num_output_layers</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">customize_info_file</span><span class="p">(</span><span class="n">template_path</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">set_index</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">particle_id_nu</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">mean_pdf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">std_pdf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;/opt/anaconda3/envs/test_lhapdf/share/LHAPDF/</span><span class="si">{</span><span class="n">neutrino_pdf_fit_name_lhapdf</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">diff_lev_1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">neutrino_pdf_fit_name_lhapdf</span><span class="si">}</span><span class="s2">_0000.dat&quot;</span>
        <span class="n">pdf_dict_error</span><span class="p">[</span><span class="mi">12</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_pdf</span>
        <span class="n">pdf_dict_central</span><span class="p">[</span><span class="mi">12</span><span class="p">]</span> <span class="o">=</span> <span class="n">std_pdf</span>
        <span class="n">write_lhapdf_grid</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">pdf_dict_central</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
        <span class="n">path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;/opt/anaconda3/envs/test_lhapdf/share/LHAPDF/</span><span class="si">{</span><span class="n">neutrino_pdf_fit_name_lhapdf</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">diff_lev_1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">neutrino_pdf_fit_name_lhapdf</span><span class="si">}</span><span class="s2">_0001.dat&quot;</span>
        <span class="n">write_lhapdf_grid</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">pdf_dict_error</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">num_output_layers</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
        <span class="n">customize_info_file</span><span class="p">(</span>
            <span class="n">template_path</span><span class="p">,</span> <span class="n">path</span><span class="p">,</span> <span class="n">set_index</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">particle_id_nu</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">particle_id_nub</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="mi">2</span>
        <span class="p">)</span>
        <span class="n">mean_pdf_nu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">neutrino_pdfs_mu</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">mean_pdf_nub</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">neutrino_pdfs_mub</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">std_pdf_nu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">neutrino_pdfs_mu</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">std_pdf_nub</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">neutrino_pdfs_mub</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;/opt/anaconda3/envs/test_lhapdf/share/LHAPDF/</span><span class="si">{</span><span class="n">neutrino_pdf_fit_name_lhapdf</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">diff_lev_1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">neutrino_pdf_fit_name_lhapdf</span><span class="si">}</span><span class="s2">_0000.dat&quot;</span>

        <span class="n">pdf_dict_error</span><span class="p">[</span><span class="mi">14</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_pdf_nu</span>
        <span class="n">pdf_dict_error</span><span class="p">[</span><span class="o">-</span><span class="mi">14</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_pdf_nub</span>
        <span class="n">pdf_dict_central</span><span class="p">[</span><span class="mi">14</span><span class="p">]</span> <span class="o">=</span> <span class="n">std_pdf_nu</span>
        <span class="n">pdf_dict_central</span><span class="p">[</span><span class="o">-</span><span class="mi">14</span><span class="p">]</span> <span class="o">=</span> <span class="n">std_pdf_nub</span>
        <span class="n">write_lhapdf_grid</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">pdf_dict_central</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>

        <span class="n">path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;/opt/anaconda3/envs/test_lhapdf/share/LHAPDF/</span><span class="si">{</span><span class="n">neutrino_pdf_fit_name_lhapdf</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">diff_lev_1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">neutrino_pdf_fit_name_lhapdf</span><span class="si">}</span><span class="s2">_0001.dat&quot;</span>
        <span class="n">write_lhapdf_grid</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">pdf_dict_error</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_losses</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">val_losses</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">val_losses</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_for_data</span><span class="si">}</span><span class="s2">/val_losses.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">val_losses</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">chi_square_for_postfit</span><span class="o">.</span><span class="n">size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_for_data</span><span class="si">}</span><span class="s2">/pred.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">pred</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_for_data</span><span class="si">}</span><span class="s2">/train_indices.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">train_indices</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_for_data</span><span class="si">}</span><span class="s2">/val_indices.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">val_indices</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dir_for_data</span><span class="si">}</span><span class="s2">/training_lengths.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">training_lengths</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s2">&quot;,&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">produce_plot</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">num_output_layers</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">plot_comb_pdf_cl</span><span class="w"> </span><span class="kn">import</span> <span class="n">plot</span>

            <span class="n">sig_tot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">stat_error</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">sys_error</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">plot</span><span class="p">(</span>
                <span class="n">x_vals</span><span class="p">,</span>
                <span class="n">neutrino_pdfs</span><span class="p">,</span>
                <span class="n">data</span><span class="p">,</span>
                <span class="n">N_event_pred</span><span class="p">,</span>
                <span class="n">sig_tot</span><span class="p">,</span>
                <span class="n">particle_id_nu</span><span class="p">,</span>
                <span class="n">low_bin</span><span class="p">,</span>
                <span class="n">high_bin</span><span class="p">,</span>
                <span class="n">pdf</span><span class="p">,</span>
                <span class="n">pdf_set</span><span class="p">,</span>
                <span class="n">dir_for_data</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">num_output_layers</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="kn">from</span><span class="w"> </span><span class="nn">plot_nu_nub_cl</span><span class="w"> </span><span class="kn">import</span> <span class="n">plot</span>

            <span class="n">sig_tot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">stat_error</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">sys_error</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
            <span class="n">plot</span><span class="p">(</span>
                <span class="n">x_vals</span><span class="p">,</span>
                <span class="n">neutrino_pdfs_mu</span><span class="p">,</span>
                <span class="n">neutrino_pdfs_mub</span><span class="p">,</span>
                <span class="n">data</span><span class="p">,</span>
                <span class="n">N_event_pred_nu</span><span class="p">,</span>
                <span class="n">N_event_pred_nub</span><span class="p">,</span>
                <span class="n">sig_tot</span><span class="p">,</span>
                <span class="n">particle_id_nu</span><span class="p">,</span>
                <span class="n">low_bin_mu</span><span class="p">,</span>
                <span class="n">high_bin_mu</span><span class="p">,</span>
                <span class="n">low_bin_mub</span><span class="p">,</span>
                <span class="n">high_bin_mub</span><span class="p">,</span>
                <span class="n">pdf</span><span class="p">,</span>
                <span class="n">pdf_set</span><span class="p">,</span>
                <span class="n">dir_for_data</span><span class="p">,</span>
            <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><hr />
<h2 id="hyperparameter-optimization">🎯 Hyperparameter optimization<a class="headerlink" href="#hyperparameter-optimization" title="Permanent link">&para;</a></h2>
<h3 id="perform_hyperoptpy"><code>perform_hyperopt.py</code><a class="headerlink" href="#perform_hyperoptpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.perform_hyperopt"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">











  </div>

    </div>

</div><h3 id="hyperopt_combpy"><code>hyperopt_comb.py</code><a class="headerlink" href="#hyperopt_combpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.hyperopt_comb"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h2 id="NN_fit.hyperopt_comb.perform_fit" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">perform_fit</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">range_alpha</span><span class="p">,</span> <span class="n">range_beta</span><span class="p">,</span> <span class="n">range_gamma</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="p">,</span> <span class="n">patience</span><span class="p">,</span> <span class="n">x_alphas</span><span class="p">,</span> <span class="n">fk_tables</span><span class="p">,</span> <span class="n">binwidths</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="p">,</span> <span class="n">extended_loss</span><span class="p">,</span> <span class="n">activation_function</span><span class="p">,</span> <span class="n">num_input_layers</span><span class="p">,</span> <span class="n">num_output_layers</span><span class="p">,</span> <span class="n">hidden_layers</span><span class="p">,</span> <span class="n">x_vals</span><span class="p">,</span> <span class="n">preproc</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">,</span> <span class="n">lag_mult_pos</span><span class="p">,</span> <span class="n">lag_mult_int</span><span class="p">,</span> <span class="n">x_int</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">)</span></code>

<a href="#NN_fit.hyperopt_comb.perform_fit" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Trains a neural network model to fit pseudo-data for electron neutrino event predictions
using K-fold cross-validation and physics-informed constraints.</p>
<p>This function fits a parameterized neural network (PreprocessedMLP) using a custom loss function
that incorporates statistical and physical constraints such as positivity and normalization.
K-fold cross-validation is used to evaluate the model's generalization performance across
different data splits. Random initialization of the preprocessing parameters (alpha, beta, gamma)
enables exploration of a hyperparameter space.</p>
<h4 id="NN_fit.hyperopt_comb.perform_fit--parameters">Parameters<a class="headerlink" href="#NN_fit.hyperopt_comb.perform_fit--parameters" title="Permanent link">&para;</a></h4>
<p>pred : List[np.ndarray]
    List containing prediction arrays (pseudo-data) for electron neutrino event counts.
range_alpha : float
    Maximum value for randomly sampling the alpha preprocessing parameter.
range_beta : float
    Maximum value for randomly sampling the beta preprocessing parameter.
range_gamma : float
    Maximum value for randomly sampling the gamma preprocessing parameter.
lr : float
    Learning rate for the Adam optimizer.
wd : float
    Weight decay (L2 regularization) used during optimization.
patience : int
    Early stopping patience threshold (number of epochs without improvement before stopping).
x_alphas : torch.Tensor
    Input tensor used to evaluate the model's predicted PDFs.
fk_tables : torch.Tensor
    Forward-folding kernel that maps PDF space to observable event space.
binwidths : torch.Tensor
    Bin widths used to scale the convolved predictions.
cov_matrix : np.ndarray
    Covariance matrix of the pseudo-data, used for uncertainty-aware loss computation.
extended_loss : bool
    Whether to include extended physics constraints (e.g., positivity, integrals) in the loss.
activation_function : str
    Name of the activation function to be used in the MLP (e.g., 'relu', 'tanh').
num_input_layers : int
    Number of input neurons to the network (typically 1 for univariate PDFs).
num_output_layers : int
    Number of output neurons (typically 1 for electron neutrinos).
hidden_layers : List[int]
    List of hidden layer sizes (e.g., [50, 50] for a 2-layer MLP with 50 neurons each).
x_vals : np.ndarray
    Input values over which the final PDF predictions will be evaluated.
preproc : str
    Type of preprocessing function used on the PDFs (e.g., 'log', 'powerlaw').
max_epochs : int
    Maximum number of training epochs per fold.
lag_mult_pos : float
    Lagrange multiplier for the positivity constraint in the loss.
lag_mult_int : float
    Lagrange multiplier for the integral (normalization) constraint in the loss.
x_int : np.ndarray
    Input values used for evaluating the integral constraints on the PDF.</p>
<h4 id="NN_fit.hyperopt_comb.perform_fit--returns">Returns<a class="headerlink" href="#NN_fit.hyperopt_comb.perform_fit--returns" title="Permanent link">&para;</a></h4>
<p>chi_squares : List[float]
    History of chi-squared values during training (saved periodically).
N_event_pred : List[np.ndarray]
    Placeholder for predicted event counts (not currently populated in this version).
neutrino_pdfs : List[np.ndarray]
    Placeholder for final PDF outputs (not currently populated in this version).
model : PreprocessedMLP
    Trained neural network model from the final fold.
chi_square_for_postfit : List[float]
    Final loss value (chi-squared) for each fold.
train_indices : np.ndarray
    Indices of the training samples used in the final fold.
val_indices : np.ndarray
    Indices of the validation samples used in the final fold.
training_length : int
    Number of epochs completed during the final fold training.
num_folds: int
    number of k-folds</p>
<h4 id="NN_fit.hyperopt_comb.perform_fit--notes">Notes<a class="headerlink" href="#NN_fit.hyperopt_comb.perform_fit--notes" title="Permanent link">&para;</a></h4>
<ul>
<li>The function uses 3-fold cross-validation to evaluate generalization.</li>
<li>Preprocessing parameters (alpha, beta, gamma) are randomized for each fold.</li>
<li>This implementation supports only one prediction channel and assumes
  symmetric treatment of integrals and positivity constraints.</li>
<li><code>N_event_pred</code> and <code>neutrino_pdfs</code> are currently not returned meaningfully.</li>
</ul>


            <details class="quote">
              <summary>Source code in <code>NN_fit/hyperopt_comb.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">perform_fit</span><span class="p">(</span>
    <span class="n">pred</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">range_alpha</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">range_beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">range_gamma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">wd</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">x_alphas</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">fk_tables</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">binwidths</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">cov_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">extended_loss</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">activation_function</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">num_input_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_output_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">hidden_layers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">x_vals</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">preproc</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">lag_mult_pos</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">lag_mult_int</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">x_int</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">num_folds</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
    <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>  <span class="c1"># chi_squares</span>
    <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>  <span class="c1"># N_event_pred</span>
    <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>  <span class="c1"># neutrino_pdfs</span>
    <span class="n">PreprocessedMLP</span><span class="p">,</span>  <span class="c1"># model (last accepted fit)</span>
    <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>  <span class="c1"># chi_square_for_postfit</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># train_indices</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># val_indices</span>
    <span class="nb">int</span><span class="p">,</span>  <span class="c1"># training_length</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Trains a neural network model to fit pseudo-data for electron neutrino event predictions</span>
<span class="sd">    using K-fold cross-validation and physics-informed constraints.</span>

<span class="sd">    This function fits a parameterized neural network (PreprocessedMLP) using a custom loss function</span>
<span class="sd">    that incorporates statistical and physical constraints such as positivity and normalization.</span>
<span class="sd">    K-fold cross-validation is used to evaluate the model&#39;s generalization performance across</span>
<span class="sd">    different data splits. Random initialization of the preprocessing parameters (alpha, beta, gamma)</span>
<span class="sd">    enables exploration of a hyperparameter space.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pred : List[np.ndarray]</span>
<span class="sd">        List containing prediction arrays (pseudo-data) for electron neutrino event counts.</span>
<span class="sd">    range_alpha : float</span>
<span class="sd">        Maximum value for randomly sampling the alpha preprocessing parameter.</span>
<span class="sd">    range_beta : float</span>
<span class="sd">        Maximum value for randomly sampling the beta preprocessing parameter.</span>
<span class="sd">    range_gamma : float</span>
<span class="sd">        Maximum value for randomly sampling the gamma preprocessing parameter.</span>
<span class="sd">    lr : float</span>
<span class="sd">        Learning rate for the Adam optimizer.</span>
<span class="sd">    wd : float</span>
<span class="sd">        Weight decay (L2 regularization) used during optimization.</span>
<span class="sd">    patience : int</span>
<span class="sd">        Early stopping patience threshold (number of epochs without improvement before stopping).</span>
<span class="sd">    x_alphas : torch.Tensor</span>
<span class="sd">        Input tensor used to evaluate the model&#39;s predicted PDFs.</span>
<span class="sd">    fk_tables : torch.Tensor</span>
<span class="sd">        Forward-folding kernel that maps PDF space to observable event space.</span>
<span class="sd">    binwidths : torch.Tensor</span>
<span class="sd">        Bin widths used to scale the convolved predictions.</span>
<span class="sd">    cov_matrix : np.ndarray</span>
<span class="sd">        Covariance matrix of the pseudo-data, used for uncertainty-aware loss computation.</span>
<span class="sd">    extended_loss : bool</span>
<span class="sd">        Whether to include extended physics constraints (e.g., positivity, integrals) in the loss.</span>
<span class="sd">    activation_function : str</span>
<span class="sd">        Name of the activation function to be used in the MLP (e.g., &#39;relu&#39;, &#39;tanh&#39;).</span>
<span class="sd">    num_input_layers : int</span>
<span class="sd">        Number of input neurons to the network (typically 1 for univariate PDFs).</span>
<span class="sd">    num_output_layers : int</span>
<span class="sd">        Number of output neurons (typically 1 for electron neutrinos).</span>
<span class="sd">    hidden_layers : List[int]</span>
<span class="sd">        List of hidden layer sizes (e.g., [50, 50] for a 2-layer MLP with 50 neurons each).</span>
<span class="sd">    x_vals : np.ndarray</span>
<span class="sd">        Input values over which the final PDF predictions will be evaluated.</span>
<span class="sd">    preproc : str</span>
<span class="sd">        Type of preprocessing function used on the PDFs (e.g., &#39;log&#39;, &#39;powerlaw&#39;).</span>
<span class="sd">    max_epochs : int</span>
<span class="sd">        Maximum number of training epochs per fold.</span>
<span class="sd">    lag_mult_pos : float</span>
<span class="sd">        Lagrange multiplier for the positivity constraint in the loss.</span>
<span class="sd">    lag_mult_int : float</span>
<span class="sd">        Lagrange multiplier for the integral (normalization) constraint in the loss.</span>
<span class="sd">    x_int : np.ndarray</span>
<span class="sd">        Input values used for evaluating the integral constraints on the PDF.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    chi_squares : List[float]</span>
<span class="sd">        History of chi-squared values during training (saved periodically).</span>
<span class="sd">    N_event_pred : List[np.ndarray]</span>
<span class="sd">        Placeholder for predicted event counts (not currently populated in this version).</span>
<span class="sd">    neutrino_pdfs : List[np.ndarray]</span>
<span class="sd">        Placeholder for final PDF outputs (not currently populated in this version).</span>
<span class="sd">    model : PreprocessedMLP</span>
<span class="sd">        Trained neural network model from the final fold.</span>
<span class="sd">    chi_square_for_postfit : List[float]</span>
<span class="sd">        Final loss value (chi-squared) for each fold.</span>
<span class="sd">    train_indices : np.ndarray</span>
<span class="sd">        Indices of the training samples used in the final fold.</span>
<span class="sd">    val_indices : np.ndarray</span>
<span class="sd">        Indices of the validation samples used in the final fold.</span>
<span class="sd">    training_length : int</span>
<span class="sd">        Number of epochs completed during the final fold training.</span>
<span class="sd">    num_folds: int</span>
<span class="sd">        number of k-folds</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - The function uses 3-fold cross-validation to evaluate generalization.</span>
<span class="sd">    - Preprocessing parameters (alpha, beta, gamma) are randomized for each fold.</span>
<span class="sd">    - This implementation supports only one prediction channel and assumes</span>
<span class="sd">      symmetric treatment of integrals and positivity constraints.</span>
<span class="sd">    - `N_event_pred` and `neutrino_pdfs` are currently not returned meaningfully.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="p">(</span>
        <span class="n">chi_squares</span><span class="p">,</span>
        <span class="n">k_fold_losses</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">[],</span>
        <span class="p">[],</span>
    <span class="p">)</span>
    <span class="n">x_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">x_int</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_int</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">num_folds</span>
    <span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

    <span class="n">folds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">indices</span><span class="p">):</span>
        <span class="n">folds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="n">train_indices</span> <span class="o">=</span> <span class="n">folds</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">val_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.1</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_indices</span><span class="p">)))</span>
        <span class="n">val_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_indices</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">val_size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">k_fold_indices</span> <span class="o">=</span> <span class="n">folds</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="n">range_alpha</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="n">range_beta</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="n">range_gamma</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">PreprocessedMLP</span><span class="p">(</span>
            <span class="n">alpha</span><span class="p">,</span>
            <span class="n">beta</span><span class="p">,</span>
            <span class="n">gamma</span><span class="p">,</span>
            <span class="n">activation_function</span><span class="p">,</span>
            <span class="n">hidden_layers</span><span class="p">,</span>
            <span class="n">num_input_layers</span><span class="p">,</span>
            <span class="n">num_output_layers</span><span class="p">,</span>
            <span class="n">preproc</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">criterion</span> <span class="o">=</span> <span class="n">CustomLoss</span><span class="p">(</span>
            <span class="n">extended_loss</span><span class="p">,</span>
            <span class="n">num_output_layers</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">wd</span><span class="p">)</span>

        <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">best_loss</span> <span class="o">=</span> <span class="mf">1e13</span>  <span class="c1"># initial loss</span>
        <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">training_length</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">while</span> <span class="n">counter</span> <span class="o">&lt;</span> <span class="n">patience</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">max_epochs</span> <span class="o">&lt;</span> <span class="n">training_length</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="n">training_length</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_alphas</span><span class="p">)</span>

            <span class="n">y_preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">fk_tables</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">binwidths</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="n">y_preds</span> <span class="o">=</span> <span class="n">y_preds</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">y_int_mu</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_int</span><span class="p">)</span>
            <span class="n">y_int_mub</span> <span class="o">=</span> <span class="n">y_int_mu</span>

            <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_preds</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span>
            <span class="n">pred_train</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">train_indices</span><span class="p">]</span>
            <span class="n">cov_matrix_train</span> <span class="o">=</span> <span class="n">cov_matrix</span><span class="p">[</span><span class="n">train_indices</span><span class="p">][:,</span> <span class="n">train_indices</span><span class="p">]</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
                <span class="n">y_train</span><span class="p">,</span>
                <span class="n">pred_train</span><span class="p">,</span>
                <span class="n">cov_matrix_train</span><span class="p">,</span>
                <span class="n">y_int_mu</span><span class="p">,</span>
                <span class="n">y_int_mub</span><span class="p">,</span>
                <span class="n">y_pred</span><span class="p">,</span>
                <span class="n">x_int</span><span class="p">,</span>
                <span class="n">lag_mult_pos</span><span class="p">,</span>
                <span class="n">lag_mult_int</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="n">y_val</span> <span class="o">=</span> <span class="n">y_preds</span><span class="p">[</span><span class="n">val_indices</span><span class="p">]</span>
            <span class="n">pred_val</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">val_indices</span><span class="p">]</span>
            <span class="n">cov_matrix_val</span> <span class="o">=</span> <span class="n">cov_matrix</span><span class="p">[</span><span class="n">val_indices</span><span class="p">][:,</span> <span class="n">val_indices</span><span class="p">]</span>

            <span class="n">loss_val</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
                <span class="n">y_val</span><span class="p">,</span>
                <span class="n">pred_val</span><span class="p">,</span>
                <span class="n">cov_matrix_val</span><span class="p">,</span>
                <span class="n">y_int_mu</span><span class="p">,</span>
                <span class="n">y_int_mub</span><span class="p">,</span>
                <span class="n">y_pred</span><span class="p">,</span>
                <span class="n">x_int</span><span class="p">,</span>
                <span class="n">lag_mult_pos</span><span class="p">,</span>
                <span class="n">lag_mult_int</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">training_length</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">chi_squares</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

            <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">loss_val</span> <span class="o">&lt;</span> <span class="n">best_loss</span><span class="p">:</span>
                <span class="n">best_loss</span> <span class="o">=</span> <span class="n">loss_val</span>
                <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">y_k_fold</span> <span class="o">=</span> <span class="n">y_preds</span><span class="p">[</span><span class="n">k_fold_indices</span><span class="p">]</span>
        <span class="n">pred_k_fold</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">k_fold_indices</span><span class="p">]</span>
        <span class="n">cov_matrix_k_fold</span> <span class="o">=</span> <span class="n">cov_matrix</span><span class="p">[</span><span class="n">k_fold_indices</span><span class="p">][:,</span> <span class="n">k_fold_indices</span><span class="p">]</span>

        <span class="n">loss_k_fold</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
            <span class="n">y_k_fold</span><span class="p">,</span>
            <span class="n">pred_k_fold</span><span class="p">,</span>
            <span class="n">cov_matrix_k_fold</span><span class="p">,</span>
            <span class="n">y_int_mu</span><span class="p">,</span>
            <span class="n">y_int_mub</span><span class="p">,</span>
            <span class="n">y_pred</span><span class="p">,</span>
            <span class="n">x_int</span><span class="p">,</span>
            <span class="n">lag_mult_pos</span><span class="p">,</span>
            <span class="n">lag_mult_int</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">k_fold_loss</span> <span class="o">=</span> <span class="n">loss_k_fold</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">k_fold_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k_fold_loss</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k_fold_losses&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">k_fold_losses</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">k_fold_losses</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><h3 id="hyperopt_nu_nubpy"><code>hyperopt_nu_nub.py</code><a class="headerlink" href="#hyperopt_nu_nubpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.hyperopt_nu_nub"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h2 id="NN_fit.hyperopt_nu_nub.perform_fit" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">perform_fit</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">range_alpha</span><span class="p">,</span> <span class="n">range_beta</span><span class="p">,</span> <span class="n">range_gamma</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">wd</span><span class="p">,</span> <span class="n">patience</span><span class="p">,</span> <span class="n">x_alphas</span><span class="p">,</span> <span class="n">fk_tables_mu</span><span class="p">,</span> <span class="n">fk_tables_mub</span><span class="p">,</span> <span class="n">binwidths_mu</span><span class="p">,</span> <span class="n">binwidths_mub</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="p">,</span> <span class="n">extended_loss</span><span class="p">,</span> <span class="n">activation_function</span><span class="p">,</span> <span class="n">num_input_layers</span><span class="p">,</span> <span class="n">num_output_layers</span><span class="p">,</span> <span class="n">hidden_layers</span><span class="p">,</span> <span class="n">x_vals</span><span class="p">,</span> <span class="n">preproc</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">,</span> <span class="n">lag_mult_pos</span><span class="p">,</span> <span class="n">lag_mult_int</span><span class="p">,</span> <span class="n">x_int</span><span class="p">,</span> <span class="n">num_folds</span><span class="p">)</span></code>

<a href="#NN_fit.hyperopt_nu_nub.perform_fit" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Performs k-fold cross-validation training and evaluation of a neural network
for muon neutrino flux prediction using Bayesian-inspired randomized hyperparameters.</p>
<p>This function trains a <code>PreprocessedMLP</code> model to predict neutrino and antineutrino
event distributions, optimizing a custom loss function that incorporates physical
constraints and covariance information. It performs training with early stopping
based on validation loss, and evaluates generalization via a held-out fold.</p>
<h4 id="NN_fit.hyperopt_nu_nub.perform_fit--parameters">Parameters:<a class="headerlink" href="#NN_fit.hyperopt_nu_nub.perform_fit--parameters" title="Permanent link">&para;</a></h4>
<p>pred : List[np.ndarray]
    List containing ground truth predicted neutrino events for training and evaluation.
range_alpha : float
    Upper bound for random initialization of the alpha hyperparameter.
range_beta : float
    Upper bound for random initialization of the beta hyperparameter.
range_gamma : float
    Upper bound for random initialization of the gamma hyperparameter.
lr : float
    Learning rate for the optimizer.
wd : float
    Weight decay (L2 regularization) for the optimizer.
patience : int
    Number of epochs to wait without validation improvement before early stopping.
x_alphas : torch.Tensor
    Input tensor used for prediction by the model.
fk_tables_mu : torch.Tensor
    Forward-folding kernel table for muon neutrinos.
fk_tables_mub : torch.Tensor
    Forward-folding kernel table for anti-muon neutrinos.
binwidths_mu : torch.Tensor
    Bin widths used for muon neutrino predictions.
binwidths_mub : torch.Tensor
    Bin widths used for anti-muon neutrino predictions.
cov_matrix : np.ndarray
    Covariance matrix for uncertainty propagation in loss computation.
extended_loss : bool
    Whether to include extended regularization terms in the custom loss.
activation_function : str
    Activation function to use in the model (e.g., "relu", "tanh").
num_input_layers : int
    Number of input features/layers for the model.
num_output_layers : int
    Number of outputs (e.g., neutrino types).
hidden_layers : List[int]
    Sizes of hidden layers in the MLP.
x_vals : np.ndarray
    Input data values used for training and evaluation.
preproc : str
    Type of input preprocessing to apply (e.g., "standard", "log").
max_epochs : int
    Maximum number of training epochs per fold.
lag_mult_pos : float
    Lagrange multiplier weight for positivity constraint in the loss.
lag_mult_int : float
    Lagrange multiplier weight for integral constraint in the loss.
x_int : np.ndarray
    Points at which the integrals for regularization are evaluated.
num_folds: int
    Number of k-folds</p>
<h4 id="NN_fit.hyperopt_nu_nub.perform_fit--returns">Returns:<a class="headerlink" href="#NN_fit.hyperopt_nu_nub.perform_fit--returns" title="Permanent link">&para;</a></h4>
<p>Tuple[
    List[float],           # chi_squares over training
    List[np.ndarray],      # Predicted neutrino event counts
    List[np.ndarray],      # Predicted neutrino PDFs
    PreprocessedMLP,       # Trained model instance
    List[float],           # Chi-square values for post-fit analysis
    np.ndarray,            # Training indices from final fold
    np.ndarray,            # Validation indices from final fold
    int                    # Total number of training iterations in last fold
]</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/hyperopt_nu_nub.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">perform_fit</span><span class="p">(</span>
    <span class="n">pred</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">range_alpha</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">range_beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">range_gamma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">wd</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">x_alphas</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">fk_tables_mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">fk_tables_mub</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">binwidths_mu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">binwidths_mub</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">cov_matrix</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">extended_loss</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">activation_function</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">num_input_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">num_output_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">hidden_layers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
    <span class="n">x_vals</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">preproc</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">lag_mult_pos</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">lag_mult_int</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">x_int</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">num_folds</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
    <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>  <span class="c1"># chi_squares</span>
    <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>  <span class="c1"># N_event_pred</span>
    <span class="n">List</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>  <span class="c1"># neutrino_pdfs</span>
    <span class="n">PreprocessedMLP</span><span class="p">,</span>  <span class="c1"># model (last accepted fit)</span>
    <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>  <span class="c1"># chi_square_for_postfit</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># train_indices</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># val_indices</span>
    <span class="nb">int</span><span class="p">,</span>  <span class="c1"># training_length</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Performs k-fold cross-validation training and evaluation of a neural network</span>
<span class="sd">    for muon neutrino flux prediction using Bayesian-inspired randomized hyperparameters.</span>

<span class="sd">    This function trains a `PreprocessedMLP` model to predict neutrino and antineutrino</span>
<span class="sd">    event distributions, optimizing a custom loss function that incorporates physical</span>
<span class="sd">    constraints and covariance information. It performs training with early stopping</span>
<span class="sd">    based on validation loss, and evaluates generalization via a held-out fold.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    ----------</span>
<span class="sd">    pred : List[np.ndarray]</span>
<span class="sd">        List containing ground truth predicted neutrino events for training and evaluation.</span>
<span class="sd">    range_alpha : float</span>
<span class="sd">        Upper bound for random initialization of the alpha hyperparameter.</span>
<span class="sd">    range_beta : float</span>
<span class="sd">        Upper bound for random initialization of the beta hyperparameter.</span>
<span class="sd">    range_gamma : float</span>
<span class="sd">        Upper bound for random initialization of the gamma hyperparameter.</span>
<span class="sd">    lr : float</span>
<span class="sd">        Learning rate for the optimizer.</span>
<span class="sd">    wd : float</span>
<span class="sd">        Weight decay (L2 regularization) for the optimizer.</span>
<span class="sd">    patience : int</span>
<span class="sd">        Number of epochs to wait without validation improvement before early stopping.</span>
<span class="sd">    x_alphas : torch.Tensor</span>
<span class="sd">        Input tensor used for prediction by the model.</span>
<span class="sd">    fk_tables_mu : torch.Tensor</span>
<span class="sd">        Forward-folding kernel table for muon neutrinos.</span>
<span class="sd">    fk_tables_mub : torch.Tensor</span>
<span class="sd">        Forward-folding kernel table for anti-muon neutrinos.</span>
<span class="sd">    binwidths_mu : torch.Tensor</span>
<span class="sd">        Bin widths used for muon neutrino predictions.</span>
<span class="sd">    binwidths_mub : torch.Tensor</span>
<span class="sd">        Bin widths used for anti-muon neutrino predictions.</span>
<span class="sd">    cov_matrix : np.ndarray</span>
<span class="sd">        Covariance matrix for uncertainty propagation in loss computation.</span>
<span class="sd">    extended_loss : bool</span>
<span class="sd">        Whether to include extended regularization terms in the custom loss.</span>
<span class="sd">    activation_function : str</span>
<span class="sd">        Activation function to use in the model (e.g., &quot;relu&quot;, &quot;tanh&quot;).</span>
<span class="sd">    num_input_layers : int</span>
<span class="sd">        Number of input features/layers for the model.</span>
<span class="sd">    num_output_layers : int</span>
<span class="sd">        Number of outputs (e.g., neutrino types).</span>
<span class="sd">    hidden_layers : List[int]</span>
<span class="sd">        Sizes of hidden layers in the MLP.</span>
<span class="sd">    x_vals : np.ndarray</span>
<span class="sd">        Input data values used for training and evaluation.</span>
<span class="sd">    preproc : str</span>
<span class="sd">        Type of input preprocessing to apply (e.g., &quot;standard&quot;, &quot;log&quot;).</span>
<span class="sd">    max_epochs : int</span>
<span class="sd">        Maximum number of training epochs per fold.</span>
<span class="sd">    lag_mult_pos : float</span>
<span class="sd">        Lagrange multiplier weight for positivity constraint in the loss.</span>
<span class="sd">    lag_mult_int : float</span>
<span class="sd">        Lagrange multiplier weight for integral constraint in the loss.</span>
<span class="sd">    x_int : np.ndarray</span>
<span class="sd">        Points at which the integrals for regularization are evaluated.</span>
<span class="sd">    num_folds: int</span>
<span class="sd">        Number of k-folds</span>

<span class="sd">    Returns:</span>
<span class="sd">    -------</span>
<span class="sd">    Tuple[</span>
<span class="sd">        List[float],           # chi_squares over training</span>
<span class="sd">        List[np.ndarray],      # Predicted neutrino event counts</span>
<span class="sd">        List[np.ndarray],      # Predicted neutrino PDFs</span>
<span class="sd">        PreprocessedMLP,       # Trained model instance</span>
<span class="sd">        List[float],           # Chi-square values for post-fit analysis</span>
<span class="sd">        np.ndarray,            # Training indices from final fold</span>
<span class="sd">        np.ndarray,            # Validation indices from final fold</span>
<span class="sd">        int                    # Total number of training iterations in last fold</span>
<span class="sd">    ]</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="p">(</span>
        <span class="n">chi_squares</span><span class="p">,</span>
        <span class="n">k_fold_losses</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">[],</span>
        <span class="p">[],</span>
    <span class="p">)</span>
    <span class="n">x_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_vals</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">x_int</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_int</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="n">k</span> <span class="o">=</span> <span class="n">num_folds</span>
    <span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">k</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

    <span class="n">folds</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">indices</span><span class="p">):</span>
        <span class="n">folds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
        <span class="n">train_indices</span> <span class="o">=</span> <span class="n">folds</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">val_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">int</span><span class="p">(</span><span class="mf">0.1</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_indices</span><span class="p">)))</span>
        <span class="n">val_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">train_indices</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">val_size</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">k_fold_indices</span> <span class="o">=</span> <span class="n">folds</span><span class="p">[</span><span class="n">j</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>

        <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="n">range_alpha</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="n">range_beta</span><span class="p">,</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span> <span class="o">*</span> <span class="n">range_gamma</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">PreprocessedMLP</span><span class="p">(</span>
            <span class="n">alpha</span><span class="p">,</span>
            <span class="n">beta</span><span class="p">,</span>
            <span class="n">gamma</span><span class="p">,</span>
            <span class="n">activation_function</span><span class="p">,</span>
            <span class="n">hidden_layers</span><span class="p">,</span>
            <span class="n">num_input_layers</span><span class="p">,</span>
            <span class="n">num_output_layers</span><span class="p">,</span>
            <span class="n">preproc</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">criterion</span> <span class="o">=</span> <span class="n">CustomLoss</span><span class="p">(</span>
            <span class="n">extended_loss</span><span class="p">,</span>
            <span class="n">num_output_layers</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">wd</span><span class="p">)</span>

        <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        <span class="n">best_loss</span> <span class="o">=</span> <span class="mf">1e13</span>  <span class="c1"># initial loss</span>
        <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">training_length</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">while</span> <span class="n">counter</span> <span class="o">&lt;</span> <span class="n">patience</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">max_epochs</span> <span class="o">&lt;</span> <span class="n">training_length</span><span class="p">:</span>
                <span class="k">break</span>

            <span class="n">training_length</span> <span class="o">+=</span> <span class="mi">1</span>

            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_alphas</span><span class="p">)</span>

            <span class="n">y_pred_mu</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">fk_tables_mu</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">binwidths_mu</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="p">)</span>
            <span class="n">y_pred_mub</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">fk_tables_mub</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span> <span class="o">*</span> <span class="n">binwidths_mub</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="n">y_pred_mu</span> <span class="o">=</span> <span class="n">y_pred_mu</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
            <span class="n">y_pred_mub</span> <span class="o">=</span> <span class="n">y_pred_mub</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>

            <span class="n">y_preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">y_pred_mu</span><span class="p">,</span> <span class="n">y_pred_mub</span><span class="p">))</span>

            <span class="n">y_train</span> <span class="o">=</span> <span class="n">y_preds</span><span class="p">[</span><span class="n">train_indices</span><span class="p">]</span>
            <span class="n">pred_train</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">train_indices</span><span class="p">]</span>
            <span class="n">cov_matrix_train</span> <span class="o">=</span> <span class="n">cov_matrix</span><span class="p">[</span><span class="n">train_indices</span><span class="p">][:,</span> <span class="n">train_indices</span><span class="p">]</span>
            <span class="n">y_int_mu</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_int</span><span class="p">)[:,</span> <span class="mi">0</span><span class="p">]</span>
            <span class="n">y_int_mub</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x_int</span><span class="p">)[:,</span> <span class="mi">1</span><span class="p">]</span>

            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
                <span class="n">y_train</span><span class="p">,</span>
                <span class="n">pred_train</span><span class="p">,</span>
                <span class="n">cov_matrix_train</span><span class="p">,</span>
                <span class="n">y_int_mu</span><span class="p">,</span>
                <span class="n">y_int_mub</span><span class="p">,</span>
                <span class="n">y_pred</span><span class="p">,</span>
                <span class="n">x_int</span><span class="p">,</span>
                <span class="n">lag_mult_pos</span><span class="p">,</span>
                <span class="n">lag_mult_int</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="c1"># print(loss)</span>

            <span class="n">y_val</span> <span class="o">=</span> <span class="n">y_preds</span><span class="p">[</span><span class="n">val_indices</span><span class="p">]</span>
            <span class="n">pred_val</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">val_indices</span><span class="p">]</span>
            <span class="n">cov_matrix_val</span> <span class="o">=</span> <span class="n">cov_matrix</span><span class="p">[</span><span class="n">val_indices</span><span class="p">][:,</span> <span class="n">val_indices</span><span class="p">]</span>

            <span class="n">loss_val</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
                <span class="n">y_val</span><span class="p">,</span>
                <span class="n">pred_val</span><span class="p">,</span>
                <span class="n">cov_matrix_val</span><span class="p">,</span>
                <span class="n">y_int_mu</span><span class="p">,</span>
                <span class="n">y_int_mub</span><span class="p">,</span>
                <span class="n">y_pred</span><span class="p">,</span>
                <span class="n">x_int</span><span class="p">,</span>
                <span class="n">lag_mult_pos</span><span class="p">,</span>
                <span class="n">lag_mult_int</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="n">training_length</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">chi_squares</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>

            <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="k">if</span> <span class="n">loss_val</span> <span class="o">&lt;</span> <span class="n">best_loss</span><span class="p">:</span>
                <span class="n">best_loss</span> <span class="o">=</span> <span class="n">loss_val</span>
                <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>

        <span class="n">y_k_fold</span> <span class="o">=</span> <span class="n">y_preds</span><span class="p">[</span><span class="n">k_fold_indices</span><span class="p">]</span>
        <span class="n">pred_k_fold</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">k_fold_indices</span><span class="p">]</span>
        <span class="n">cov_matrix_k_fold</span> <span class="o">=</span> <span class="n">cov_matrix</span><span class="p">[</span><span class="n">k_fold_indices</span><span class="p">][:,</span> <span class="n">k_fold_indices</span><span class="p">]</span>

        <span class="n">loss_k_fold</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span>
            <span class="n">y_k_fold</span><span class="p">,</span>
            <span class="n">pred_k_fold</span><span class="p">,</span>
            <span class="n">cov_matrix_k_fold</span><span class="p">,</span>
            <span class="n">y_int_mu</span><span class="p">,</span>
            <span class="n">y_int_mub</span><span class="p">,</span>
            <span class="n">y_pred</span><span class="p">,</span>
            <span class="n">x_int</span><span class="p">,</span>
            <span class="n">lag_mult_pos</span><span class="p">,</span>
            <span class="n">lag_mult_int</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">k_fold_loss</span> <span class="o">=</span> <span class="n">loss_k_fold</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">k_fold_losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">k_fold_loss</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;k_fold_losses&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">k_fold_losses</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">k_fold_losses</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><hr />
<h2 id="model-architecture">🧠 Model Architecture<a class="headerlink" href="#model-architecture" title="Permanent link">&para;</a></h2>
<h3 id="structure_nnpy"><code>structure_NN.py</code><a class="headerlink" href="#structure_nnpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.structure_NN"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="NN_fit.structure_NN.CustomLoss" class="doc doc-heading">
            <code>CustomLoss</code>


<a href="#NN_fit.structure_NN.CustomLoss" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


        <p>Custom loss function wrapper supporting multiple modes: raw chi-squared, or extended with constraints.</p>
<h4 id="NN_fit.structure_NN.CustomLoss--parameters">Parameters<a class="headerlink" href="#NN_fit.structure_NN.CustomLoss--parameters" title="Permanent link">&para;</a></h4>
<p>extended_loss : bool
    If True, uses extended loss with positivity and normalization constraints.
num_output_layers : int
    Determines loss mode: 1 for combined ν+ν̄, 2 for separate ν and ν̄ losses.</p>
<h4 id="NN_fit.structure_NN.CustomLoss--methods">Methods<a class="headerlink" href="#NN_fit.structure_NN.CustomLoss--methods" title="Permanent link">&para;</a></h4>
<p>forward(pred, data, cov_matrix, small_x_point1, small_x_point2, model, x_int, lag_mult_pos, lag_mult_int)
    Computes the loss.</p>







              <details class="quote">
                <summary>Source code in <code>NN_fit/structure_NN.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">CustomLoss</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Custom loss function wrapper supporting multiple modes: raw chi-squared, or extended with constraints.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    extended_loss : bool</span>
<span class="sd">        If True, uses extended loss with positivity and normalization constraints.</span>
<span class="sd">    num_output_layers : int</span>
<span class="sd">        Determines loss mode: 1 for combined ν+ν̄, 2 for separate ν and ν̄ losses.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    forward(pred, data, cov_matrix, small_x_point1, small_x_point2, model, x_int, lag_mult_pos, lag_mult_int)</span>
<span class="sd">        Computes the loss.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">extended_loss</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">num_output_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CustomLoss</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">extended_loss</span> <span class="o">=</span> <span class="n">extended_loss</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_output_layers</span> <span class="o">=</span> <span class="n">num_output_layers</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pred</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">cov_matrix</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">small_x_point1</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">small_x_point2</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">x_int</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">lag_mult_pos</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">lag_mult_int</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Computes the loss function.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        pred : torch.Tensor</span>
<span class="sd">            Model prediction.</span>
<span class="sd">        data : torch.Tensor</span>
<span class="sd">            Target data (pseudo-data).</span>
<span class="sd">        cov_matrix : np.ndarray or torch.Tensor</span>
<span class="sd">            Covariance matrix for data.</span>
<span class="sd">        small_x_point1 : torch.Tensor</span>
<span class="sd">            Neural prediction before preprocessing (ν or combined).</span>
<span class="sd">        small_x_point2 : torch.Tensor</span>
<span class="sd">            Neural prediction before preprocessing (ν̄, if using two outputs).</span>
<span class="sd">        model : torch.nn.Module</span>
<span class="sd">            Reference to the model (used for constraints).</span>
<span class="sd">        x_int : torch.Tensor</span>
<span class="sd">            x-points for integral constraint.</span>
<span class="sd">        lag_mult_pos : float</span>
<span class="sd">            Lagrange multiplier for positivity.</span>
<span class="sd">        lag_mult_int : float</span>
<span class="sd">            Lagrange multiplier for integral constraint.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Final loss scalar.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">extended_loss</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_output_layers</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">complete_loss_fct_comb</span><span class="p">(</span>
                    <span class="n">pred</span><span class="p">,</span>
                    <span class="n">data</span><span class="p">,</span>
                    <span class="n">cov_matrix</span><span class="p">,</span>
                    <span class="n">small_x_point1</span><span class="p">,</span>
                    <span class="n">model</span><span class="p">,</span>
                    <span class="n">x_int</span><span class="p">,</span>
                    <span class="n">lag_mult_pos</span><span class="p">,</span>
                    <span class="n">lag_mult_int</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_output_layers</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">complete_loss_fct_nu_nub</span><span class="p">(</span>
                    <span class="n">pred</span><span class="p">,</span>
                    <span class="n">data</span><span class="p">,</span>
                    <span class="n">cov_matrix</span><span class="p">,</span>
                    <span class="n">small_x_point1</span><span class="p">,</span>
                    <span class="n">small_x_point2</span><span class="p">,</span>
                    <span class="n">model</span><span class="p">,</span>
                    <span class="n">x_int</span><span class="p">,</span>
                    <span class="n">lag_mult_pos</span><span class="p">,</span>
                    <span class="n">lag_mult_int</span><span class="p">,</span>
                <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">raw_loss_fct</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="NN_fit.structure_NN.CustomLoss.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="p">,</span> <span class="n">small_x_point1</span><span class="p">,</span> <span class="n">small_x_point2</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">x_int</span><span class="p">,</span> <span class="n">lag_mult_pos</span><span class="p">,</span> <span class="n">lag_mult_int</span><span class="p">)</span></code>

<a href="#NN_fit.structure_NN.CustomLoss.forward" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Computes the loss function.</p>
<h5 id="NN_fit.structure_NN.CustomLoss.forward--parameters">Parameters<a class="headerlink" href="#NN_fit.structure_NN.CustomLoss.forward--parameters" title="Permanent link">&para;</a></h5>
<p>pred : torch.Tensor
    Model prediction.
data : torch.Tensor
    Target data (pseudo-data).
cov_matrix : np.ndarray or torch.Tensor
    Covariance matrix for data.
small_x_point1 : torch.Tensor
    Neural prediction before preprocessing (ν or combined).
small_x_point2 : torch.Tensor
    Neural prediction before preprocessing (ν̄, if using two outputs).
model : torch.nn.Module
    Reference to the model (used for constraints).
x_int : torch.Tensor
    x-points for integral constraint.
lag_mult_pos : float
    Lagrange multiplier for positivity.
lag_mult_int : float
    Lagrange multiplier for integral constraint.</p>
<h5 id="NN_fit.structure_NN.CustomLoss.forward--returns">Returns<a class="headerlink" href="#NN_fit.structure_NN.CustomLoss.forward--returns" title="Permanent link">&para;</a></h5>
<p>torch.Tensor
    Final loss scalar.</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/structure_NN.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">pred</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">cov_matrix</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">small_x_point1</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">small_x_point2</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">x_int</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">lag_mult_pos</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">lag_mult_int</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes the loss function.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pred : torch.Tensor</span>
<span class="sd">        Model prediction.</span>
<span class="sd">    data : torch.Tensor</span>
<span class="sd">        Target data (pseudo-data).</span>
<span class="sd">    cov_matrix : np.ndarray or torch.Tensor</span>
<span class="sd">        Covariance matrix for data.</span>
<span class="sd">    small_x_point1 : torch.Tensor</span>
<span class="sd">        Neural prediction before preprocessing (ν or combined).</span>
<span class="sd">    small_x_point2 : torch.Tensor</span>
<span class="sd">        Neural prediction before preprocessing (ν̄, if using two outputs).</span>
<span class="sd">    model : torch.nn.Module</span>
<span class="sd">        Reference to the model (used for constraints).</span>
<span class="sd">    x_int : torch.Tensor</span>
<span class="sd">        x-points for integral constraint.</span>
<span class="sd">    lag_mult_pos : float</span>
<span class="sd">        Lagrange multiplier for positivity.</span>
<span class="sd">    lag_mult_int : float</span>
<span class="sd">        Lagrange multiplier for integral constraint.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        Final loss scalar.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">extended_loss</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_output_layers</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">complete_loss_fct_comb</span><span class="p">(</span>
                <span class="n">pred</span><span class="p">,</span>
                <span class="n">data</span><span class="p">,</span>
                <span class="n">cov_matrix</span><span class="p">,</span>
                <span class="n">small_x_point1</span><span class="p">,</span>
                <span class="n">model</span><span class="p">,</span>
                <span class="n">x_int</span><span class="p">,</span>
                <span class="n">lag_mult_pos</span><span class="p">,</span>
                <span class="n">lag_mult_int</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_output_layers</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">complete_loss_fct_nu_nub</span><span class="p">(</span>
                <span class="n">pred</span><span class="p">,</span>
                <span class="n">data</span><span class="p">,</span>
                <span class="n">cov_matrix</span><span class="p">,</span>
                <span class="n">small_x_point1</span><span class="p">,</span>
                <span class="n">small_x_point2</span><span class="p">,</span>
                <span class="n">model</span><span class="p">,</span>
                <span class="n">x_int</span><span class="p">,</span>
                <span class="n">lag_mult_pos</span><span class="p">,</span>
                <span class="n">lag_mult_int</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">raw_loss_fct</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="NN_fit.structure_NN.CustomPreprocessing" class="doc doc-heading">
            <code>CustomPreprocessing</code>


<a href="#NN_fit.structure_NN.CustomPreprocessing" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


        <p>Applies a parameterized functional preprocessing to the input based on power-law forms.</p>


<details class="the-form-is" open>
  <summary>The form is</summary>
  <p>f(x) = γ * (1 - x)^β * x^(1 - α)</p>
</details>        <h4 id="NN_fit.structure_NN.CustomPreprocessing--parameters">Parameters<a class="headerlink" href="#NN_fit.structure_NN.CustomPreprocessing--parameters" title="Permanent link">&para;</a></h4>
<p>alpha : float
    Initial value for α parameter.
beta : float
    Initial value for β parameter.
gamma : float
    Initial value for γ parameter.
preproc : bool
    If True, alpha, beta, and gamma are learnable parameters. Otherwise, they are fixed.</p>
<h4 id="NN_fit.structure_NN.CustomPreprocessing--notes">Notes<a class="headerlink" href="#NN_fit.structure_NN.CustomPreprocessing--notes" title="Permanent link">&para;</a></h4>
<ul>
<li>Input values are clamped between [1e-6, 1 - 1e-6] for numerical stability.</li>
</ul>







              <details class="quote">
                <summary>Source code in <code>NN_fit/structure_NN.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">CustomPreprocessing</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies a parameterized functional preprocessing to the input based on power-law forms.</span>

<span class="sd">    The form is:</span>
<span class="sd">        f(x) = γ * (1 - x)^β * x^(1 - α)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    alpha : float</span>
<span class="sd">        Initial value for α parameter.</span>
<span class="sd">    beta : float</span>
<span class="sd">        Initial value for β parameter.</span>
<span class="sd">    gamma : float</span>
<span class="sd">        Initial value for γ parameter.</span>
<span class="sd">    preproc : bool</span>
<span class="sd">        If True, alpha, beta, and gamma are learnable parameters. Otherwise, they are fixed.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - Input values are clamped between [1e-6, 1 - 1e-6] for numerical stability.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">preproc</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CustomPreprocessing</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">preproc</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;beta&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">beta</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;gamma&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">gamma</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Applies the preprocessing function.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : torch.Tensor</span>
<span class="sd">            Input tensor of shape (N, 1).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Preprocessed output of same shape.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="mf">1e-6</span><span class="p">)</span>
        <span class="n">beta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">**</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="NN_fit.structure_NN.CustomPreprocessing.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

<a href="#NN_fit.structure_NN.CustomPreprocessing.forward" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Applies the preprocessing function.</p>
<h5 id="NN_fit.structure_NN.CustomPreprocessing.forward--parameters">Parameters<a class="headerlink" href="#NN_fit.structure_NN.CustomPreprocessing.forward--parameters" title="Permanent link">&para;</a></h5>
<p>x : torch.Tensor
    Input tensor of shape (N, 1).</p>
<h5 id="NN_fit.structure_NN.CustomPreprocessing.forward--returns">Returns<a class="headerlink" href="#NN_fit.structure_NN.CustomPreprocessing.forward--returns" title="Permanent link">&para;</a></h5>
<p>torch.Tensor
    Preprocessed output of same shape.</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/structure_NN.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies the preprocessing function.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : torch.Tensor</span>
<span class="sd">        Input tensor of shape (N, 1).</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        Preprocessed output of same shape.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="mf">1e-6</span><span class="p">)</span>
    <span class="n">beta</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span><span class="p">)</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">gamma</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">**</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="NN_fit.structure_NN.PreprocessedMLP" class="doc doc-heading">
            <code>PreprocessedMLP</code>


<a href="#NN_fit.structure_NN.PreprocessedMLP" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


        <p>A neural network combining a preprocessing layer with an MLP.</p>
<h4 id="NN_fit.structure_NN.PreprocessedMLP--parameters">Parameters<a class="headerlink" href="#NN_fit.structure_NN.PreprocessedMLP--parameters" title="Permanent link">&para;</a></h4>
<p>alpha, beta, gamma : float
    Parameters for the preprocessing function.
activation_function : list of str
    Activation functions for the MLP.
hidden_layers : list of int
    Sizes of hidden layers.
num_input_layers : int
    Number of input features.
num_output_layers : int
    Number of output features.
preproc : bool
    Whether to use preprocessing.</p>
<h4 id="NN_fit.structure_NN.PreprocessedMLP--attributes">Attributes<a class="headerlink" href="#NN_fit.structure_NN.PreprocessedMLP--attributes" title="Permanent link">&para;</a></h4>
<p>preprocessing : CustomPreprocessing
    The preprocessing module applied before the MLP.
mlp : SimplePerceptron
    The neural network model applied to the preprocessed inputs.</p>
<h4 id="NN_fit.structure_NN.PreprocessedMLP--methods">Methods<a class="headerlink" href="#NN_fit.structure_NN.PreprocessedMLP--methods" title="Permanent link">&para;</a></h4>
<p>forward(x)
    Applies preprocessing (if enabled) followed by the MLP.
neuralnet(x)
    Returns raw MLP output (no preprocessing).
preproces(x)
    Returns the preprocessing factor only.</p>







              <details class="quote">
                <summary>Source code in <code>NN_fit/structure_NN.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">PreprocessedMLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A neural network combining a preprocessing layer with an MLP.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    alpha, beta, gamma : float</span>
<span class="sd">        Parameters for the preprocessing function.</span>
<span class="sd">    activation_function : list of str</span>
<span class="sd">        Activation functions for the MLP.</span>
<span class="sd">    hidden_layers : list of int</span>
<span class="sd">        Sizes of hidden layers.</span>
<span class="sd">    num_input_layers : int</span>
<span class="sd">        Number of input features.</span>
<span class="sd">    num_output_layers : int</span>
<span class="sd">        Number of output features.</span>
<span class="sd">    preproc : bool</span>
<span class="sd">        Whether to use preprocessing.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    preprocessing : CustomPreprocessing</span>
<span class="sd">        The preprocessing module applied before the MLP.</span>
<span class="sd">    mlp : SimplePerceptron</span>
<span class="sd">        The neural network model applied to the preprocessed inputs.</span>

<span class="sd">    Methods</span>
<span class="sd">    -------</span>
<span class="sd">    forward(x)</span>
<span class="sd">        Applies preprocessing (if enabled) followed by the MLP.</span>
<span class="sd">    neuralnet(x)</span>
<span class="sd">        Returns raw MLP output (no preprocessing).</span>
<span class="sd">    preproces(x)</span>
<span class="sd">        Returns the preprocessing factor only.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">alpha</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">gamma</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">activation_function</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">hidden_layers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">num_input_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_output_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">preproc</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PreprocessedMLP</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span> <span class="o">=</span> <span class="n">CustomPreprocessing</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">preproc</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">SimplePerceptron</span><span class="p">(</span>
            <span class="n">activation_function</span><span class="p">,</span> <span class="n">num_input_layers</span><span class="p">,</span> <span class="n">hidden_layers</span><span class="p">,</span> <span class="n">num_output_layers</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">preproc</span> <span class="o">=</span> <span class="n">preproc</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Full forward pass through preprocessing and MLP.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : torch.Tensor</span>
<span class="sd">            Input tensor.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Output of the combined preprocessing and MLP.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">preproc</span><span class="p">:</span>
            <span class="n">f_preproc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">f_NN</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">f_nu</span> <span class="o">=</span> <span class="n">f_preproc</span> <span class="o">*</span> <span class="n">f_NN</span>
            <span class="k">return</span> <span class="n">f_nu</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">f_NN</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">f_NN</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">neuralnet</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass through only the MLP (no preprocessing).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : torch.Tensor</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">f_NN</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">f_NN</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">preproces</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Returns the preprocessing term γ * (1 - x)^β * x^(1 - α)</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : torch.Tensor</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">f_preproc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">f_preproc</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="NN_fit.structure_NN.PreprocessedMLP.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

<a href="#NN_fit.structure_NN.PreprocessedMLP.forward" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Full forward pass through preprocessing and MLP.</p>
<h5 id="NN_fit.structure_NN.PreprocessedMLP.forward--parameters">Parameters<a class="headerlink" href="#NN_fit.structure_NN.PreprocessedMLP.forward--parameters" title="Permanent link">&para;</a></h5>
<p>x : torch.Tensor
    Input tensor.</p>
<h5 id="NN_fit.structure_NN.PreprocessedMLP.forward--returns">Returns<a class="headerlink" href="#NN_fit.structure_NN.PreprocessedMLP.forward--returns" title="Permanent link">&para;</a></h5>
<p>torch.Tensor
    Output of the combined preprocessing and MLP.</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/structure_NN.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Full forward pass through preprocessing and MLP.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : torch.Tensor</span>
<span class="sd">        Input tensor.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        Output of the combined preprocessing and MLP.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">preproc</span><span class="p">:</span>
        <span class="n">f_preproc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">f_NN</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">f_nu</span> <span class="o">=</span> <span class="n">f_preproc</span> <span class="o">*</span> <span class="n">f_NN</span>
        <span class="k">return</span> <span class="n">f_nu</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">f_NN</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">f_NN</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="NN_fit.structure_NN.PreprocessedMLP.neuralnet" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">neuralnet</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

<a href="#NN_fit.structure_NN.PreprocessedMLP.neuralnet" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Forward pass through only the MLP (no preprocessing).</p>
<h5 id="NN_fit.structure_NN.PreprocessedMLP.neuralnet--parameters">Parameters<a class="headerlink" href="#NN_fit.structure_NN.PreprocessedMLP.neuralnet--parameters" title="Permanent link">&para;</a></h5>
<p>x : torch.Tensor</p>
<h5 id="NN_fit.structure_NN.PreprocessedMLP.neuralnet--returns">Returns<a class="headerlink" href="#NN_fit.structure_NN.PreprocessedMLP.neuralnet--returns" title="Permanent link">&para;</a></h5>
<p>torch.Tensor</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/structure_NN.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">neuralnet</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Forward pass through only the MLP (no preprocessing).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : torch.Tensor</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">f_NN</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">f_NN</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="NN_fit.structure_NN.PreprocessedMLP.preproces" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">preproces</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

<a href="#NN_fit.structure_NN.PreprocessedMLP.preproces" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Returns the preprocessing term γ * (1 - x)^β * x^(1 - α)</p>
<h5 id="NN_fit.structure_NN.PreprocessedMLP.preproces--parameters">Parameters<a class="headerlink" href="#NN_fit.structure_NN.PreprocessedMLP.preproces--parameters" title="Permanent link">&para;</a></h5>
<p>x : torch.Tensor</p>
<h5 id="NN_fit.structure_NN.PreprocessedMLP.preproces--returns">Returns<a class="headerlink" href="#NN_fit.structure_NN.PreprocessedMLP.preproces--returns" title="Permanent link">&para;</a></h5>
<p>torch.Tensor</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/structure_NN.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">preproces</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Returns the preprocessing term γ * (1 - x)^β * x^(1 - α)</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : torch.Tensor</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">f_preproc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">preprocessing</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">f_preproc</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>

<div class="doc doc-object doc-class">



<h2 id="NN_fit.structure_NN.SimplePerceptron" class="doc doc-heading">
            <code>SimplePerceptron</code>


<a href="#NN_fit.structure_NN.SimplePerceptron" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">
            <p class="doc doc-class-bases">
              Bases: <code><span title="torch.nn.Module">Module</span></code></p>


        <p>A feedforward multilayer perceptron (MLP) with configurable activation functions and layer sizes.</p>
<h4 id="NN_fit.structure_NN.SimplePerceptron--parameters">Parameters<a class="headerlink" href="#NN_fit.structure_NN.SimplePerceptron--parameters" title="Permanent link">&para;</a></h4>
<p>act_functions : list of str
    List of activation function names (e.g., ['relu', 'relu', 'softplus']) for each layer.
num_input_layers : int
    Number of input features.
hidden_layers : list of int
    List of integers specifying the number of units in each hidden layer.
num_output_layers : int
    Number of output features.</p>
<h4 id="NN_fit.structure_NN.SimplePerceptron--attributes">Attributes<a class="headerlink" href="#NN_fit.structure_NN.SimplePerceptron--attributes" title="Permanent link">&para;</a></h4>
<p>layers : nn.Sequential
    Composed list of linear and activation layers forming the MLP.</p>
<h4 id="NN_fit.structure_NN.SimplePerceptron--notes">Notes<a class="headerlink" href="#NN_fit.structure_NN.SimplePerceptron--notes" title="Permanent link">&para;</a></h4>
<ul>
<li>Supported activation functions: 'relu', 'softplus'.</li>
<li>The last activation is applied after the final output layer.</li>
</ul>







              <details class="quote">
                <summary>Source code in <code>NN_fit/structure_NN.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">SimplePerceptron</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    A feedforward multilayer perceptron (MLP) with configurable activation functions and layer sizes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    act_functions : list of str</span>
<span class="sd">        List of activation function names (e.g., [&#39;relu&#39;, &#39;relu&#39;, &#39;softplus&#39;]) for each layer.</span>
<span class="sd">    num_input_layers : int</span>
<span class="sd">        Number of input features.</span>
<span class="sd">    hidden_layers : list of int</span>
<span class="sd">        List of integers specifying the number of units in each hidden layer.</span>
<span class="sd">    num_output_layers : int</span>
<span class="sd">        Number of output features.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    layers : nn.Sequential</span>
<span class="sd">        Composed list of linear and activation layers forming the MLP.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - Supported activation functions: &#39;relu&#39;, &#39;softplus&#39;.</span>
<span class="sd">    - The last activation is applied after the final output layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">act_functions</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
        <span class="n">num_input_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">hidden_layers</span><span class="p">:</span> <span class="nb">list</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
        <span class="n">num_output_layers</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">activation_map</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;softplus&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">,</span>
            <span class="s2">&quot;relu&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
            <span class="s2">&quot;tanh&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">,</span>
            <span class="s2">&quot;sigmoid&quot;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="n">activation_names</span> <span class="o">=</span> <span class="n">act_functions</span>

        <span class="n">act_functions</span> <span class="o">=</span> <span class="p">[</span><span class="n">activation_map</span><span class="p">[</span><span class="n">name</span><span class="p">]()</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">activation_names</span><span class="p">]</span>

        <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_input_layers</span><span class="p">,</span> <span class="n">hidden_layers</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">act_functions</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">hidden_layers</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_layers</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">hidden_layers</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))</span>
            <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">act_functions</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>

        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_layers</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_output_layers</span><span class="p">))</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">act_functions</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Forward pass through the MLP.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : torch.Tensor</span>
<span class="sd">            Input tensor of shape (batch_size, num_input_layers)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Output tensor of shape (batch_size, num_output_layers)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="NN_fit.structure_NN.SimplePerceptron.forward" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">forward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span></code>

<a href="#NN_fit.structure_NN.SimplePerceptron.forward" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Forward pass through the MLP.</p>
<h5 id="NN_fit.structure_NN.SimplePerceptron.forward--parameters">Parameters<a class="headerlink" href="#NN_fit.structure_NN.SimplePerceptron.forward--parameters" title="Permanent link">&para;</a></h5>
<p>x : torch.Tensor
    Input tensor of shape (batch_size, num_input_layers)</p>
<h5 id="NN_fit.structure_NN.SimplePerceptron.forward--returns">Returns<a class="headerlink" href="#NN_fit.structure_NN.SimplePerceptron.forward--returns" title="Permanent link">&para;</a></h5>
<p>torch.Tensor
    Output tensor of shape (batch_size, num_output_layers)</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/structure_NN.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Forward pass through the MLP.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x : torch.Tensor</span>
<span class="sd">        Input tensor of shape (batch_size, num_input_layers)</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        Output tensor of shape (batch_size, num_output_layers)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div><hr />
<h2 id="plotting-and-visualization">📈 Plotting and Visualization<a class="headerlink" href="#plotting-and-visualization" title="Permanent link">&para;</a></h2>
<h3 id="plot_comb_pdf_clpy"><code>plot_comb_pdf_cl.py</code><a class="headerlink" href="#plot_comb_pdf_clpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.plot_comb_pdf_cl"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">











  </div>

    </div>

</div><h3 id="plot_diff_level1_combpy"><code>plot_diff_level1_comb.py</code><a class="headerlink" href="#plot_diff_level1_combpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.plot_diff_level1_comb"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">











  </div>

    </div>

</div><h3 id="plot_for_diff_level_1_shifts_nu_nubpy"><code>plot_for_diff_level_1_shifts_nu_nub.py</code><a class="headerlink" href="#plot_for_diff_level_1_shifts_nu_nubpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.plot_for_diff_level_1_shifts_nu_nub"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">











  </div>

    </div>

</div><h3 id="plot_nu_nub_clpy"><code>plot_nu_nub_cl.py</code><a class="headerlink" href="#plot_nu_nub_clpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.plot_nu_nub_cl"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">











  </div>

    </div>

</div><hr />
<h2 id="pdf-output">📦 PDF Output<a class="headerlink" href="#pdf-output" title="Permanent link">&para;</a></h2>
<h3 id="write_all_pdfs_to_lhapdfpy"><code>write_all_pdfs_to_lhapdf.py</code><a class="headerlink" href="#write_all_pdfs_to_lhapdfpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.write_all_pdfs_to_lhapdf"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h2 id="NN_fit.write_all_pdfs_to_lhapdf.customize_info_file" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">customize_info_file</span><span class="p">(</span><span class="n">template_path</span><span class="p">,</span> <span class="n">output_path</span><span class="p">,</span> <span class="n">set_index</span><span class="p">,</span> <span class="n">flavor</span><span class="p">,</span> <span class="n">num_members</span><span class="p">)</span></code>

<a href="#NN_fit.write_all_pdfs_to_lhapdf.customize_info_file" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Creates a customized LHAPDF <code>.info</code> file from a template by replacing placeholders.</p>
<h4 id="NN_fit.write_all_pdfs_to_lhapdf.customize_info_file--parameters">Parameters:<a class="headerlink" href="#NN_fit.write_all_pdfs_to_lhapdf.customize_info_file--parameters" title="Permanent link">&para;</a></h4>
<p>template_path : str
    Path to the <code>.info</code> template file containing placeholders (e.g., SETINDEX, FLAVOR).
output_path : str
    Path to the output <code>.info</code> file to be generated.
set_index : int
    Unique identifier for the PDF set (used to replace "SETINDEX" in the template).
flavor : str
    Flavor content to be listed in the info file (used to replace "FLAVOR").
    Can be a single PDG ID (e.g., "12") or a comma-separated list (e.g., "14, -14").
num_members : int
    Number of PDF members or replicas (used to replace the "NumMembers" field).</p>
<h4 id="NN_fit.write_all_pdfs_to_lhapdf.customize_info_file--notes">Notes:<a class="headerlink" href="#NN_fit.write_all_pdfs_to_lhapdf.customize_info_file--notes" title="Permanent link">&para;</a></h4>
<ul>
<li>The function assumes the template has default "NumMembers: 1000" and replaces that value.</li>
<li>All replaced content is written to the specified output path.</li>
</ul>


            <details class="quote">
              <summary>Source code in <code>NN_fit/write_all_pdfs_to_lhapdf.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span>
<span class="normal">75</span>
<span class="normal">76</span>
<span class="normal">77</span>
<span class="normal">78</span>
<span class="normal">79</span>
<span class="normal">80</span>
<span class="normal">81</span>
<span class="normal">82</span>
<span class="normal">83</span>
<span class="normal">84</span>
<span class="normal">85</span>
<span class="normal">86</span>
<span class="normal">87</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">customize_info_file</span><span class="p">(</span>
    <span class="n">template_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">output_path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">set_index</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">flavor</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">num_members</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Creates a customized LHAPDF `.info` file from a template by replacing placeholders.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    template_path : str</span>
<span class="sd">        Path to the `.info` template file containing placeholders (e.g., SETINDEX, FLAVOR).</span>
<span class="sd">    output_path : str</span>
<span class="sd">        Path to the output `.info` file to be generated.</span>
<span class="sd">    set_index : int</span>
<span class="sd">        Unique identifier for the PDF set (used to replace &quot;SETINDEX&quot; in the template).</span>
<span class="sd">    flavor : str</span>
<span class="sd">        Flavor content to be listed in the info file (used to replace &quot;FLAVOR&quot;).</span>
<span class="sd">        Can be a single PDG ID (e.g., &quot;12&quot;) or a comma-separated list (e.g., &quot;14, -14&quot;).</span>
<span class="sd">    num_members : int</span>
<span class="sd">        Number of PDF members or replicas (used to replace the &quot;NumMembers&quot; field).</span>

<span class="sd">    Notes:</span>
<span class="sd">    ------</span>
<span class="sd">    - The function assumes the template has default &quot;NumMembers: 1000&quot; and replaces that value.</span>
<span class="sd">    - All replaced content is written to the specified output path.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">template_path</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">file</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>

    <span class="n">content</span> <span class="o">=</span> <span class="n">content</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;SETINDEX&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">set_index</span><span class="p">))</span>
    <span class="n">content</span> <span class="o">=</span> <span class="n">content</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;FLAVOR&quot;</span><span class="p">,</span> <span class="nb">str</span><span class="p">(</span><span class="n">flavor</span><span class="p">))</span>
    <span class="n">content</span> <span class="o">=</span> <span class="n">content</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s2">&quot;NumMembers: 1000&quot;</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;NumMembers: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">num_members</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">output_path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">file</span><span class="p">:</span>
        <span class="n">file</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="NN_fit.write_all_pdfs_to_lhapdf.write_lhapdf_grid" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">write_lhapdf_grid</span><span class="p">(</span><span class="n">xgrid</span><span class="p">,</span> <span class="n">pdf_dict</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span></code>

<a href="#NN_fit.write_all_pdfs_to_lhapdf.write_lhapdf_grid" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Writes a set of neutrino PDFs to a file in LHAPDF grid format (lhagrid1).</p>
<p>This function formats and saves PDF data into a file readable by LHAPDF tools,
using the specified x-grid and dictionary of parton distribution functions.</p>
<h4 id="NN_fit.write_all_pdfs_to_lhapdf.write_lhapdf_grid--parameters">Parameters:<a class="headerlink" href="#NN_fit.write_all_pdfs_to_lhapdf.write_lhapdf_grid--parameters" title="Permanent link">&para;</a></h4>
<p>xgrid : array-like
    Array of Bjorken-x values at which PDFs are evaluated.
pdf_dict : dict
    Dictionary mapping particle IDs (PDG codes) to arrays of PDF values.
    Each value should be an array of length equal to the length of <code>xgrid</code>.
path : str
    Path to the output <code>.dat</code> file where the grid will be written.</p>
<h4 id="NN_fit.write_all_pdfs_to_lhapdf.write_lhapdf_grid--notes">Notes:<a class="headerlink" href="#NN_fit.write_all_pdfs_to_lhapdf.write_lhapdf_grid--notes" title="Permanent link">&para;</a></h4>
<ul>
<li>The output format follows LHAPDF's <code>lhagrid1</code> specification.</li>
<li>Each PDF line is duplicated, as required by the LHAPDF grid format.</li>
<li>The order of flavors is sorted by PDG code.</li>
</ul>


            <details class="quote">
              <summary>Source code in <code>NN_fit/write_all_pdfs_to_lhapdf.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">write_lhapdf_grid</span><span class="p">(</span>
    <span class="n">xgrid</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]],</span>
    <span class="n">pdf_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]]],</span>
    <span class="n">path</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Writes a set of neutrino PDFs to a file in LHAPDF grid format (lhagrid1).</span>

<span class="sd">    This function formats and saves PDF data into a file readable by LHAPDF tools,</span>
<span class="sd">    using the specified x-grid and dictionary of parton distribution functions.</span>

<span class="sd">    Parameters:</span>
<span class="sd">    -----------</span>
<span class="sd">    xgrid : array-like</span>
<span class="sd">        Array of Bjorken-x values at which PDFs are evaluated.</span>
<span class="sd">    pdf_dict : dict</span>
<span class="sd">        Dictionary mapping particle IDs (PDG codes) to arrays of PDF values.</span>
<span class="sd">        Each value should be an array of length equal to the length of `xgrid`.</span>
<span class="sd">    path : str</span>
<span class="sd">        Path to the output `.dat` file where the grid will be written.</span>

<span class="sd">    Notes:</span>
<span class="sd">    ------</span>
<span class="sd">    - The output format follows LHAPDF&#39;s `lhagrid1` specification.</span>
<span class="sd">    - Each PDF line is duplicated, as required by the LHAPDF grid format.</span>
<span class="sd">    - The order of flavors is sorted by PDG code.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">path</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;PdfType: replica</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;Format: lhagrid1</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;---</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;  &quot;</span> <span class="o">+</span> <span class="s2">&quot;  &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">val</span><span class="si">:</span><span class="s2">.8e</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">val</span> <span class="ow">in</span> <span class="n">xgrid</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;0.1E+001 0.1E+007</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">pids</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">pdf_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">pid</span><span class="p">)</span> <span class="k">for</span> <span class="n">pid</span> <span class="ow">in</span> <span class="n">pids</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">num_x</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">xgrid</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_x</span><span class="p">):</span>
            <span class="n">line</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">pdf_dict</span><span class="p">[</span><span class="n">pid</span><span class="p">][</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">.14e</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">pid</span> <span class="ow">in</span> <span class="n">pids</span><span class="p">)</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">line</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="s2">&quot;---</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><hr />
<h2 id="data-and-reading">🧪 Data and Reading<a class="headerlink" href="#data-and-reading" title="Permanent link">&para;</a></h2>
<h3 id="mc_data_repspy"><code>MC_data_reps.py</code><a class="headerlink" href="#mc_data_repspy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.MC_data_reps"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h2 id="NN_fit.MC_data_reps.generate_MC_replicas" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">generate_MC_replicas</span><span class="p">(</span><span class="n">REPLICAS</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">sig_sys</span><span class="p">,</span> <span class="n">sig_stat</span><span class="p">,</span> <span class="n">seed</span><span class="p">)</span></code>

<a href="#NN_fit.MC_data_reps.generate_MC_replicas" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Generate level 2 data MC replicas for the NN fit by adding a level 1 and then a level 2 gaussian noise to the data</p>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>tuple</code></td>            <td>
                  <code><span title="typing.Tuple">Tuple</span>[<span title="typing.List">List</span>[<span title="torch.Tensor">Tensor</span>], <span title="typing.List">List</span>[<span title="torch.Tensor">Tensor</span>], <span title="typing.List">List</span>[<span title="torch.Tensor">Tensor</span>]]</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>level 0,1 and 2 data</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>NN_fit/MC_data_reps.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">generate_MC_replicas</span><span class="p">(</span>
    <span class="n">REPLICAS</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">sig_sys</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">sig_stat</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Generate level 2 data MC replicas for the NN fit by adding a level 1 and then a level 2 gaussian noise to the data</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple: level 0,1 and 2 data</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">level0</span><span class="p">,</span> <span class="n">level1</span><span class="p">,</span> <span class="n">level2</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="n">rng_level1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">r_sys_1</span> <span class="o">=</span> <span class="n">rng_level1</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">*</span> <span class="n">sig_sys</span>
    <span class="n">r_stat_1</span> <span class="o">=</span> <span class="n">rng_level1</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">*</span> <span class="n">sig_stat</span>

    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">REPLICAS</span><span class="p">):</span>
        <span class="n">data_level1</span> <span class="o">=</span> <span class="n">data</span> <span class="o">+</span> <span class="n">r_sys_1</span> <span class="o">+</span> <span class="n">r_stat_1</span>
        <span class="n">r_sys_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">*</span> <span class="n">sig_sys</span>
        <span class="n">r_stat_2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">))</span> <span class="o">*</span> <span class="n">sig_stat</span>

        <span class="n">data_level2</span> <span class="o">=</span> <span class="n">data_level1</span> <span class="o">+</span> <span class="n">r_sys_2</span> <span class="o">+</span> <span class="n">r_stat_2</span>

        <span class="n">level0</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">level1</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data_level1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
        <span class="n">level2</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data_level2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">level0</span><span class="p">,</span> <span class="n">level1</span><span class="p">,</span> <span class="n">level2</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><h3 id="read_faserv_pdfpy"><code>read_faserv_pdf.py</code><a class="headerlink" href="#read_faserv_pdfpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.read_faserv_pdf"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h2 id="NN_fit.read_faserv_pdf.read_pdf" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">read_pdf</span><span class="p">(</span><span class="n">pdf</span><span class="p">,</span> <span class="n">x_vals</span><span class="p">,</span> <span class="n">particle</span><span class="p">,</span> <span class="nb">set</span><span class="p">)</span></code>

<a href="#NN_fit.read_faserv_pdf.read_pdf" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Reads the parton distribution function (PDF) values for a given particle
at specified momentum fractions and energy scale using LHAPDF.</p>
<h4 id="NN_fit.read_faserv_pdf.read_pdf--parameters">Parameters<a class="headerlink" href="#NN_fit.read_faserv_pdf.read_pdf--parameters" title="Permanent link">&para;</a></h4>
<p>pdf : str
    Name of the PDF set to load.
x_vals : np.ndarray
    Array of momentum fraction values (x) at which to evaluate the PDF.
particle : int
    Particle ID (PDG code) for which the PDF is evaluated.
set : int
    Specific member or set number within the PDF.</p>
<h4 id="NN_fit.read_faserv_pdf.read_pdf--returns">Returns<a class="headerlink" href="#NN_fit.read_faserv_pdf.read_pdf--returns" title="Permanent link">&para;</a></h4>
<p>Tuple[np.ndarray, np.ndarray]
    A tuple containing:
    - pdf_vals: np.ndarray of PDF values normalized by x_vals.
    - x_vals: The input array of momentum fractions.</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/read_faserv_pdf.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">read_pdf</span><span class="p">(</span>
    <span class="n">pdf</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">x_vals</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">particle</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="nb">set</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Reads the parton distribution function (PDF) values for a given particle</span>
<span class="sd">    at specified momentum fractions and energy scale using LHAPDF.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pdf : str</span>
<span class="sd">        Name of the PDF set to load.</span>
<span class="sd">    x_vals : np.ndarray</span>
<span class="sd">        Array of momentum fraction values (x) at which to evaluate the PDF.</span>
<span class="sd">    particle : int</span>
<span class="sd">        Particle ID (PDG code) for which the PDF is evaluated.</span>
<span class="sd">    set : int</span>
<span class="sd">        Specific member or set number within the PDF.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tuple[np.ndarray, np.ndarray]</span>
<span class="sd">        A tuple containing:</span>
<span class="sd">        - pdf_vals: np.ndarray of PDF values normalized by x_vals.</span>
<span class="sd">        - x_vals: The input array of momentum fractions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pid</span> <span class="o">=</span> <span class="n">particle</span>
    <span class="n">Q2</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">pdf</span> <span class="o">=</span> <span class="n">lhapdf</span><span class="o">.</span><span class="n">mkPDF</span><span class="p">(</span><span class="n">pdf</span><span class="p">,</span> <span class="nb">set</span><span class="p">)</span>
    <span class="n">pdf_vals</span> <span class="o">=</span> <span class="p">[</span><span class="n">pdf</span><span class="o">.</span><span class="n">xfxQ2</span><span class="p">(</span><span class="n">pid</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">Q2</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">x_vals</span><span class="p">]</span>
    <span class="n">pdf_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">pdf_vals</span><span class="p">)</span>
    <span class="n">pdf_vals</span> <span class="o">/=</span> <span class="n">x_vals</span>
    <span class="k">return</span> <span class="n">pdf_vals</span><span class="p">,</span> <span class="n">x_vals</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><h3 id="read_fk_tablepy"><code>read_fk_table.py</code><a class="headerlink" href="#read_fk_tablepy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.read_fk_table"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h2 id="NN_fit.read_fk_table.get_fk_table" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">get_fk_table</span><span class="p">(</span><span class="n">filename</span><span class="p">,</span> <span class="n">parent_dir</span><span class="p">)</span></code>

<a href="#NN_fit.read_fk_table.get_fk_table" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Loads a FastKernel (FK) table and corresponding x_alpha nodes from text files,
converts them to PyTorch tensors, and reshapes x_alpha to a column vector.</p>
<h4 id="NN_fit.read_fk_table.get_fk_table--parameters">Parameters<a class="headerlink" href="#NN_fit.read_fk_table.get_fk_table--parameters" title="Permanent link">&para;</a></h4>
<p>filename : str
    Name of the FK table file to load (relative to parent_dir).
parent_dir : str
    Path to the directory containing the FK table file and relative location
    of the x_alpha file.</p>
<h4 id="NN_fit.read_fk_table.get_fk_table--returns">Returns<a class="headerlink" href="#NN_fit.read_fk_table.get_fk_table--returns" title="Permanent link">&para;</a></h4>
<p>Tuple[torch.Tensor, torch.Tensor]
    - x_alpha: Tensor of shape (N, 1) containing x_alpha grid nodes.
    - fk_table: Tensor containing the FK table data.</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/read_fk_table.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">get_fk_table</span><span class="p">(</span><span class="n">filename</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">parent_dir</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Loads a FastKernel (FK) table and corresponding x_alpha nodes from text files,</span>
<span class="sd">    converts them to PyTorch tensors, and reshapes x_alpha to a column vector.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filename : str</span>
<span class="sd">        Name of the FK table file to load (relative to parent_dir).</span>
<span class="sd">    parent_dir : str</span>
<span class="sd">        Path to the directory containing the FK table file and relative location</span>
<span class="sd">        of the x_alpha file.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tuple[torch.Tensor, torch.Tensor]</span>
<span class="sd">        - x_alpha: Tensor of shape (N, 1) containing x_alpha grid nodes.</span>
<span class="sd">        - fk_table: Tensor containing the FK table data.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">parent_dir</span><span class="p">,</span> <span class="n">filename</span><span class="p">)</span>
    <span class="n">fk_table</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">parent_dir</span><span class="p">,</span> <span class="s2">&quot;../../../Data/gridnodes/x_alpha.dat&quot;</span><span class="p">)</span>
    <span class="n">x_alpha</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="n">file_path</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="n">x_alpha</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">x_alpha</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">fk_table</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">fk_table</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x_alpha</span><span class="p">,</span> <span class="n">fk_table</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><h3 id="help_read_filespy"><code>help_read_files.py</code><a class="headerlink" href="#help_read_filespy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.help_read_files"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">











  </div>

    </div>

</div><hr />
<h2 id="post-fit-analysis">📊 Post-Fit Analysis<a class="headerlink" href="#post-fit-analysis" title="Permanent link">&para;</a></h2>
<h3 id="postfit_criteriapy"><code>postfit_criteria.py</code><a class="headerlink" href="#postfit_criteriapy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.postfit_criteria"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="NN_fit.postfit_criteria.Postfit" class="doc doc-heading">
            <code>Postfit</code>


<a href="#NN_fit.postfit_criteria.Postfit" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">








              <details class="quote">
                <summary>Source code in <code>NN_fit/postfit_criteria.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">Postfit</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="c1"># def compute_arc_length(self, model):</span>
    <span class="c1">#     npoints = 199  # 200 intervals</span>
    <span class="c1">#     seg_min = [1e-6, 1e-4, 1e-2]</span>
    <span class="c1">#     seg_max = [1e-4, 1e-2, 1.0]</span>
    <span class="c1">#     res = 0</span>
    <span class="c1">#     for a, b in zip(seg_min, seg_max):</span>
    <span class="c1">#         eps = (b - a) / npoints</span>
    <span class="c1">#         ixgrid = np.linspace(a, b, npoints, endpoint=False)</span>
    <span class="c1">#         ixgrid = torch.tensor(ixgrid, dtype=torch.float32).view(-1, 1)</span>

    <span class="c1">#         pdf_vals_grid = model(ixgrid)</span>
    <span class="c1">#         pdf_vals_grid = pdf_vals_grid.detach().numpy().flatten()</span>
    <span class="c1">#         ixgrid = ixgrid.detach().numpy().flatten()</span>

    <span class="c1">#         fdiff = np.diff(pdf_vals_grid) / eps</span>
    <span class="c1">#         res += integrate.simpson(np.sqrt(1 + np.square(fdiff)), x=ixgrid[1:])</span>
    <span class="c1">#     return res</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">apply_postfit_criteria</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">chi_squares</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
        <span class="n">N_event_pred</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">neutrino_pdfs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">pred</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Applies post-fit criteria to filter out replicas with chi-squared values</span>
<span class="sd">        that deviate significantly from the mean (more than 4 standard deviations).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        chi_squares : List[float]</span>
<span class="sd">            List of chi-squared values for each replica.</span>
<span class="sd">        N_event_pred : np.ndarray</span>
<span class="sd">            Array of predicted event yields for each replica.</span>
<span class="sd">        neutrino_pdfs : np.ndarray</span>
<span class="sd">            Array of predicted neutrino PDFs for each replica.</span>
<span class="sd">        pred : np.ndarray</span>
<span class="sd">            Array of original pseudo-data predictions for each replica.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        Tuple[np.ndarray, np.ndarray, np.ndarray]</span>
<span class="sd">            Filtered arrays of neutrino_pdfs, N_event_pred, and pred with outlier replicas removed.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        Replicas whose chi-squared differ from the mean by more than 4 standard deviations</span>
<span class="sd">        are considered outliers and removed.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">sig_chi_squares</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">chi_squares</span><span class="p">)</span>
        <span class="n">mean_chi_squares</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">chi_squares</span><span class="p">)</span>

        <span class="n">indices_to_remove</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chi_squares</span><span class="p">)):</span>
            <span class="n">diff_chi_squares</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">chi_squares</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean_chi_squares</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">diff_chi_squares</span> <span class="o">&gt;</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">sig_chi_squares</span><span class="p">:</span>
                <span class="n">indices_to_remove</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices_to_remove</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">indices_to_remove</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">indices_to_remove</span><span class="p">)</span>
            <span class="n">N_event_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">N_event_pred</span><span class="p">,</span> <span class="n">indices_to_remove</span><span class="p">)</span>
            <span class="n">neutrino_pdfs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">indices_to_remove</span><span class="p">)</span>
            <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">indices_to_remove</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">pred</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h3 id="NN_fit.postfit_criteria.Postfit.apply_postfit_criteria" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">apply_postfit_criteria</span><span class="p">(</span><span class="n">chi_squares</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span></code>

<a href="#NN_fit.postfit_criteria.Postfit.apply_postfit_criteria" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Applies post-fit criteria to filter out replicas with chi-squared values
that deviate significantly from the mean (more than 4 standard deviations).</p>
<h5 id="NN_fit.postfit_criteria.Postfit.apply_postfit_criteria--parameters">Parameters<a class="headerlink" href="#NN_fit.postfit_criteria.Postfit.apply_postfit_criteria--parameters" title="Permanent link">&para;</a></h5>
<p>chi_squares : List[float]
    List of chi-squared values for each replica.
N_event_pred : np.ndarray
    Array of predicted event yields for each replica.
neutrino_pdfs : np.ndarray
    Array of predicted neutrino PDFs for each replica.
pred : np.ndarray
    Array of original pseudo-data predictions for each replica.</p>
<h5 id="NN_fit.postfit_criteria.Postfit.apply_postfit_criteria--returns">Returns<a class="headerlink" href="#NN_fit.postfit_criteria.Postfit.apply_postfit_criteria--returns" title="Permanent link">&para;</a></h5>
<p>Tuple[np.ndarray, np.ndarray, np.ndarray]
    Filtered arrays of neutrino_pdfs, N_event_pred, and pred with outlier replicas removed.</p>
<h5 id="NN_fit.postfit_criteria.Postfit.apply_postfit_criteria--notes">Notes<a class="headerlink" href="#NN_fit.postfit_criteria.Postfit.apply_postfit_criteria--notes" title="Permanent link">&para;</a></h5>
<p>Replicas whose chi-squared differ from the mean by more than 4 standard deviations
are considered outliers and removed.</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/postfit_criteria.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span>
<span class="normal">74</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">apply_postfit_criteria</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">chi_squares</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
    <span class="n">N_event_pred</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">neutrino_pdfs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">pred</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Applies post-fit criteria to filter out replicas with chi-squared values</span>
<span class="sd">    that deviate significantly from the mean (more than 4 standard deviations).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    chi_squares : List[float]</span>
<span class="sd">        List of chi-squared values for each replica.</span>
<span class="sd">    N_event_pred : np.ndarray</span>
<span class="sd">        Array of predicted event yields for each replica.</span>
<span class="sd">    neutrino_pdfs : np.ndarray</span>
<span class="sd">        Array of predicted neutrino PDFs for each replica.</span>
<span class="sd">    pred : np.ndarray</span>
<span class="sd">        Array of original pseudo-data predictions for each replica.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    Tuple[np.ndarray, np.ndarray, np.ndarray]</span>
<span class="sd">        Filtered arrays of neutrino_pdfs, N_event_pred, and pred with outlier replicas removed.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    Replicas whose chi-squared differ from the mean by more than 4 standard deviations</span>
<span class="sd">    are considered outliers and removed.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">sig_chi_squares</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">chi_squares</span><span class="p">)</span>
    <span class="n">mean_chi_squares</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">chi_squares</span><span class="p">)</span>

    <span class="n">indices_to_remove</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">chi_squares</span><span class="p">)):</span>
        <span class="n">diff_chi_squares</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">chi_squares</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">mean_chi_squares</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">diff_chi_squares</span> <span class="o">&gt;</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">sig_chi_squares</span><span class="p">:</span>
            <span class="n">indices_to_remove</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices_to_remove</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">indices_to_remove</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">indices_to_remove</span><span class="p">)</span>
        <span class="n">N_event_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">N_event_pred</span><span class="p">,</span> <span class="n">indices_to_remove</span><span class="p">)</span>
        <span class="n">neutrino_pdfs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">indices_to_remove</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">indices_to_remove</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">neutrino_pdfs</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">pred</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div><h3 id="postfit_measurespy"><code>postfit_measures.py</code><a class="headerlink" href="#postfit_measurespy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.postfit_measures"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">








<div class="doc doc-object doc-class">



<h2 id="NN_fit.postfit_measures.Measures" class="doc doc-heading">
            <code>Measures</code>


<a href="#NN_fit.postfit_measures.Measures" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">








              <details class="quote">
                <summary>Source code in <code>NN_fit/postfit_measures.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">  7</span>
<span class="normal">  8</span>
<span class="normal">  9</span>
<span class="normal"> 10</span>
<span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">class</span><span class="w"> </span><span class="nc">Measures</span><span class="p">:</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">cov_matrix</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">pdf</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">N_event_pred</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cov_matrix</span> <span class="o">=</span> <span class="n">cov_matrix</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pdf</span> <span class="o">=</span> <span class="n">pdf</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">N_event_pred</span> <span class="o">=</span> <span class="n">N_event_pred</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize Measures class with covariance matrix, PDF, and predicted events.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        cov_matrix : torch.Tensor</span>
<span class="sd">            Covariance matrix used in chi-squared calculations.</span>
<span class="sd">        pdf : np.ndarray</span>
<span class="sd">            Reference PDF array.</span>
<span class="sd">        N_event_pred : np.ndarray</span>
<span class="sd">            Predicted event yields array, shape (num_replicas, num_bins).</span>
<span class="sd">        &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compute_delta_chi</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">level0</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">N_event_pred</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">data_level1</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">x_vals</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the relative change in chi-squared between a baseline theory prediction</span>
<span class="sd">        and the fit prediction.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        level0 : Union[np.ndarray, torch.Tensor]</span>
<span class="sd">            Baseline theory prediction.</span>
<span class="sd">        N_event_pred : np.ndarray</span>
<span class="sd">            Predicted events for all replicas.</span>
<span class="sd">        data_level1 : torch.Tensor</span>
<span class="sd">            Observed data level 1 tensor, shape (num_bins, 1).</span>
<span class="sd">        x_vals : Union[np.ndarray, torch.Tensor]</span>
<span class="sd">            x-values (unused in this function).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Relative change in chi-squared (delta chi).</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">level0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">level0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">data_level1</span> <span class="o">=</span> <span class="n">data_level1</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">level0</span> <span class="o">-</span> <span class="n">data_level1</span>

        <span class="n">diffcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>
        <span class="n">chi_theory</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">diffcov</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">mean_N_events</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">N_event_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">mean_N_events</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">mean_N_events</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">mean_N_events</span> <span class="o">-</span> <span class="n">data_level1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">diffcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>
        <span class="n">chi_fit</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">diffcov</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">delta_chi</span> <span class="o">=</span> <span class="p">(</span><span class="n">chi_fit</span> <span class="o">-</span> <span class="n">chi_theory</span><span class="p">)</span> <span class="o">/</span> <span class="n">chi_theory</span>

        <span class="k">return</span> <span class="n">delta_chi</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compute_phi</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">data</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">chi_squares</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the phi metric as the difference between average chi-square over replicas</span>
<span class="sd">        and chi-square of the mean prediction.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        data : Union[np.ndarray, torch.Tensor]</span>
<span class="sd">            Observed data points.</span>
<span class="sd">        chi_squares : List[float]</span>
<span class="sd">            List of chi-square losses per replica.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            The phi metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">num_reps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_event_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">chis</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_reps</span><span class="p">):</span>
            <span class="n">N_event_rep</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_event_pred</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

            <span class="n">diff</span> <span class="o">=</span> <span class="n">N_event_rep</span> <span class="o">-</span> <span class="n">data</span>
            <span class="n">diffcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">diffcov</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
            <span class="n">chis</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
        <span class="n">mean_N_event_fits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_event_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="c1"># data = torch.tensor(data, dtype=torch.float32)</span>
        <span class="n">mean_N_event_fits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">mean_N_event_fits</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="n">diff</span> <span class="o">=</span> <span class="n">mean_N_event_fits</span> <span class="o">-</span> <span class="n">data</span>
        <span class="n">diffcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">diffcov</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">phi_chi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">chis</span><span class="p">)</span> <span class="o">-</span> <span class="n">mean</span>
        <span class="k">return</span> <span class="n">phi_chi</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compute_accuracy</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">x_alphas</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">neutrino_pdf</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">pdf</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">n</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
        <span class="n">pdf_set</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">pid</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the accuracy metric as the fraction of bins where the predicted neutrino PDF</span>
<span class="sd">        agrees with the reference PDF within n standard deviations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x_alphas : np.ndarray</span>
<span class="sd">            Input x-values (not used directly in this function).</span>
<span class="sd">        neutrino_pdf : np.ndarray</span>
<span class="sd">            Array of predicted neutrino PDFs (shape: replicas x bins).</span>
<span class="sd">        pdf : str</span>
<span class="sd">            Path or identifier for the reference PDF file.</span>
<span class="sd">        n : float</span>
<span class="sd">            Number of standard deviations for the acceptance criterion.</span>
<span class="sd">        pdf_set : str</span>
<span class="sd">            Identifier of the PDF set.</span>
<span class="sd">        pid : int</span>
<span class="sd">            Particle ID for PDF retrieval.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            Fraction of bins where predicted PDF agrees within n std deviations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mean_neutrino_pdf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">neutrino_pdf</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">std_pdfs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">neutrino_pdf</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">distances</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

        <span class="n">log_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="mf">0.02</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="mf">0.8</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
        <span class="n">lin_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
        <span class="n">log_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">log_vals</span><span class="p">)</span>
        <span class="n">lin_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">lin_vals</span><span class="p">)</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">log_indices</span><span class="p">,</span> <span class="n">lin_indices</span><span class="p">))</span>

        <span class="n">faser_pdf</span><span class="p">,</span> <span class="n">x_faser</span> <span class="o">=</span> <span class="n">read_pdf</span><span class="p">(</span><span class="n">pdf</span><span class="p">,</span> <span class="n">arr</span><span class="p">,</span> <span class="n">pid</span><span class="p">,</span> <span class="n">pdf_set</span><span class="p">)</span>
        <span class="n">faser_pdf</span> <span class="o">=</span> <span class="n">faser_pdf</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="o">*</span> <span class="mf">1.16186e-09</span>
        <span class="n">faser_pdf</span> <span class="o">=</span> <span class="n">faser_pdf</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
        <span class="n">mean_neutrino_pdf</span> <span class="o">=</span> <span class="n">mean_neutrino_pdf</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

        <span class="n">std_pdfs</span> <span class="o">=</span> <span class="n">std_pdfs</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)):</span>
            <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">mean_neutrino_pdf</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">faser_pdf</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">n</span> <span class="o">*</span> <span class="n">std_pdfs</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
                <span class="n">distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">distance</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">distance</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compute_bias_to_variance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">level0</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
        <span class="n">level2</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">N_event_pred</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">REPLICAS</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute the ratio of bias to variance in the PDF fits.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        level0 : Union[np.ndarray, torch.Tensor]</span>
<span class="sd">            Baseline theory prediction.</span>
<span class="sd">        level2 : np.ndarray</span>
<span class="sd">            Array of predictions at level 2, shape (REPLICAS, num_bins).</span>
<span class="sd">        N_event_pred : np.ndarray</span>
<span class="sd">            Predicted events for all replicas.</span>
<span class="sd">        REPLICAS : int</span>
<span class="sd">            Number of replicas.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        torch.Tensor</span>
<span class="sd">            Ratio of bias to variance.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">mean_N_events</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">N_event_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">mean_N_events</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">mean_N_events</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">level0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">level0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="n">diff</span> <span class="o">=</span> <span class="n">mean_N_events</span> <span class="o">-</span> <span class="n">level0</span>
        <span class="n">diffcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>
        <span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">diffcov</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">chi_square_level2</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">REPLICAS</span><span class="p">):</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">mean_N_events</span> <span class="o">-</span> <span class="n">level2</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
            <span class="n">diff</span> <span class="o">=</span> <span class="n">diff</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">diffcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>
            <span class="n">chi_square</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">diffcov</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

            <span class="n">chi_square_level2</span> <span class="o">+=</span> <span class="n">chi_square</span>

        <span class="n">variance</span> <span class="o">=</span> <span class="n">chi_square_level2</span> <span class="o">/</span> <span class="n">REPLICAS</span>

        <span class="n">ratio</span> <span class="o">=</span> <span class="n">bias</span> <span class="o">/</span> <span class="n">variance</span>
        <span class="k">return</span> <span class="n">ratio</span>
</code></pre></div></td></tr></table></div>
              </details>



  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">



<h3 id="NN_fit.postfit_measures.Measures.N_event_pred" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">N_event_pred</span> <span class="o">=</span> <span class="n">N_event_pred</span></code>

  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-instance-attribute"><code>instance-attribute</code></small>
  </span>

<a href="#NN_fit.postfit_measures.Measures.N_event_pred" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Initialize Measures class with covariance matrix, PDF, and predicted events.</p>
<h5 id="NN_fit.postfit_measures.Measures.N_event_pred--parameters">Parameters<a class="headerlink" href="#NN_fit.postfit_measures.Measures.N_event_pred--parameters" title="Permanent link">&para;</a></h5>
<p>cov_matrix : torch.Tensor
    Covariance matrix used in chi-squared calculations.
pdf : np.ndarray
    Reference PDF array.
N_event_pred : np.ndarray
    Predicted event yields array, shape (num_replicas, num_bins).</p>

    </div>

</div>



<div class="doc doc-object doc-function">


<h3 id="NN_fit.postfit_measures.Measures.compute_accuracy" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_accuracy</span><span class="p">(</span><span class="n">x_alphas</span><span class="p">,</span> <span class="n">neutrino_pdf</span><span class="p">,</span> <span class="n">pdf</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">pdf_set</span><span class="p">,</span> <span class="n">pid</span><span class="p">)</span></code>

<a href="#NN_fit.postfit_measures.Measures.compute_accuracy" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Compute the accuracy metric as the fraction of bins where the predicted neutrino PDF
agrees with the reference PDF within n standard deviations.</p>
<h5 id="NN_fit.postfit_measures.Measures.compute_accuracy--parameters">Parameters<a class="headerlink" href="#NN_fit.postfit_measures.Measures.compute_accuracy--parameters" title="Permanent link">&para;</a></h5>
<p>x_alphas : np.ndarray
    Input x-values (not used directly in this function).
neutrino_pdf : np.ndarray
    Array of predicted neutrino PDFs (shape: replicas x bins).
pdf : str
    Path or identifier for the reference PDF file.
n : float
    Number of standard deviations for the acceptance criterion.
pdf_set : str
    Identifier of the PDF set.
pid : int
    Particle ID for PDF retrieval.</p>
<h5 id="NN_fit.postfit_measures.Measures.compute_accuracy--returns">Returns<a class="headerlink" href="#NN_fit.postfit_measures.Measures.compute_accuracy--returns" title="Permanent link">&para;</a></h5>
<p>float
    Fraction of bins where predicted PDF agrees within n std deviations.</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/postfit_measures.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">compute_accuracy</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">x_alphas</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">neutrino_pdf</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">pdf</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">n</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">pdf_set</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">pid</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the accuracy metric as the fraction of bins where the predicted neutrino PDF</span>
<span class="sd">    agrees with the reference PDF within n standard deviations.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    x_alphas : np.ndarray</span>
<span class="sd">        Input x-values (not used directly in this function).</span>
<span class="sd">    neutrino_pdf : np.ndarray</span>
<span class="sd">        Array of predicted neutrino PDFs (shape: replicas x bins).</span>
<span class="sd">    pdf : str</span>
<span class="sd">        Path or identifier for the reference PDF file.</span>
<span class="sd">    n : float</span>
<span class="sd">        Number of standard deviations for the acceptance criterion.</span>
<span class="sd">    pdf_set : str</span>
<span class="sd">        Identifier of the PDF set.</span>
<span class="sd">    pid : int</span>
<span class="sd">        Particle ID for PDF retrieval.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        Fraction of bins where predicted PDF agrees within n std deviations.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mean_neutrino_pdf</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">neutrino_pdf</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">std_pdfs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">neutrino_pdf</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="n">arr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>

    <span class="n">log_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">logspace</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="mf">0.02</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">log10</span><span class="p">(</span><span class="mf">0.8</span><span class="p">),</span> <span class="mi">100</span><span class="p">)</span>
    <span class="n">lin_vals</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">log_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">log_vals</span><span class="p">)</span>
    <span class="n">lin_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">arr</span><span class="p">,</span> <span class="n">lin_vals</span><span class="p">)</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">log_indices</span><span class="p">,</span> <span class="n">lin_indices</span><span class="p">))</span>

    <span class="n">faser_pdf</span><span class="p">,</span> <span class="n">x_faser</span> <span class="o">=</span> <span class="n">read_pdf</span><span class="p">(</span><span class="n">pdf</span><span class="p">,</span> <span class="n">arr</span><span class="p">,</span> <span class="n">pid</span><span class="p">,</span> <span class="n">pdf_set</span><span class="p">)</span>
    <span class="n">faser_pdf</span> <span class="o">=</span> <span class="n">faser_pdf</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="o">*</span> <span class="mf">1.16186e-09</span>
    <span class="n">faser_pdf</span> <span class="o">=</span> <span class="n">faser_pdf</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
    <span class="n">mean_neutrino_pdf</span> <span class="o">=</span> <span class="n">mean_neutrino_pdf</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

    <span class="n">std_pdfs</span> <span class="o">=</span> <span class="n">std_pdfs</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)):</span>
        <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">mean_neutrino_pdf</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">faser_pdf</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="o">&lt;</span> <span class="n">n</span> <span class="o">*</span> <span class="n">std_pdfs</span><span class="p">[</span><span class="n">i</span><span class="p">]:</span>
            <span class="n">distances</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">distance</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">distance</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="NN_fit.postfit_measures.Measures.compute_bias_to_variance" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_bias_to_variance</span><span class="p">(</span><span class="n">level0</span><span class="p">,</span> <span class="n">level2</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">REPLICAS</span><span class="p">)</span></code>

<a href="#NN_fit.postfit_measures.Measures.compute_bias_to_variance" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Compute the ratio of bias to variance in the PDF fits.</p>
<h5 id="NN_fit.postfit_measures.Measures.compute_bias_to_variance--parameters">Parameters<a class="headerlink" href="#NN_fit.postfit_measures.Measures.compute_bias_to_variance--parameters" title="Permanent link">&para;</a></h5>
<p>level0 : Union[np.ndarray, torch.Tensor]
    Baseline theory prediction.
level2 : np.ndarray
    Array of predictions at level 2, shape (REPLICAS, num_bins).
N_event_pred : np.ndarray
    Predicted events for all replicas.
REPLICAS : int
    Number of replicas.</p>
<h5 id="NN_fit.postfit_measures.Measures.compute_bias_to_variance--returns">Returns<a class="headerlink" href="#NN_fit.postfit_measures.Measures.compute_bias_to_variance--returns" title="Permanent link">&para;</a></h5>
<p>torch.Tensor
    Ratio of bias to variance.</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/postfit_measures.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">compute_bias_to_variance</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">level0</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">level2</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">N_event_pred</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">REPLICAS</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the ratio of bias to variance in the PDF fits.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    level0 : Union[np.ndarray, torch.Tensor]</span>
<span class="sd">        Baseline theory prediction.</span>
<span class="sd">    level2 : np.ndarray</span>
<span class="sd">        Array of predictions at level 2, shape (REPLICAS, num_bins).</span>
<span class="sd">    N_event_pred : np.ndarray</span>
<span class="sd">        Predicted events for all replicas.</span>
<span class="sd">    REPLICAS : int</span>
<span class="sd">        Number of replicas.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        Ratio of bias to variance.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">mean_N_events</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">N_event_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">mean_N_events</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">mean_N_events</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">level0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">level0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">diff</span> <span class="o">=</span> <span class="n">mean_N_events</span> <span class="o">-</span> <span class="n">level0</span>
    <span class="n">diffcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">diffcov</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">chi_square_level2</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">REPLICAS</span><span class="p">):</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">mean_N_events</span> <span class="o">-</span> <span class="n">level2</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
        <span class="n">diff</span> <span class="o">=</span> <span class="n">diff</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">diffcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>
        <span class="n">chi_square</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">diffcov</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">chi_square_level2</span> <span class="o">+=</span> <span class="n">chi_square</span>

    <span class="n">variance</span> <span class="o">=</span> <span class="n">chi_square_level2</span> <span class="o">/</span> <span class="n">REPLICAS</span>

    <span class="n">ratio</span> <span class="o">=</span> <span class="n">bias</span> <span class="o">/</span> <span class="n">variance</span>
    <span class="k">return</span> <span class="n">ratio</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="NN_fit.postfit_measures.Measures.compute_delta_chi" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_delta_chi</span><span class="p">(</span><span class="n">level0</span><span class="p">,</span> <span class="n">N_event_pred</span><span class="p">,</span> <span class="n">data_level1</span><span class="p">,</span> <span class="n">x_vals</span><span class="p">)</span></code>

<a href="#NN_fit.postfit_measures.Measures.compute_delta_chi" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Compute the relative change in chi-squared between a baseline theory prediction
and the fit prediction.</p>
<h5 id="NN_fit.postfit_measures.Measures.compute_delta_chi--parameters">Parameters<a class="headerlink" href="#NN_fit.postfit_measures.Measures.compute_delta_chi--parameters" title="Permanent link">&para;</a></h5>
<p>level0 : Union[np.ndarray, torch.Tensor]
    Baseline theory prediction.
N_event_pred : np.ndarray
    Predicted events for all replicas.
data_level1 : torch.Tensor
    Observed data level 1 tensor, shape (num_bins, 1).
x_vals : Union[np.ndarray, torch.Tensor]
    x-values (unused in this function).</p>
<h5 id="NN_fit.postfit_measures.Measures.compute_delta_chi--returns">Returns<a class="headerlink" href="#NN_fit.postfit_measures.Measures.compute_delta_chi--returns" title="Permanent link">&para;</a></h5>
<p>torch.Tensor
    Relative change in chi-squared (delta chi).</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/postfit_measures.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span>
<span class="normal">65</span>
<span class="normal">66</span>
<span class="normal">67</span>
<span class="normal">68</span>
<span class="normal">69</span>
<span class="normal">70</span>
<span class="normal">71</span>
<span class="normal">72</span>
<span class="normal">73</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">compute_delta_chi</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">level0</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">N_event_pred</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">data_level1</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">x_vals</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the relative change in chi-squared between a baseline theory prediction</span>
<span class="sd">    and the fit prediction.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    level0 : Union[np.ndarray, torch.Tensor]</span>
<span class="sd">        Baseline theory prediction.</span>
<span class="sd">    N_event_pred : np.ndarray</span>
<span class="sd">        Predicted events for all replicas.</span>
<span class="sd">    data_level1 : torch.Tensor</span>
<span class="sd">        Observed data level 1 tensor, shape (num_bins, 1).</span>
<span class="sd">    x_vals : Union[np.ndarray, torch.Tensor]</span>
<span class="sd">        x-values (unused in this function).</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        Relative change in chi-squared (delta chi).</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">level0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">level0</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">data_level1</span> <span class="o">=</span> <span class="n">data_level1</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">level0</span> <span class="o">-</span> <span class="n">data_level1</span>

    <span class="n">diffcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>
    <span class="n">chi_theory</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">diffcov</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">mean_N_events</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">N_event_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">mean_N_events</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">mean_N_events</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">mean_N_events</span> <span class="o">-</span> <span class="n">data_level1</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="n">diffcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>
    <span class="n">chi_fit</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">diffcov</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">delta_chi</span> <span class="o">=</span> <span class="p">(</span><span class="n">chi_fit</span> <span class="o">-</span> <span class="n">chi_theory</span><span class="p">)</span> <span class="o">/</span> <span class="n">chi_theory</span>

    <span class="k">return</span> <span class="n">delta_chi</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h3 id="NN_fit.postfit_measures.Measures.compute_phi" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_phi</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">chi_squares</span><span class="p">)</span></code>

<a href="#NN_fit.postfit_measures.Measures.compute_phi" class="headerlink" title="Permanent link">&para;</a></h3>


    <div class="doc doc-contents ">

        <p>Compute the phi metric as the difference between average chi-square over replicas
and chi-square of the mean prediction.</p>
<h5 id="NN_fit.postfit_measures.Measures.compute_phi--parameters">Parameters<a class="headerlink" href="#NN_fit.postfit_measures.Measures.compute_phi--parameters" title="Permanent link">&para;</a></h5>
<p>data : Union[np.ndarray, torch.Tensor]
    Observed data points.
chi_squares : List[float]
    List of chi-square losses per replica.</p>
<h5 id="NN_fit.postfit_measures.Measures.compute_phi--returns">Returns<a class="headerlink" href="#NN_fit.postfit_measures.Measures.compute_phi--returns" title="Permanent link">&para;</a></h5>
<p>float
    The phi metric.</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/postfit_measures.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">compute_phi</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
    <span class="n">chi_squares</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the phi metric as the difference between average chi-square over replicas</span>
<span class="sd">    and chi-square of the mean prediction.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    data : Union[np.ndarray, torch.Tensor]</span>
<span class="sd">        Observed data points.</span>
<span class="sd">    chi_squares : List[float]</span>
<span class="sd">        List of chi-square losses per replica.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The phi metric.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">num_reps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">N_event_pred</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">chis</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_reps</span><span class="p">):</span>
        <span class="n">N_event_rep</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_event_pred</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

        <span class="n">diff</span> <span class="o">=</span> <span class="n">N_event_rep</span> <span class="o">-</span> <span class="n">data</span>
        <span class="n">diffcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">diffcov</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">chis</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
    <span class="n">mean_N_event_fits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">N_event_pred</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="c1"># data = torch.tensor(data, dtype=torch.float32)</span>
    <span class="n">mean_N_event_fits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">mean_N_event_fits</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

    <span class="n">diff</span> <span class="o">=</span> <span class="n">mean_N_event_fits</span> <span class="o">-</span> <span class="n">data</span>
    <span class="n">diffcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">diffcov</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="n">phi_chi</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">chis</span><span class="p">)</span> <span class="o">-</span> <span class="n">mean</span>
    <span class="k">return</span> <span class="n">phi_chi</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div>




  </div>

    </div>

</div><h3 id="pullpy"><code>pull.py</code><a class="headerlink" href="#pullpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.pull"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h2 id="NN_fit.pull.compute_pull" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_pull</span><span class="p">(</span><span class="n">mean_pdf1</span><span class="p">,</span> <span class="n">mean_pdf2</span><span class="p">,</span> <span class="n">error_pdf1</span><span class="p">,</span> <span class="n">error_pdf2</span><span class="p">)</span></code>

<a href="#NN_fit.pull.compute_pull" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Computes pull between pdfs</p>


<p><span class="doc-section-title">Parameters:</span></p>
    <table>
      <thead>
        <tr>
          <th>Name</th>
          <th>Type</th>
          <th>Description</th>
          <th>Default</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
            <td>
                <code>mean_pdf1</code>
            </td>
            <td>
                  <code>np array</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>neutrino pdf 1</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>mean_pdf2</code>
            </td>
            <td>
                  <code>np array</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>neutrino pdf 2</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>error_pdf1</code>
            </td>
            <td>
                  <code>np array</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>std neutrino pdf 1</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
          <tr class="doc-section-item">
            <td>
                <code>error_pdf2</code>
            </td>
            <td>
                  <code>np array</code>
            </td>
            <td>
              <div class="doc-md-description">
                <p>std neutrino pdf 2</p>
              </div>
            </td>
            <td>
                <em>required</em>
            </td>
          </tr>
      </tbody>
    </table>


    <p><span class="doc-section-title">Returns:</span></p>
    <table>
      <thead>
        <tr>
<th>Name</th>          <th>Type</th>
          <th>Description</th>
        </tr>
      </thead>
      <tbody>
          <tr class="doc-section-item">
<td><code>list</code></td>            <td>
            </td>
            <td>
              <div class="doc-md-description">
                <p>pull</p>
              </div>
            </td>
          </tr>
      </tbody>
    </table>


            <details class="quote">
              <summary>Source code in <code>NN_fit/pull.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 4</span>
<span class="normal"> 5</span>
<span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">compute_pull</span><span class="p">(</span><span class="n">mean_pdf1</span><span class="p">,</span> <span class="n">mean_pdf2</span><span class="p">,</span> <span class="n">error_pdf1</span><span class="p">,</span> <span class="n">error_pdf2</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Computes pull between pdfs</span>

<span class="sd">    Args:</span>
<span class="sd">        mean_pdf1 (np array): neutrino pdf 1</span>
<span class="sd">        mean_pdf2 (np array): neutrino pdf 2</span>
<span class="sd">        error_pdf1 (np array): std neutrino pdf 1</span>
<span class="sd">        error_pdf2 (np array): std neutrino pdf 2</span>

<span class="sd">    Returns:</span>
<span class="sd">        list: pull</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">pull</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">mean_pdf1</span> <span class="o">-</span> <span class="n">mean_pdf2</span><span class="p">)</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">error_pdf1</span><span class="o">**</span><span class="mi">2</span> <span class="o">-</span> <span class="n">error_pdf2</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pull</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><hr />
<h2 id="miscellaneous-modules">🧬 Miscellaneous Modules<a class="headerlink" href="#miscellaneous-modules" title="Permanent link">&para;</a></h2>
<h3 id="form_loss_fctpy"><code>form_loss_fct.py</code><a class="headerlink" href="#form_loss_fctpy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.form_loss_fct"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h2 id="NN_fit.form_loss_fct.complete_loss_fct_comb" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">complete_loss_fct_comb</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">int_point_nu</span><span class="p">,</span> <span class="n">x_int</span><span class="p">,</span> <span class="n">lag_mult_pos</span><span class="p">,</span> <span class="n">lag_mult_int</span><span class="p">)</span></code>

<a href="#NN_fit.form_loss_fct.complete_loss_fct_comb" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Extended chi-squared loss for combined neutrino + antineutrino prediction, with constraints.</p>
<h4 id="NN_fit.form_loss_fct.complete_loss_fct_comb--parameters">Parameters<a class="headerlink" href="#NN_fit.form_loss_fct.complete_loss_fct_comb--parameters" title="Permanent link">&para;</a></h4>
<p>pred : torch.Tensor
    Model predictions (shape: N).
data : torch.Tensor
    Observed pseudo-data (shape: N).
cov_matrix : torch.Tensor
    Covariance matrix for the data (shape: N x N).
f : torch.Tensor
    Raw NN output without preprocessing (shape: N).
int_point_nu : torch.Tensor
    Integral constraint vector (shape: N).
x_int : torch.Tensor
    x-values for integral constraint (shape: N).
lag_mult_pos : float
    Lagrange multiplier for positivity constraint.
lag_mult_int : float
    Lagrange multiplier for integral normalization.</p>
<h4 id="NN_fit.form_loss_fct.complete_loss_fct_comb--returns">Returns<a class="headerlink" href="#NN_fit.form_loss_fct.complete_loss_fct_comb--returns" title="Permanent link">&para;</a></h4>
<p>torch.Tensor
    Total loss.</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/form_loss_fct.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">complete_loss_fct_comb</span><span class="p">(</span>
    <span class="n">pred</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">cov_matrix</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">f</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">int_point_nu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">x_int</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">lag_mult_pos</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">lag_mult_int</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extended chi-squared loss for combined neutrino + antineutrino prediction, with constraints.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pred : torch.Tensor</span>
<span class="sd">        Model predictions (shape: N).</span>
<span class="sd">    data : torch.Tensor</span>
<span class="sd">        Observed pseudo-data (shape: N).</span>
<span class="sd">    cov_matrix : torch.Tensor</span>
<span class="sd">        Covariance matrix for the data (shape: N x N).</span>
<span class="sd">    f : torch.Tensor</span>
<span class="sd">        Raw NN output without preprocessing (shape: N).</span>
<span class="sd">    int_point_nu : torch.Tensor</span>
<span class="sd">        Integral constraint vector (shape: N).</span>
<span class="sd">    x_int : torch.Tensor</span>
<span class="sd">        x-values for integral constraint (shape: N).</span>
<span class="sd">    lag_mult_pos : float</span>
<span class="sd">        Lagrange multiplier for positivity constraint.</span>
<span class="sd">    lag_mult_int : float</span>
<span class="sd">        Lagrange multiplier for integral normalization.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        Total loss.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">-</span> <span class="n">data</span>
    <span class="n">diffcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>

    <span class="n">f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">f</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">pred</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">diffcov</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="o">+</span> <span class="nb">abs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">f</span><span class="p">))</span> <span class="o">*</span> <span class="n">lag_mult_pos</span>
        <span class="o">+</span> <span class="nb">abs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">int_point_nu</span> <span class="o">*</span> <span class="n">x_int</span><span class="p">))</span> <span class="o">*</span> <span class="n">lag_mult_int</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="NN_fit.form_loss_fct.complete_loss_fct_nu_nub" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">complete_loss_fct_nu_nub</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">int_point_nu</span><span class="p">,</span> <span class="n">int_point_nub</span><span class="p">,</span> <span class="n">x_int</span><span class="p">,</span> <span class="n">lag_mult_pos</span><span class="p">,</span> <span class="n">lag_mult_int</span><span class="p">)</span></code>

<a href="#NN_fit.form_loss_fct.complete_loss_fct_nu_nub" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Extended chi-squared loss for separate neutrino and antineutrino predictions, with constraints.</p>
<h4 id="NN_fit.form_loss_fct.complete_loss_fct_nu_nub--parameters">Parameters<a class="headerlink" href="#NN_fit.form_loss_fct.complete_loss_fct_nu_nub--parameters" title="Permanent link">&para;</a></h4>
<p>pred : torch.Tensor
    Model predictions for observed data (shape: N).
data : torch.Tensor
    Observed pseudo-data (shape: N).
cov_matrix : torch.Tensor
    Covariance matrix for the data (shape: N x N).
f : torch.Tensor
    Raw (non-preprocessed) neural network outputs (shape: N x 2), with:
        - f[:, 0]: neutrino component (ν)
        - f[:, 1]: antineutrino component (ν̄)
int_point_nu : torch.Tensor
    Integral constraint values for ν (shape: N).
int_point_nub : torch.Tensor
    Integral constraint values for ν̄ (shape: N).
x_int : torch.Tensor
    x-values for integral evaluation (shape: N).
lag_mult_pos : float
    Lagrange multiplier for enforcing positivity.
lag_mult_int : float
    Lagrange multiplier for enforcing normalization via integral.</p>
<h4 id="NN_fit.form_loss_fct.complete_loss_fct_nu_nub--returns">Returns<a class="headerlink" href="#NN_fit.form_loss_fct.complete_loss_fct_nu_nub--returns" title="Permanent link">&para;</a></h4>
<p>torch.Tensor
    Total loss including chi-squared term, positivity penalty, and integral constraint.</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/form_loss_fct.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 6</span>
<span class="normal"> 7</span>
<span class="normal"> 8</span>
<span class="normal"> 9</span>
<span class="normal">10</span>
<span class="normal">11</span>
<span class="normal">12</span>
<span class="normal">13</span>
<span class="normal">14</span>
<span class="normal">15</span>
<span class="normal">16</span>
<span class="normal">17</span>
<span class="normal">18</span>
<span class="normal">19</span>
<span class="normal">20</span>
<span class="normal">21</span>
<span class="normal">22</span>
<span class="normal">23</span>
<span class="normal">24</span>
<span class="normal">25</span>
<span class="normal">26</span>
<span class="normal">27</span>
<span class="normal">28</span>
<span class="normal">29</span>
<span class="normal">30</span>
<span class="normal">31</span>
<span class="normal">32</span>
<span class="normal">33</span>
<span class="normal">34</span>
<span class="normal">35</span>
<span class="normal">36</span>
<span class="normal">37</span>
<span class="normal">38</span>
<span class="normal">39</span>
<span class="normal">40</span>
<span class="normal">41</span>
<span class="normal">42</span>
<span class="normal">43</span>
<span class="normal">44</span>
<span class="normal">45</span>
<span class="normal">46</span>
<span class="normal">47</span>
<span class="normal">48</span>
<span class="normal">49</span>
<span class="normal">50</span>
<span class="normal">51</span>
<span class="normal">52</span>
<span class="normal">53</span>
<span class="normal">54</span>
<span class="normal">55</span>
<span class="normal">56</span>
<span class="normal">57</span>
<span class="normal">58</span>
<span class="normal">59</span>
<span class="normal">60</span>
<span class="normal">61</span>
<span class="normal">62</span>
<span class="normal">63</span>
<span class="normal">64</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">complete_loss_fct_nu_nub</span><span class="p">(</span>
    <span class="n">pred</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">cov_matrix</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">f</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">int_point_nu</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">int_point_nub</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">x_int</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">lag_mult_pos</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">lag_mult_int</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extended chi-squared loss for separate neutrino and antineutrino predictions, with constraints.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pred : torch.Tensor</span>
<span class="sd">        Model predictions for observed data (shape: N).</span>
<span class="sd">    data : torch.Tensor</span>
<span class="sd">        Observed pseudo-data (shape: N).</span>
<span class="sd">    cov_matrix : torch.Tensor</span>
<span class="sd">        Covariance matrix for the data (shape: N x N).</span>
<span class="sd">    f : torch.Tensor</span>
<span class="sd">        Raw (non-preprocessed) neural network outputs (shape: N x 2), with:</span>
<span class="sd">            - f[:, 0]: neutrino component (ν)</span>
<span class="sd">            - f[:, 1]: antineutrino component (ν̄)</span>
<span class="sd">    int_point_nu : torch.Tensor</span>
<span class="sd">        Integral constraint values for ν (shape: N).</span>
<span class="sd">    int_point_nub : torch.Tensor</span>
<span class="sd">        Integral constraint values for ν̄ (shape: N).</span>
<span class="sd">    x_int : torch.Tensor</span>
<span class="sd">        x-values for integral evaluation (shape: N).</span>
<span class="sd">    lag_mult_pos : float</span>
<span class="sd">        Lagrange multiplier for enforcing positivity.</span>
<span class="sd">    lag_mult_int : float</span>
<span class="sd">        Lagrange multiplier for enforcing normalization via integral.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        Total loss including chi-squared term, positivity penalty, and integral constraint.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">-</span> <span class="n">data</span>
    <span class="n">diffcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>

    <span class="n">fnu</span> <span class="o">=</span> <span class="n">f</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span>
    <span class="n">fnub</span> <span class="o">=</span> <span class="n">f</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span>
    <span class="n">fnu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">fnu</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">fnu</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>
    <span class="n">fnub</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">fnub</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">fnub</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">pred</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">diffcov</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>
        <span class="o">+</span> <span class="nb">abs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">fnu</span><span class="p">))</span> <span class="o">*</span> <span class="n">lag_mult_pos</span>
        <span class="o">+</span> <span class="nb">abs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">fnub</span><span class="p">))</span> <span class="o">*</span> <span class="n">lag_mult_pos</span>
        <span class="o">+</span> <span class="nb">abs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">int_point_nu</span> <span class="o">*</span> <span class="n">x_int</span><span class="p">))</span> <span class="o">*</span> <span class="n">lag_mult_int</span>
        <span class="o">+</span> <span class="nb">abs</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">int_point_nub</span> <span class="o">*</span> <span class="n">x_int</span><span class="p">))</span> <span class="o">*</span> <span class="n">lag_mult_int</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="NN_fit.form_loss_fct.raw_loss_fct" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">raw_loss_fct</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="p">)</span></code>

<a href="#NN_fit.form_loss_fct.raw_loss_fct" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Standard chi-squared loss without any constraints.</p>
<h4 id="NN_fit.form_loss_fct.raw_loss_fct--parameters">Parameters<a class="headerlink" href="#NN_fit.form_loss_fct.raw_loss_fct--parameters" title="Permanent link">&para;</a></h4>
<p>pred : torch.Tensor
    Model predictions (shape: N).
data : torch.Tensor
    Observed pseudo-data (shape: N).
cov_matrix : torch.Tensor
    Covariance matrix (shape: N x N).</p>
<h4 id="NN_fit.form_loss_fct.raw_loss_fct--returns">Returns<a class="headerlink" href="#NN_fit.form_loss_fct.raw_loss_fct--returns" title="Permanent link">&para;</a></h4>
<p>torch.Tensor
    Chi-squared loss.</p>


            <details class="quote">
              <summary>Source code in <code>NN_fit/form_loss_fct.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">raw_loss_fct</span><span class="p">(</span>
    <span class="n">pred</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">cov_matrix</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Standard chi-squared loss without any constraints.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    pred : torch.Tensor</span>
<span class="sd">        Model predictions (shape: N).</span>
<span class="sd">    data : torch.Tensor</span>
<span class="sd">        Observed pseudo-data (shape: N).</span>
<span class="sd">    cov_matrix : torch.Tensor</span>
<span class="sd">        Covariance matrix (shape: N x N).</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    torch.Tensor</span>
<span class="sd">        Chi-squared loss.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">diff</span> <span class="o">=</span> <span class="n">pred</span> <span class="o">-</span> <span class="n">data</span>
    <span class="n">diffcov</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">cov_matrix</span><span class="p">,</span> <span class="n">diff</span><span class="p">)</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">pred</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">diff</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">diffcov</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">loss</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><h3 id="generate_datapy"><code>generate_data.py</code><a class="headerlink" href="#generate_datapy" title="Permanent link">&para;</a></h3>


<div class="doc doc-object doc-module">



<a id="NN_fit.generate_data"></a>
    <div class="doc doc-contents first">









  <div class="doc doc-children">









<div class="doc doc-object doc-function">


<h2 id="NN_fit.generate_data.aggregate_entries_with_indices" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">aggregate_entries_with_indices</span><span class="p">(</span><span class="n">fk_tables</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">binwidths</span><span class="p">,</span> <span class="n">low_bin</span><span class="p">,</span> <span class="n">high_bin</span><span class="p">,</span> <span class="n">threshold</span><span class="p">)</span></code>

<a href="#NN_fit.generate_data.aggregate_entries_with_indices" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Aggregates FK table rows and data bins until a minimum threshold of events is reached.</p>
<p>This function rebins cross section data, corresponding FK table rows, and bin widths
such that each new bin has at least a specified number of events (threshold). This
is often necessary for achieving meaningful statistical analysis in low-statistics bins.</p>
<h4 id="NN_fit.generate_data.aggregate_entries_with_indices--parameters">Parameters<a class="headerlink" href="#NN_fit.generate_data.aggregate_entries_with_indices--parameters" title="Permanent link">&para;</a></h4>
<p>fk_tables : torch.Tensor
    The FastKernel table with shape (n_bins, n_x).
data : np.ndarray
    Event data per bin (e.g., cross section  bin width).
binwidths : np.ndarray
    Width of each original bin.
low_bin : np.ndarray
    Lower edges of the original bins.
high_bin : np.ndarray
    Upper edges of the original bins.
threshold : float
    Minimum number of events required to form a new rebinned bin.</p>
<h4 id="NN_fit.generate_data.aggregate_entries_with_indices--returns">Returns<a class="headerlink" href="#NN_fit.generate_data.aggregate_entries_with_indices--returns" title="Permanent link">&para;</a></h4>
<p>rebin_data : list of float
    Aggregated event counts after rebinning.
rebin_fk_table_mu : torch.Tensor
    Rebinned FK table rows (shape: new_n_bins  n_x).
rebin_binwidhts : np.ndarray
    Bin widths corresponding to rebinned bins.
rebin_low_bin : np.ndarray
    Lower edges of the rebinned bins.
rebin_high_bin : np.ndarray
    Upper edges of the rebinned bins.</p>
<h4 id="NN_fit.generate_data.aggregate_entries_with_indices--notes">Notes<a class="headerlink" href="#NN_fit.generate_data.aggregate_entries_with_indices--notes" title="Permanent link">&para;</a></h4>
<ul>
<li>Remaining data after the last full threshold bin is added to the final bin.</li>
<li>Bin widths are recomputed using weighted averages to ensure consistency.</li>
</ul>


            <details class="quote">
              <summary>Source code in <code>NN_fit/generate_data.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">aggregate_entries_with_indices</span><span class="p">(</span>
    <span class="n">fk_tables</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
    <span class="n">data</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">binwidths</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">low_bin</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">high_bin</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
    <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">],</span>  <span class="c1"># rebin_data</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>  <span class="c1"># rebin_fk_table_mu</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># rebin_binwidhts</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># rebin_low_bin</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># rebin_high_bin</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Aggregates FK table rows and data bins until a minimum threshold of events is reached.</span>

<span class="sd">    This function rebins cross section data, corresponding FK table rows, and bin widths</span>
<span class="sd">    such that each new bin has at least a specified number of events (threshold). This</span>
<span class="sd">    is often necessary for achieving meaningful statistical analysis in low-statistics bins.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    fk_tables : torch.Tensor</span>
<span class="sd">        The FastKernel table with shape (n_bins, n_x).</span>
<span class="sd">    data : np.ndarray</span>
<span class="sd">        Event data per bin (e.g., cross section  bin width).</span>
<span class="sd">    binwidths : np.ndarray</span>
<span class="sd">        Width of each original bin.</span>
<span class="sd">    low_bin : np.ndarray</span>
<span class="sd">        Lower edges of the original bins.</span>
<span class="sd">    high_bin : np.ndarray</span>
<span class="sd">        Upper edges of the original bins.</span>
<span class="sd">    threshold : float</span>
<span class="sd">        Minimum number of events required to form a new rebinned bin.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    rebin_data : list of float</span>
<span class="sd">        Aggregated event counts after rebinning.</span>
<span class="sd">    rebin_fk_table_mu : torch.Tensor</span>
<span class="sd">        Rebinned FK table rows (shape: new_n_bins  n_x).</span>
<span class="sd">    rebin_binwidhts : np.ndarray</span>
<span class="sd">        Bin widths corresponding to rebinned bins.</span>
<span class="sd">    rebin_low_bin : np.ndarray</span>
<span class="sd">        Lower edges of the rebinned bins.</span>
<span class="sd">    rebin_high_bin : np.ndarray</span>
<span class="sd">        Upper edges of the rebinned bins.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - Remaining data after the last full threshold bin is added to the final bin.</span>
<span class="sd">    - Bin widths are recomputed using weighted averages to ensure consistency.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="p">(</span>
        <span class="n">rebin_data</span><span class="p">,</span>
        <span class="n">rebin_fk_table_mu</span><span class="p">,</span>
        <span class="n">rebin_binwidhts</span><span class="p">,</span>
        <span class="n">rebin_low_bin</span><span class="p">,</span>
        <span class="n">rebin_high_bin</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">[],</span>
        <span class="p">[],</span>
        <span class="p">[],</span>
        <span class="p">[],</span>
        <span class="p">[],</span>
    <span class="p">)</span>
    <span class="n">current_sum</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">start_idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">raw_data</span> <span class="o">=</span> <span class="n">data</span> <span class="o">/</span> <span class="n">binwidths</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
        <span class="n">current_sum</span> <span class="o">+=</span> <span class="n">value</span>

        <span class="k">if</span> <span class="n">current_sum</span> <span class="o">&gt;=</span> <span class="n">threshold</span><span class="p">:</span>
            <span class="n">rebin_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">start_idx</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]))</span>
            <span class="n">sum_binwidth</span> <span class="o">=</span> <span class="mf">0.0</span>

            <span class="n">sum_binwidth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">start_idx</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span>
                <span class="n">raw_data</span><span class="p">[</span><span class="n">start_idx</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
            <span class="p">)</span>

            <span class="n">rebin_binwidhts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sum_binwidth</span><span class="p">)</span>

            <span class="n">rebin_low_bin</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">low_bin</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">rebin_high_bin</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">high_bin</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">summed_column_mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">fk_tables</span><span class="p">[</span><span class="n">start_idx</span> <span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">summed_column_mu</span> <span class="o">=</span> <span class="n">summed_column_mu</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">rebin_fk_table_mu</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">summed_column_mu</span><span class="p">)</span>

            <span class="n">previous_idx</span> <span class="o">=</span> <span class="n">start_idx</span>
            <span class="n">start_idx</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="n">current_sum</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">if</span> <span class="n">current_sum</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">rebin_data</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="nb">sum</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:])</span>

        <span class="n">sum_binwidth</span> <span class="o">=</span> <span class="mf">0.0</span>

        <span class="n">sum_binwidth</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">previous_idx</span><span class="p">:])</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">raw_data</span><span class="p">[</span><span class="n">previous_idx</span><span class="p">:])</span>

        <span class="n">rebin_binwidhts</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">sum_binwidth</span>

        <span class="n">rebin_fk_table_mu</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">fk_tables</span><span class="p">[</span><span class="n">start_idx</span><span class="p">:,</span> <span class="p">:],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span>
            <span class="mi">0</span>
        <span class="p">)</span>
        <span class="n">rebin_low_bin</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">low_bin</span><span class="p">[</span><span class="n">previous_idx</span><span class="p">]</span>
        <span class="n">rebin_high_bin</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">high_bin</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

    <span class="n">rebin_fk_table_mu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">rebin_fk_table_mu</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="n">rebin_binwidhts</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rebin_binwidhts</span><span class="p">)</span>
    <span class="n">rebin_low_bin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">rebin_low_bin</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="n">rebin_data</span><span class="p">,</span>
        <span class="n">rebin_fk_table_mu</span><span class="p">,</span>
        <span class="n">rebin_binwidhts</span><span class="p">,</span>
        <span class="n">rebin_low_bin</span><span class="p">,</span>
        <span class="n">rebin_high_bin</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="NN_fit.generate_data.compute_pseudo_data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">compute_pseudo_data</span><span class="p">(</span><span class="n">filename_fk_mub_n</span><span class="p">,</span> <span class="n">filename_fk_mub_p</span><span class="p">,</span> <span class="n">filename_fk_mu_n</span><span class="p">,</span> <span class="n">filename_fk_mu_p</span><span class="p">,</span> <span class="n">filename_binsize</span><span class="p">,</span> <span class="n">pid</span><span class="p">,</span> <span class="n">pdf_name</span><span class="p">,</span> <span class="n">pdf_set</span><span class="p">)</span></code>

<a href="#NN_fit.generate_data.compute_pseudo_data" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Computes pseudo-data for neutrino and anti-neutrino scattering using FK tables and PDFs.</p>
<p>This function processes FK tables (FastKernel weight tables) and convolves them with
parton distribution functions (PDFs) to produce synthetic ("pseudo") data for both
neutrinos (mu) and anti-neutrinos (mub). It also calculates associated statistical errors.</p>
<h4 id="NN_fit.generate_data.compute_pseudo_data--parameters">Parameters<a class="headerlink" href="#NN_fit.generate_data.compute_pseudo_data--parameters" title="Permanent link">&para;</a></h4>
<p>filename_fk_mub_n : str
    Filename for the anti-neutrino FK table (neutron target).
filename_fk_mub_p : str
    Filename for the anti-neutrino FK table (proton target).
filename_fk_mu_n : str
    Filename for the neutrino FK table (neutron target).
filename_fk_mu_p : str
    Filename for the neutrino FK table (proton target).
filename_binsize : str
    Filename containing binning information (low, high bin edges, and widths).
pid : int
    PDG ID of the relevant parton (e.g., 12, 14, 16 for neutrino flavors).
pdf_name : str
    Name of the PDF set (e.g., "CT18", "NNPDF4.0").
pdf_set : int
    Index of the replica or member within the PDF set.</p>
<h4 id="NN_fit.generate_data.compute_pseudo_data--returns">Returns<a class="headerlink" href="#NN_fit.generate_data.compute_pseudo_data--returns" title="Permanent link">&para;</a></h4>
<p>data_mu : np.ndarray
    Pseudo-data for neutrino cross sections, binned.
data_mub : np.ndarray
    Pseudo-data for anti-neutrino cross sections, binned.
error_mu : np.ndarray
    Statistical uncertainty (sqrt(N)) for neutrino data.
error_mub : np.ndarray
    Statistical uncertainty (sqrt(N)) for anti-neutrino data.
fk_tables_mu : torch.Tensor
    Final combined FK table for neutrinos.
fk_tables_mub : torch.Tensor
    Final combined FK table for anti-neutrinos.
low_bin : np.ndarray
    Lower bin edges of the energy bins.
high_bin : np.ndarray
    Upper bin edges of the energy bins.
binwidths_mu : np.ndarray
    Widths of bins used for neutrino integration.
binwidths_mub : np.ndarray
    Widths of bins used for anti-neutrino integration (same as <code>binwidths_mu</code>).</p>
<h4 id="NN_fit.generate_data.compute_pseudo_data--notes">Notes<a class="headerlink" href="#NN_fit.generate_data.compute_pseudo_data--notes" title="Permanent link">&para;</a></h4>
<ul>
<li>This function uses hard-coded weights: 59.56% neutron and 40.44% proton contributions.</li>
<li>Any negative or zero values in the pseudo-data are replaced with small positive values
  (0.1) to avoid numerical issues.</li>
<li>Requires FK tables and bin sizes to be precomputed and available as text files.</li>
</ul>


            <details class="quote">
              <summary>Source code in <code>NN_fit/generate_data.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">compute_pseudo_data</span><span class="p">(</span>
    <span class="n">filename_fk_mub_n</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">filename_fk_mub_p</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">filename_fk_mu_n</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">filename_fk_mu_p</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">filename_binsize</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">pid</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">pdf_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">pdf_set</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># data_mu</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># data_mub</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># error_mu</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># error_mub</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>  <span class="c1"># fk_tables_mu</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>  <span class="c1"># fk_tables_mub</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># low_bin</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># high_bin</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># binwidths_mu</span>
    <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>  <span class="c1"># binwidths_mub</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes pseudo-data for neutrino and anti-neutrino scattering using FK tables and PDFs.</span>

<span class="sd">    This function processes FK tables (FastKernel weight tables) and convolves them with</span>
<span class="sd">    parton distribution functions (PDFs) to produce synthetic (&quot;pseudo&quot;) data for both</span>
<span class="sd">    neutrinos (mu) and anti-neutrinos (mub). It also calculates associated statistical errors.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filename_fk_mub_n : str</span>
<span class="sd">        Filename for the anti-neutrino FK table (neutron target).</span>
<span class="sd">    filename_fk_mub_p : str</span>
<span class="sd">        Filename for the anti-neutrino FK table (proton target).</span>
<span class="sd">    filename_fk_mu_n : str</span>
<span class="sd">        Filename for the neutrino FK table (neutron target).</span>
<span class="sd">    filename_fk_mu_p : str</span>
<span class="sd">        Filename for the neutrino FK table (proton target).</span>
<span class="sd">    filename_binsize : str</span>
<span class="sd">        Filename containing binning information (low, high bin edges, and widths).</span>
<span class="sd">    pid : int</span>
<span class="sd">        PDG ID of the relevant parton (e.g., 12, 14, 16 for neutrino flavors).</span>
<span class="sd">    pdf_name : str</span>
<span class="sd">        Name of the PDF set (e.g., &quot;CT18&quot;, &quot;NNPDF4.0&quot;).</span>
<span class="sd">    pdf_set : int</span>
<span class="sd">        Index of the replica or member within the PDF set.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    data_mu : np.ndarray</span>
<span class="sd">        Pseudo-data for neutrino cross sections, binned.</span>
<span class="sd">    data_mub : np.ndarray</span>
<span class="sd">        Pseudo-data for anti-neutrino cross sections, binned.</span>
<span class="sd">    error_mu : np.ndarray</span>
<span class="sd">        Statistical uncertainty (sqrt(N)) for neutrino data.</span>
<span class="sd">    error_mub : np.ndarray</span>
<span class="sd">        Statistical uncertainty (sqrt(N)) for anti-neutrino data.</span>
<span class="sd">    fk_tables_mu : torch.Tensor</span>
<span class="sd">        Final combined FK table for neutrinos.</span>
<span class="sd">    fk_tables_mub : torch.Tensor</span>
<span class="sd">        Final combined FK table for anti-neutrinos.</span>
<span class="sd">    low_bin : np.ndarray</span>
<span class="sd">        Lower bin edges of the energy bins.</span>
<span class="sd">    high_bin : np.ndarray</span>
<span class="sd">        Upper bin edges of the energy bins.</span>
<span class="sd">    binwidths_mu : np.ndarray</span>
<span class="sd">        Widths of bins used for neutrino integration.</span>
<span class="sd">    binwidths_mub : np.ndarray</span>
<span class="sd">        Widths of bins used for anti-neutrino integration (same as `binwidths_mu`).</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - This function uses hard-coded weights: 59.56% neutron and 40.44% proton contributions.</span>
<span class="sd">    - Any negative or zero values in the pseudo-data are replaced with small positive values</span>
<span class="sd">      (0.1) to avoid numerical issues.</span>
<span class="sd">    - Requires FK tables and bin sizes to be precomputed and available as text files.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">x_alphas</span><span class="p">,</span> <span class="n">fk_tables_mu_n</span> <span class="o">=</span> <span class="n">get_fk_table</span><span class="p">(</span>
        <span class="n">filename</span><span class="o">=</span><span class="n">filename_fk_mu_n</span><span class="p">,</span> <span class="n">parent_dir</span><span class="o">=</span><span class="n">parent_dir</span>
    <span class="p">)</span>

    <span class="n">x_alphas</span><span class="p">,</span> <span class="n">fk_tables_mu_p</span> <span class="o">=</span> <span class="n">get_fk_table</span><span class="p">(</span>
        <span class="n">filename</span><span class="o">=</span><span class="n">filename_fk_mu_p</span><span class="p">,</span> <span class="n">parent_dir</span><span class="o">=</span><span class="n">parent_dir</span>
    <span class="p">)</span>

    <span class="n">fk_tables_mu</span> <span class="o">=</span> <span class="n">fk_tables_mu_n</span> <span class="o">*</span> <span class="mf">0.5956284</span> <span class="o">+</span> <span class="n">fk_tables_mu_p</span> <span class="o">*</span> <span class="mf">0.4043716</span>

    <span class="n">x_alphas</span><span class="p">,</span> <span class="n">fk_tables_mub_n</span> <span class="o">=</span> <span class="n">get_fk_table</span><span class="p">(</span>
        <span class="n">filename</span><span class="o">=</span><span class="n">filename_fk_mub_n</span><span class="p">,</span> <span class="n">parent_dir</span><span class="o">=</span><span class="n">parent_dir</span>
    <span class="p">)</span>

    <span class="n">x_alphas</span><span class="p">,</span> <span class="n">fk_tables_mub_p</span> <span class="o">=</span> <span class="n">get_fk_table</span><span class="p">(</span>
        <span class="n">filename</span><span class="o">=</span><span class="n">filename_fk_mub_p</span><span class="p">,</span> <span class="n">parent_dir</span><span class="o">=</span><span class="n">parent_dir</span>
    <span class="p">)</span>
    <span class="n">fk_tables_mub</span> <span class="o">=</span> <span class="n">fk_tables_mub_n</span> <span class="o">*</span> <span class="mf">0.5956284</span> <span class="o">+</span> <span class="n">fk_tables_mub_p</span> <span class="o">*</span> <span class="mf">0.4043716</span>

    <span class="n">file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">parent_dir</span><span class="p">,</span> <span class="n">filename_binsize</span><span class="p">)</span>
    <span class="n">low_bin</span><span class="p">,</span> <span class="n">high_bin</span><span class="p">,</span> <span class="n">binwidths_mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">loadtxt</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">file_path</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">unpack</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">binwidths_mub</span> <span class="o">=</span> <span class="n">binwidths_mu</span>

    <span class="n">faser_pdf</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">read_pdf</span><span class="p">(</span><span class="n">pdf_name</span><span class="p">,</span> <span class="n">x_alphas</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="n">pid</span><span class="p">,</span> <span class="n">pdf_set</span><span class="p">)</span>
    <span class="n">faser_pdf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">faser_pdf</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">data_mu</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">fk_tables_mu</span><span class="p">,</span> <span class="n">faser_pdf</span><span class="p">)</span> <span class="o">*</span> <span class="n">binwidths_mu</span><span class="p">)</span>
        <span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="p">)</span>

    <span class="n">faser_pdf</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">read_pdf</span><span class="p">(</span>
        <span class="n">pdf_name</span><span class="p">,</span> <span class="n">x_alphas</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span> <span class="o">-</span><span class="n">pid</span><span class="p">,</span> <span class="n">pdf_set</span>
    <span class="p">)</span>
    <span class="n">faser_pdf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">faser_pdf</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">data_mub</span> <span class="o">=</span> <span class="p">(</span>
        <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">fk_tables_mub</span><span class="p">,</span> <span class="n">faser_pdf</span><span class="p">)</span> <span class="o">*</span> <span class="n">binwidths_mub</span><span class="p">)</span>
        <span class="o">.</span><span class="n">detach</span><span class="p">()</span>
        <span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
    <span class="p">)</span>
    <span class="n">data_mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data_mu</span><span class="p">)</span>
    <span class="n">data_mub</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data_mub</span><span class="p">)</span>
    <span class="n">data_mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">data_mu</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">data_mu</span><span class="p">)</span>
    <span class="n">data_mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">data_mu</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">data_mu</span><span class="p">)</span>
    <span class="n">data_mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">data_mu</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">data_mu</span><span class="p">)</span>
    <span class="n">data_mub</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">data_mub</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">data_mub</span><span class="p">)</span>

    <span class="n">error_mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">data_mu</span><span class="p">)</span>
    <span class="n">error_mub</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">data_mub</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">(</span>
        <span class="n">data_mu</span><span class="p">,</span>
        <span class="n">data_mub</span><span class="p">,</span>
        <span class="n">error_mu</span><span class="p">,</span>
        <span class="n">error_mub</span><span class="p">,</span>
        <span class="n">fk_tables_mu</span><span class="p">,</span>
        <span class="n">fk_tables_mub</span><span class="p">,</span>
        <span class="n">low_bin</span><span class="p">,</span>
        <span class="n">high_bin</span><span class="p">,</span>
        <span class="n">binwidths_mu</span><span class="p">,</span>
        <span class="n">binwidths_mub</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>

<div class="doc doc-object doc-function">


<h2 id="NN_fit.generate_data.write_data" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">write_data</span><span class="p">(</span><span class="n">filename_fk_mub_n</span><span class="p">,</span> <span class="n">filename_fk_mub_p</span><span class="p">,</span> <span class="n">filename_fk_mu_n</span><span class="p">,</span> <span class="n">filename_fk_mu_p</span><span class="p">,</span> <span class="n">filename_binsize</span><span class="p">,</span> <span class="n">pid</span><span class="p">,</span> <span class="n">pdf_name</span><span class="p">,</span> <span class="n">pdf_set</span><span class="p">,</span> <span class="n">filename_to_store_events</span><span class="p">,</span> <span class="n">filename_to_store_stat_error</span><span class="p">,</span> <span class="n">filename_to_store_sys_error</span><span class="p">,</span> <span class="n">filename_to_store_cov_matrix</span><span class="p">,</span> <span class="n">min_num_events</span><span class="p">,</span> <span class="n">observable</span><span class="p">,</span> <span class="n">combine_nu_nub_data</span><span class="p">,</span> <span class="n">multiplication_factor_sys_error</span><span class="p">)</span></code>

<a href="#NN_fit.generate_data.write_data" class="headerlink" title="Permanent link">&para;</a></h2>


    <div class="doc doc-contents ">

        <p>Computes pseudo-data from FK tables and PDFs, optionally rebins them, and writes the results to disk.</p>
<p>This function is the main pipeline to produce and store pseudo-experimental data, its
statistical and systematic uncertainties, covariance matrix, binning information, and
FastKernel tables, all ready for use in PDF fits or phenomenology studies.</p>
<h4 id="NN_fit.generate_data.write_data--parameters">Parameters<a class="headerlink" href="#NN_fit.generate_data.write_data--parameters" title="Permanent link">&para;</a></h4>
<p>filename_fk_mub_n : str
    FK table for anti-neutrino interactions on neutrons.
filename_fk_mub_p : str
    FK table for anti-neutrino interactions on protons.
filename_fk_mu_n : str
    FK table for neutrino interactions on neutrons.
filename_fk_mu_p : str
    FK table for neutrino interactions on protons.
filename_binsize : str
    Filename for bin edges and widths (low, high, width).
pid : int
    PDG ID of the target parton species.
pdf_name : str
    Name of the LHAPDF set to use.
pdf_set : int
    Index of the PDF replica or member.
filename_to_store_events : str
    Base filename for storing rebinned event data.
filename_to_store_stat_error : str
    Base filename for storing statistical uncertainties.
filename_to_store_sys_error : str
    Base filename for storing systematic uncertainties.
filename_to_store_cov_matrix : str
    Base filename for storing the inverse of the covariance matrix.
min_num_events : int
    Minimum number of events per bin in the rebinned dataset.
observable : str
    Observable label (e.g., "energy", "pt") used in output filenames.
combine_nu_nub_data : bool
    If True, neutrino and anti-neutrino data are summed into one dataset.
multiplication_factor_sys_error : float
    Factor to multiply event counts for estimating systematic uncertainties.</p>
<h4 id="NN_fit.generate_data.write_data--returns">Returns<a class="headerlink" href="#NN_fit.generate_data.write_data--returns" title="Permanent link">&para;</a></h4>
<p>None
    Writes output files directly to disk.</p>
<h4 id="NN_fit.generate_data.write_data--output-files">Output Files<a class="headerlink" href="#NN_fit.generate_data.write_data--output-files" title="Permanent link">&para;</a></h4>
<p>../../../Data/data/:
    - Re-binned event counts (combined, mu, mub)</p>
<p>../../../Data/uncertainties/:
    - Statistical and systematic uncertainties
    - Covariance matrix (inverted, diagonal only)</p>
<p>../../../Data/binning/:
    - Re-binned bin edges and widths (mu, mub, or combined)</p>
<p>../../../Data/fastkernel/:
    - Re-binned FK tables</p>
<h4 id="NN_fit.generate_data.write_data--notes">Notes<a class="headerlink" href="#NN_fit.generate_data.write_data--notes" title="Permanent link">&para;</a></h4>
<ul>
<li>Assumes FK and bin files are already precomputed and exist in the expected format.</li>
<li>The covariance matrix is stored in inverted form (1/σ² on the diagonal).</li>
<li>Output filenames are automatically labeled with PID and threshold settings.</li>
<li>Handles both the case where ν and ν̄ data are stored separately or combined.</li>
</ul>


            <details class="quote">
              <summary>Source code in <code>NN_fit/generate_data.py</code></summary>
              <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span>
<span class="normal">494</span>
<span class="normal">495</span>
<span class="normal">496</span>
<span class="normal">497</span>
<span class="normal">498</span>
<span class="normal">499</span>
<span class="normal">500</span>
<span class="normal">501</span>
<span class="normal">502</span>
<span class="normal">503</span>
<span class="normal">504</span>
<span class="normal">505</span>
<span class="normal">506</span>
<span class="normal">507</span>
<span class="normal">508</span>
<span class="normal">509</span>
<span class="normal">510</span>
<span class="normal">511</span>
<span class="normal">512</span>
<span class="normal">513</span>
<span class="normal">514</span>
<span class="normal">515</span>
<span class="normal">516</span>
<span class="normal">517</span>
<span class="normal">518</span>
<span class="normal">519</span>
<span class="normal">520</span>
<span class="normal">521</span>
<span class="normal">522</span>
<span class="normal">523</span>
<span class="normal">524</span>
<span class="normal">525</span>
<span class="normal">526</span>
<span class="normal">527</span>
<span class="normal">528</span>
<span class="normal">529</span>
<span class="normal">530</span>
<span class="normal">531</span>
<span class="normal">532</span>
<span class="normal">533</span>
<span class="normal">534</span>
<span class="normal">535</span>
<span class="normal">536</span>
<span class="normal">537</span>
<span class="normal">538</span>
<span class="normal">539</span>
<span class="normal">540</span>
<span class="normal">541</span>
<span class="normal">542</span>
<span class="normal">543</span>
<span class="normal">544</span>
<span class="normal">545</span>
<span class="normal">546</span>
<span class="normal">547</span></pre></div></td><td class="code"><div><pre><span></span><code><span class="k">def</span><span class="w"> </span><span class="nf">write_data</span><span class="p">(</span>
    <span class="n">filename_fk_mub_n</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">filename_fk_mub_p</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">filename_fk_mu_n</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">filename_fk_mu_p</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">filename_binsize</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">pid</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">pdf_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">pdf_set</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">filename_to_store_events</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">filename_to_store_stat_error</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">filename_to_store_sys_error</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">filename_to_store_cov_matrix</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">min_num_events</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">observable</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">combine_nu_nub_data</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">multiplication_factor_sys_error</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Computes pseudo-data from FK tables and PDFs, optionally rebins them, and writes the results to disk.</span>

<span class="sd">    This function is the main pipeline to produce and store pseudo-experimental data, its</span>
<span class="sd">    statistical and systematic uncertainties, covariance matrix, binning information, and</span>
<span class="sd">    FastKernel tables, all ready for use in PDF fits or phenomenology studies.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    filename_fk_mub_n : str</span>
<span class="sd">        FK table for anti-neutrino interactions on neutrons.</span>
<span class="sd">    filename_fk_mub_p : str</span>
<span class="sd">        FK table for anti-neutrino interactions on protons.</span>
<span class="sd">    filename_fk_mu_n : str</span>
<span class="sd">        FK table for neutrino interactions on neutrons.</span>
<span class="sd">    filename_fk_mu_p : str</span>
<span class="sd">        FK table for neutrino interactions on protons.</span>
<span class="sd">    filename_binsize : str</span>
<span class="sd">        Filename for bin edges and widths (low, high, width).</span>
<span class="sd">    pid : int</span>
<span class="sd">        PDG ID of the target parton species.</span>
<span class="sd">    pdf_name : str</span>
<span class="sd">        Name of the LHAPDF set to use.</span>
<span class="sd">    pdf_set : int</span>
<span class="sd">        Index of the PDF replica or member.</span>
<span class="sd">    filename_to_store_events : str</span>
<span class="sd">        Base filename for storing rebinned event data.</span>
<span class="sd">    filename_to_store_stat_error : str</span>
<span class="sd">        Base filename for storing statistical uncertainties.</span>
<span class="sd">    filename_to_store_sys_error : str</span>
<span class="sd">        Base filename for storing systematic uncertainties.</span>
<span class="sd">    filename_to_store_cov_matrix : str</span>
<span class="sd">        Base filename for storing the inverse of the covariance matrix.</span>
<span class="sd">    min_num_events : int</span>
<span class="sd">        Minimum number of events per bin in the rebinned dataset.</span>
<span class="sd">    observable : str</span>
<span class="sd">        Observable label (e.g., &quot;energy&quot;, &quot;pt&quot;) used in output filenames.</span>
<span class="sd">    combine_nu_nub_data : bool</span>
<span class="sd">        If True, neutrino and anti-neutrino data are summed into one dataset.</span>
<span class="sd">    multiplication_factor_sys_error : float</span>
<span class="sd">        Factor to multiply event counts for estimating systematic uncertainties.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    None</span>
<span class="sd">        Writes output files directly to disk.</span>

<span class="sd">    Output Files</span>
<span class="sd">    ------------</span>
<span class="sd">    ../../../Data/data/:</span>
<span class="sd">        - Re-binned event counts (combined, mu, mub)</span>

<span class="sd">    ../../../Data/uncertainties/:</span>
<span class="sd">        - Statistical and systematic uncertainties</span>
<span class="sd">        - Covariance matrix (inverted, diagonal only)</span>

<span class="sd">    ../../../Data/binning/:</span>
<span class="sd">        - Re-binned bin edges and widths (mu, mub, or combined)</span>

<span class="sd">    ../../../Data/fastkernel/:</span>
<span class="sd">        - Re-binned FK tables</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    - Assumes FK and bin files are already precomputed and exist in the expected format.</span>
<span class="sd">    - The covariance matrix is stored in inverted form (1/σ² on the diagonal).</span>
<span class="sd">    - Output filenames are automatically labeled with PID and threshold settings.</span>
<span class="sd">    - Handles both the case where ν and ν̄ data are stored separately or combined.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="p">(</span>
        <span class="n">data_mu</span><span class="p">,</span>
        <span class="n">data_mub</span><span class="p">,</span>
        <span class="n">error_mu</span><span class="p">,</span>
        <span class="n">error_mub</span><span class="p">,</span>
        <span class="n">fk_tables_mu</span><span class="p">,</span>
        <span class="n">fk_tables_mub</span><span class="p">,</span>
        <span class="n">low_bin</span><span class="p">,</span>
        <span class="n">high_bin</span><span class="p">,</span>
        <span class="n">binwidths_mu</span><span class="p">,</span>
        <span class="n">binwidths_mub</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">compute_pseudo_data</span><span class="p">(</span>
        <span class="n">filename_fk_mub_n</span><span class="p">,</span>
        <span class="n">filename_fk_mub_p</span><span class="p">,</span>
        <span class="n">filename_fk_mu_n</span><span class="p">,</span>
        <span class="n">filename_fk_mu_p</span><span class="p">,</span>
        <span class="n">filename_binsize</span><span class="p">,</span>
        <span class="n">pid</span><span class="p">,</span>
        <span class="n">pdf_name</span><span class="p">,</span>
        <span class="n">pdf_set</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">combine_nu_nub_data</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data_mu</span> <span class="o">+</span> <span class="n">data_mub</span>
        <span class="n">binwidths</span> <span class="o">=</span> <span class="n">binwidths_mu</span>
        <span class="n">fk_tables</span> <span class="o">=</span> <span class="n">fk_tables_mu</span> <span class="o">+</span> <span class="n">fk_tables_mub</span>
        <span class="p">(</span>
            <span class="n">data</span><span class="p">,</span>
            <span class="n">fk_tables</span><span class="p">,</span>
            <span class="n">binwidths</span><span class="p">,</span>
            <span class="n">low_bin</span><span class="p">,</span>
            <span class="n">high_bin</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">aggregate_entries_with_indices</span><span class="p">(</span>
            <span class="n">fk_tables</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">binwidths</span><span class="p">,</span> <span class="n">low_bin</span><span class="p">,</span> <span class="n">high_bin</span><span class="p">,</span> <span class="n">min_num_events</span>
        <span class="p">)</span>
        <span class="n">stack_binning</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">low_bin</span><span class="p">,</span> <span class="n">high_bin</span><span class="p">,</span> <span class="n">binwidths</span><span class="p">))</span>

        <span class="n">error_stat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">error_sys</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">multiplication_factor_sys_error</span>

        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/uncertainties/</span><span class="si">{</span><span class="n">filename_to_store_stat_error</span><span class="si">}</span><span class="s2">_comb_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">error_stat</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/data/</span><span class="si">{</span><span class="n">filename_to_store_events</span><span class="si">}</span><span class="s2">_comb_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">data</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">cov_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">error_sys</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">error_stat</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">cov_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">cov_matrix</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/uncertainties/</span><span class="si">{</span><span class="n">filename_to_store_cov_matrix</span><span class="si">}</span><span class="s2">_comb_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">cov_matrix</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/uncertainties/</span><span class="si">{</span><span class="n">filename_to_store_sys_error</span><span class="si">}</span><span class="s2">_comb_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">error_sys</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/binning/FK_</span><span class="si">{</span><span class="n">observable</span><span class="si">}</span><span class="s2">_binsize_nu_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">stack_binning</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/binning/FK_</span><span class="si">{</span><span class="n">observable</span><span class="si">}</span><span class="s2">_binsize_nub_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">stack_binning</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/fastkernel/FK_</span><span class="si">{</span><span class="n">observable</span><span class="si">}</span><span class="s2">_comb_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">fk_tables</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="p">(</span>
            <span class="n">data_mu</span><span class="p">,</span>
            <span class="n">fk_tables_mu</span><span class="p">,</span>
            <span class="n">binwidths_mu</span><span class="p">,</span>
            <span class="n">low_bin_mu</span><span class="p">,</span>
            <span class="n">high_bin_mu</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">aggregate_entries_with_indices</span><span class="p">(</span>
            <span class="n">fk_tables_mu</span><span class="p">,</span> <span class="n">data_mu</span><span class="p">,</span> <span class="n">binwidths_mu</span><span class="p">,</span> <span class="n">low_bin</span><span class="p">,</span> <span class="n">high_bin</span><span class="p">,</span> <span class="n">min_num_events</span>
        <span class="p">)</span>

        <span class="p">(</span>
            <span class="n">data_mub</span><span class="p">,</span>
            <span class="n">fk_tables_mub</span><span class="p">,</span>
            <span class="n">binwidths_mub</span><span class="p">,</span>
            <span class="n">low_bin_mub</span><span class="p">,</span>
            <span class="n">high_bin_mub</span><span class="p">,</span>
        <span class="p">)</span> <span class="o">=</span> <span class="n">aggregate_entries_with_indices</span><span class="p">(</span>
            <span class="n">fk_tables_mub</span><span class="p">,</span> <span class="n">data_mub</span><span class="p">,</span> <span class="n">binwidths_mub</span><span class="p">,</span> <span class="n">low_bin</span><span class="p">,</span> <span class="n">high_bin</span><span class="p">,</span> <span class="n">min_num_events</span>
        <span class="p">)</span>
        <span class="n">error_stat_nu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">data_mu</span><span class="p">)</span>
        <span class="n">error_stat_nub</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">data_mub</span><span class="p">)</span>
        <span class="n">error_sys_nu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data_mu</span><span class="p">)</span> <span class="o">*</span> <span class="n">multiplication_factor_sys_error</span>
        <span class="n">error_sys_nub</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">data_mub</span><span class="p">)</span> <span class="o">*</span> <span class="n">multiplication_factor_sys_error</span>
        <span class="n">stacked_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">data_mu</span><span class="p">,</span> <span class="n">data_mub</span><span class="p">))</span>
        <span class="n">error_tot_nu</span> <span class="o">=</span> <span class="n">error_stat_nu</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">error_sys_nu</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">error_tot_nub</span> <span class="o">=</span> <span class="n">error_stat_nub</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="n">error_sys_nub</span><span class="o">**</span><span class="mi">2</span>
        <span class="n">stacked_error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">error_tot_nu</span><span class="p">,</span> <span class="n">error_tot_nub</span><span class="p">))</span>
        <span class="n">error_stat_tot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">error_stat_nu</span><span class="p">,</span> <span class="n">error_stat_nub</span><span class="p">))</span>
        <span class="n">error_sys_tot</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">error_sys_nu</span><span class="p">,</span> <span class="n">error_sys_nub</span><span class="p">))</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/data/</span><span class="si">{</span><span class="n">filename_to_store_events</span><span class="si">}</span><span class="s2">_nu_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">data_mu</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/data/</span><span class="si">{</span><span class="n">filename_to_store_events</span><span class="si">}</span><span class="s2">_nub_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="o">-</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">data_mub</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/data/</span><span class="si">{</span><span class="n">filename_to_store_events</span><span class="si">}</span><span class="s2">_comb_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">stacked_data</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/uncertainties/</span><span class="si">{</span><span class="n">filename_to_store_stat_error</span><span class="si">}</span><span class="s2">_comb_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">error_stat_tot</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/uncertainties/</span><span class="si">{</span><span class="n">filename_to_store_sys_error</span><span class="si">}</span><span class="s2">_comb_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">error_sys_tot</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">cov_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">stacked_error</span><span class="p">)</span>
        <span class="n">cov_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">cov_matrix</span><span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/uncertainties/</span><span class="si">{</span><span class="n">filename_to_store_cov_matrix</span><span class="si">}</span><span class="s2">_comb_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">cov_matrix</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/fastkernel/FK_</span><span class="si">{</span><span class="n">observable</span><span class="si">}</span><span class="s2">_mu_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">fk_tables_mu</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/fastkernel/FK_</span><span class="si">{</span><span class="n">observable</span><span class="si">}</span><span class="s2">_mub_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="o">-</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">fk_tables_mub</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">stack_binning_mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">low_bin_mu</span><span class="p">,</span> <span class="n">high_bin_mu</span><span class="p">,</span> <span class="n">binwidths_mu</span><span class="p">))</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/binning/FK_</span><span class="si">{</span><span class="n">observable</span><span class="si">}</span><span class="s2">_binsize_mu_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">stack_binning_mu</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">stack_binning_mub</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">low_bin_mub</span><span class="p">,</span> <span class="n">high_bin_mub</span><span class="p">,</span> <span class="n">binwidths_mub</span><span class="p">))</span>
        <span class="n">np</span><span class="o">.</span><span class="n">savetxt</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;../../../Data/binning/FK_</span><span class="si">{</span><span class="n">observable</span><span class="si">}</span><span class="s2">_binsize_mub_min_</span><span class="si">{</span><span class="n">min_num_events</span><span class="si">}</span><span class="s2">_events_</span><span class="si">{</span><span class="o">-</span><span class="n">pid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">stack_binning_mub</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The data has been written to the Data directory&quot;</span><span class="p">)</span>
</code></pre></div></td></tr></table></div>
            </details>
    </div>

</div>



  </div>

    </div>

</div><h3 id="datayaml-fit_settingsyaml-aall_fits-runcards-etc"><code>data.yaml</code>, <code>fit_settings.yaml</code>, <code>aall_fits/</code>, <code>runcards/</code>, etc.<a class="headerlink" href="#datayaml-fit_settingsyaml-aall_fits-runcards-etc" title="Permanent link">&para;</a></h3>
<p>These files are config/data files and are not included here directly. You can describe them in a separate <strong>"Configuration Guide"</strong> if needed.</p>
<hr />
<blockquote>
<p>📝 <em>All modules are automatically documented from Python docstrings using <a href="https://mkdocstrings.github.io/">mkdocstrings</a>.</em> Type hints, function signatures, and class hierarchies are included where available.</p>
</blockquote>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["content.code.annotate", "content.math"], "search": "../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>